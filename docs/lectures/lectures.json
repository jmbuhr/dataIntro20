[
  {
    "path": "lectures/lecture7/",
    "title": "Lecture 7",
    "description": "Stories of Warplanes, Correlation and Regression",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-12-13",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nData Considerations\n1943\nThe Story of Abraham Wald\nThinking further\n\nMiscelaneous\nGlue\nSVGs\nBest Practices\n\nCovariance, Correlation and Regression\nIntroducing the Dataset\nPearson vs. Spearman (not a Boxing Match)\nLinear Regression\n\nNon-linear Least Squares\n\nExercises\nThe Datasaurus Dozen\nPreparing for the Christmas Special\n\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen. Press ? for a list of keyboard shortcuts.\n\n\n\n\nScript\nData Considerations\n1943\n1943. The second World War is well underway, ravaging large parts of Europe. Military aircraft that had first entered the stage in World War I are now reaching their peak importance as they rain fire from the skies. But the Allied forces are facing a problem. As warplanes get better, so do anti-aircraft systems. In an effort to improve the survival of their fleet, the US military starts examining the planes returning from skirmishes with the opposing forces. They characterize the pattern of bullet holes in the metal hull, meticulously noting down each hit that the plane sustained. The resulting picture is better summarized in the modern, redrawn version in figure 1. We will look at it in just a second, but before we do, let me preface this one by stressing the reach of what we will find.\nThe effect in question has an invisible hand in the laboratory results you create, in the advice people give and is the reason why you don’t get rich after reading books by people telling you how to get rich. It is the pervasive mechanism that powerful people often don’t want to admit exists.\n\n\n\n\nFigure 1: Figure from Wikipedia (“Survivorship Bias” 2020).\n\n\n\nAfter taking a look at the data they gathered, the military is ready to rush into action. To improve the endurance of their aircraft, the plan is to reinforce the parts of the plane that were most often hit by bullets. With stronger wings and a sturdier body of the plane, they think, surely more pilots will come back from their missions safely. They were wrong.\nThe Story of Abraham Wald\nBut the pilots where in luck. The military also consulted with the Statistics Research Group at Columbia University. A man named Abraham Wald worked there. In his now unclassified report “A method of estimating plane vulnerability based on damage of survivors,” he argued against the generals (Wald 1980). Instead of the most-hit parts of the planes, the least-hit parts are to be reinforced.\nCover of “A method of estimating plane vulnerability based on damage of survivors” (Wald 1980)\nInstead of the most-hit parts, the least-hit parts are to be reinforced.\n\nThe reason for this seemingly counterintuitive result is what is now known as survivorship bias. The data that was collected contained only survivors, those planes that sustained damage not severe enough to hinder them from coming back after their mission. The aircraft that where hit in other places simply didn’t make it back. Consequently, Wald advised to reinforce the engines and the fuel tanks.\nThinking further\nThis is but one of a multitude of biases, specifically a selection bias, that will influence the quality of the inferences you can draw from available data. Keep in mind, data is not objective and never exists in a vacuum. There is always context to consider. The way the data was collected is just one of them. A lot of these ideas seem obvious in hindsight, which incidentally is another bias that social psychologists call hindsight bias, but they can sometimes be hard to spot.\nA common saying is that music was better back in the days, or that all the old music still holds up while the new stuff on the radio just sounds the same. Well, not quite. This is also survivorship bias at work. All the bad and forgettable songs from the past just faded into oblivion, never to be mentioned again, while the songs people generally agreed to be good survived the ravages of time unscathed. A similar happens with success in general, not just songs. If you ask any CEO high up the corporate ladder, a millionaire or the author of a book that reads “How to get rich,” they are sure to have a witty anecdote about how their persistence or their brilliance or charisma got them to where they are now. What we are not seeing is all the people just as witty, just as charismatic or even just as persistent that where simply not as lucky. Very few people will tell you this. Because it takes a whole lot of courage to admit that ones success is based on luck and privilege.\nAnd to take it back to the scientific context: When you are planning an experiment for the lab, always ask whether your data collection process can in some way be biased towards what you are trying to show.\nI leave you with this:\n\npreserve6c2551c41d872c17\n\nAnd from this cautionary tale we jump straight back into RStudio.\nMiscelaneous\nTo ease back into R programming, let’s look at some small but helpful things that might otherwise be missed on the sidelines.\nGlue\nFirst up is the glue package. Using paste to create a text in which the values of variables are inserted can be painful. The glue package makes it a breeze. Everything inside of curly braces in the text inside of the glue function will be evaluated as regular R code, enabling us to write text quite naturally:\n\n\nlibrary(glue)\nglue(\"1 + 1 is {1 + 1}\")\n\n\n1 + 1 is 2\n\nI hope you are not too confused by the package and it’s main function having the same name.\n\n\nvalue <- 0.04\nglue(\"With a p-value of {value}!\")\n\n\nWith a p-value of 0.04!\n\nAnother thing I want to briefly mention was already hinted at, when I talked about graphics devices.\nSVGs\nGenerally, there are those devices that produce pixel graphics where the information is stored as color values of the pixels. These are called raster devices. ragg, which I showed you last week, provides some of them. When you zoom into raster images, you can see the texts and shapes getting pixely or blurry. Another way to store information about graphs is to write a mathematical description of the lines and other shapes in the plot, which will then be interpreted by the program with which you open the vector graphic. Let me show you the most popular one called Scalable Vector Graphics (svg).\n\n\nexample <- ggplot(mtcars, aes(disp, mpg)) +\n  geom_point() +\n  labs(title = \"Placeholder Title\")\n\nggsave(\"plots/example.svg\", example)\n\n\n\nIf you get Error in loadNamespace(name) : there is no package called ‘svglite’ you will have to install the mentioned package first.\nYou can now open the svg file with e.g. your browser to preview it. Some image display software will also preview it. Notice, how you can zoom in without loosing clarity. However, the more points and shapes your plot has, the more you computer will have to work to preview it and the file gets bigger than a comparable pixel graphics like png.\nI am showing you svgs specifically, because it takes time to master all the intricacies of ggplot, for example to create annotation. And I don’t want to leave the impression that everything has to be done with pure R. Sure, from a reproducibility standpoint, being able to replicate all your plots and even the complete research report via Rmarkdown at the press of a button is great and should be the ultimate goal. But no one ever started out as an expert. And connecting with tools you already know is an important step.\nSo, for example, we could open up the svg file with the vector editor inkscape, which is also open source software, to add a different title and annotate some points.\n\nBut a word of Warning: When you do this, there is nothing from preventing you to also modify, move or scale the actual datapoints and other important parts that are vital to convey the correct information. So be extra careful when you do this.\nBest Practices\nSpeaking of being careful. There is one rule I can give you to make your data analysis more secure:\n\nYour raw data is sacred! Do not ever modify it or save over it.\n\nThis is even more important when, for example, using excel to preview a csv file. Under no circumstances should you hit the save button in excel when you are looking at the raw data. With approximately one-fifth of genomic research papers containing errors in the gene lists, because excel converted genes such as SEPT2 (Septin 2) into dates, you can see why (Ziemann, Eren, and El-Osta 2016). Biologists have since given up and renamed the genes that where commonly converted into dates… but the point still stands. This caution is of course also necessary when analyzing data with R, not just excel. When we read in the raw data and save a processed version, we create a new file, or even better, a new folder for it. A good convention for example would be do divide your data into a raw and derived folder.\nCovariance, Correlation and Regression\nSource: https://xkcd.com/552/Last week, we talked about a measure of the spread of a random variable called the variance.\n\\[var(X) = \\frac{\\sum_{i=0}^{n}{(x_i-\\bar x)^2}}{(n-1)}\\]\nToday, we are extending this idea to 2 random variables. Because the normal distribution is so common, we are using two normally distributed variables. For the fun of it, they will have different means and standard deviations (remember: SD is the square-root of the variance).\n\n\nN <- 50\ndf <- tibble(\n  x = rnorm(N, 1, 0.8),\n  y = rnorm(N, 3, 1.2)\n)\n\nm_x <- mean(df$x)\nm_y <- mean(df$y)\n\nggplot(df, aes(x, y)) +\n  geom_vline(xintercept = m_x, alpha = 0.8, color = \"darkviolet\") +\n  geom_hline(yintercept = m_y, alpha = 0.8, color = \"darkviolet\") +\n  geom_point() \n\n\n\n\nWe also added lines for the means of the two random variables. Maybe I should have mentioned this more clearly earlier on, but the general convention in statistics is that random variables are uppercase and concrete values from the distribution have the same letter but lowercase.\nWe now get the covariance of X and Y as:\n\\[cov(X,Y)=\\text{E}\\left[(X-\\text{E}\\left[X\\right])(Y-\\text{E}\\left[Y\\right])\\right]\\]\nThe expected value \\(E[X]\\) is just a fancy way of saying the mean of X. If we asses the contribution of individual points towards the covariance, we can understand it quite intuitively. A point that has a higher x than the mean of X and a higher y than the mean of Y (top right quadrant) will push the covariance towards positive values. Likewise, a point in the bottom left quadrant will have negative differences with the X and Y mean, which cancel each other out to result in a positive covariance. The bottom right and top left quadrants push towards a negative covariance. A mix of positive and negative contributions will result in a covariance with a small absolute value.\nThe covariance has one problem: It will have weird units (X times Y) and the scale is different depending on the random variables. So what we do is standardize it by dividing by both standard deviations and get the correlation coefficient:\n\\[corr(X,Y)=\\frac{cov(X,Y)}{\\sigma_{X}\\sigma_{Y}}\\]\nIt can assume values between -1 and 1. It’s full name is Pearson product-moment correlation coefficient, or pearsons R. We can square it to get \\(R^2\\) (obviously), which indicates the strength of the correlation with values between 0 and 1 independent of the direction. We will meet it again later.\nLet us apply our knowledge to a new dataset.\nIntroducing the Dataset\nThe dplyr package includes and example dataset of Star Wars characters. Unfortunately, it was created a while ago, so the is no baby yoda, but 87 other characters are present.\nI guess it is the baby yoda show now.\n\nstarwars\n\n\n\n\n\n\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"height\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"mass\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"hair_color\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"skin_color\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"eye_color\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"birth_year\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sex\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"gender\"],\"name\":[9],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"homeworld\"],\"name\":[10],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"species\"],\"name\":[11],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"films\"],\"name\":[12],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"vehicles\"],\"name\":[13],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"starships\"],\"name\":[14],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Luke Skywalker\",\"2\":\"172\",\"3\":\"77.0\",\"4\":\"blond\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"19.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [5]>\",\"13\":\"<chr [2]>\",\"14\":\"<chr [2]>\"},{\"1\":\"C-3PO\",\"2\":\"167\",\"3\":\"75.0\",\"4\":\"NA\",\"5\":\"gold\",\"6\":\"yellow\",\"7\":\"112.0\",\"8\":\"none\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Droid\",\"12\":\"<chr [6]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"R2-D2\",\"2\":\"96\",\"3\":\"32.0\",\"4\":\"NA\",\"5\":\"white, blue\",\"6\":\"red\",\"7\":\"33.0\",\"8\":\"none\",\"9\":\"masculine\",\"10\":\"Naboo\",\"11\":\"Droid\",\"12\":\"<chr [7]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Darth Vader\",\"2\":\"202\",\"3\":\"136.0\",\"4\":\"none\",\"5\":\"white\",\"6\":\"yellow\",\"7\":\"41.9\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [4]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Leia Organa\",\"2\":\"150\",\"3\":\"49.0\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"19.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Alderaan\",\"11\":\"Human\",\"12\":\"<chr [5]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Owen Lars\",\"2\":\"178\",\"3\":\"120.0\",\"4\":\"brown, grey\",\"5\":\"light\",\"6\":\"blue\",\"7\":\"52.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Beru Whitesun lars\",\"2\":\"165\",\"3\":\"75.0\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"blue\",\"7\":\"47.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"R5-D4\",\"2\":\"97\",\"3\":\"32.0\",\"4\":\"NA\",\"5\":\"white, red\",\"6\":\"red\",\"7\":\"NA\",\"8\":\"none\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Droid\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Biggs Darklighter\",\"2\":\"183\",\"3\":\"84.0\",\"4\":\"black\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"24.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Obi-Wan Kenobi\",\"2\":\"182\",\"3\":\"77.0\",\"4\":\"auburn, white\",\"5\":\"fair\",\"6\":\"blue-gray\",\"7\":\"57.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Stewjon\",\"11\":\"Human\",\"12\":\"<chr [6]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [5]>\"},{\"1\":\"Anakin Skywalker\",\"2\":\"188\",\"3\":\"84.0\",\"4\":\"blond\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"41.9\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [2]>\",\"14\":\"<chr [3]>\"},{\"1\":\"Wilhuff Tarkin\",\"2\":\"180\",\"3\":\"NA\",\"4\":\"auburn, grey\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"64.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Eriadu\",\"11\":\"Human\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Chewbacca\",\"2\":\"228\",\"3\":\"112.0\",\"4\":\"brown\",\"5\":\"unknown\",\"6\":\"blue\",\"7\":\"200.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Kashyyyk\",\"11\":\"Wookiee\",\"12\":\"<chr [5]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [2]>\"},{\"1\":\"Han Solo\",\"2\":\"180\",\"3\":\"80.0\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"brown\",\"7\":\"29.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Corellia\",\"11\":\"Human\",\"12\":\"<chr [4]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [2]>\"},{\"1\":\"Greedo\",\"2\":\"173\",\"3\":\"74.0\",\"4\":\"NA\",\"5\":\"green\",\"6\":\"black\",\"7\":\"44.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Rodia\",\"11\":\"Rodian\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Jabba Desilijic Tiure\",\"2\":\"175\",\"3\":\"1358.0\",\"4\":\"NA\",\"5\":\"green-tan, brown\",\"6\":\"orange\",\"7\":\"600.0\",\"8\":\"hermaphroditic\",\"9\":\"masculine\",\"10\":\"Nal Hutta\",\"11\":\"Hutt\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Wedge Antilles\",\"2\":\"170\",\"3\":\"77.0\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"hazel\",\"7\":\"21.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Corellia\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Jek Tono Porkins\",\"2\":\"180\",\"3\":\"110.0\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Bestine IV\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Yoda\",\"2\":\"66\",\"3\":\"17.0\",\"4\":\"white\",\"5\":\"green\",\"6\":\"brown\",\"7\":\"896.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Yoda's species\",\"12\":\"<chr [5]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Palpatine\",\"2\":\"170\",\"3\":\"75.0\",\"4\":\"grey\",\"5\":\"pale\",\"6\":\"yellow\",\"7\":\"82.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Naboo\",\"11\":\"Human\",\"12\":\"<chr [5]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Boba Fett\",\"2\":\"183\",\"3\":\"78.2\",\"4\":\"black\",\"5\":\"fair\",\"6\":\"brown\",\"7\":\"31.5\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Kamino\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"IG-88\",\"2\":\"200\",\"3\":\"140.0\",\"4\":\"none\",\"5\":\"metal\",\"6\":\"red\",\"7\":\"15.0\",\"8\":\"none\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Droid\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Bossk\",\"2\":\"190\",\"3\":\"113.0\",\"4\":\"none\",\"5\":\"green\",\"6\":\"red\",\"7\":\"53.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Trandosha\",\"11\":\"Trandoshan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Lando Calrissian\",\"2\":\"177\",\"3\":\"79.0\",\"4\":\"black\",\"5\":\"dark\",\"6\":\"brown\",\"7\":\"31.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Socorro\",\"11\":\"Human\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Lobot\",\"2\":\"175\",\"3\":\"79.0\",\"4\":\"none\",\"5\":\"light\",\"6\":\"blue\",\"7\":\"37.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Bespin\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Ackbar\",\"2\":\"180\",\"3\":\"83.0\",\"4\":\"none\",\"5\":\"brown mottle\",\"6\":\"orange\",\"7\":\"41.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Mon Cala\",\"11\":\"Mon Calamari\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Mon Mothma\",\"2\":\"150\",\"3\":\"NA\",\"4\":\"auburn\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"48.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Chandrila\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Arvel Crynyd\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Wicket Systri Warrick\",\"2\":\"88\",\"3\":\"20.0\",\"4\":\"brown\",\"5\":\"brown\",\"6\":\"brown\",\"7\":\"8.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Endor\",\"11\":\"Ewok\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Nien Nunb\",\"2\":\"160\",\"3\":\"68.0\",\"4\":\"none\",\"5\":\"grey\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Sullust\",\"11\":\"Sullustan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Qui-Gon Jinn\",\"2\":\"193\",\"3\":\"89.0\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"92.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Nute Gunray\",\"2\":\"191\",\"3\":\"90.0\",\"4\":\"none\",\"5\":\"mottled green\",\"6\":\"red\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Cato Neimoidia\",\"11\":\"Neimodian\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Finis Valorum\",\"2\":\"170\",\"3\":\"NA\",\"4\":\"blond\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"91.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Coruscant\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Jar Jar Binks\",\"2\":\"196\",\"3\":\"66.0\",\"4\":\"none\",\"5\":\"orange\",\"6\":\"orange\",\"7\":\"52.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Naboo\",\"11\":\"Gungan\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Roos Tarpals\",\"2\":\"224\",\"3\":\"82.0\",\"4\":\"none\",\"5\":\"grey\",\"6\":\"orange\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Naboo\",\"11\":\"Gungan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Rugor Nass\",\"2\":\"206\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"green\",\"6\":\"orange\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Naboo\",\"11\":\"Gungan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Ric Olié\",\"2\":\"183\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"NA\",\"8\":\"NA\",\"9\":\"NA\",\"10\":\"Naboo\",\"11\":\"NA\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Watto\",\"2\":\"137\",\"3\":\"NA\",\"4\":\"black\",\"5\":\"blue, grey\",\"6\":\"yellow\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Toydaria\",\"11\":\"Toydarian\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Sebulba\",\"2\":\"112\",\"3\":\"40.0\",\"4\":\"none\",\"5\":\"grey, red\",\"6\":\"orange\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Malastare\",\"11\":\"Dug\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Quarsh Panaka\",\"2\":\"183\",\"3\":\"NA\",\"4\":\"black\",\"5\":\"dark\",\"6\":\"brown\",\"7\":\"62.0\",\"8\":\"NA\",\"9\":\"NA\",\"10\":\"Naboo\",\"11\":\"NA\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Shmi Skywalker\",\"2\":\"163\",\"3\":\"NA\",\"4\":\"black\",\"5\":\"fair\",\"6\":\"brown\",\"7\":\"72.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Darth Maul\",\"2\":\"175\",\"3\":\"80.0\",\"4\":\"none\",\"5\":\"red\",\"6\":\"yellow\",\"7\":\"54.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Dathomir\",\"11\":\"Zabrak\",\"12\":\"<chr [1]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Bib Fortuna\",\"2\":\"180\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"pale\",\"6\":\"pink\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Ryloth\",\"11\":\"Twi'lek\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Ayla Secura\",\"2\":\"178\",\"3\":\"55.0\",\"4\":\"none\",\"5\":\"blue\",\"6\":\"hazel\",\"7\":\"48.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Ryloth\",\"11\":\"Twi'lek\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Dud Bolt\",\"2\":\"94\",\"3\":\"45.0\",\"4\":\"none\",\"5\":\"blue, grey\",\"6\":\"yellow\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Vulpter\",\"11\":\"Vulptereen\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Gasgano\",\"2\":\"122\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"white, blue\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Troiken\",\"11\":\"Xexto\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Ben Quadinaros\",\"2\":\"163\",\"3\":\"65.0\",\"4\":\"none\",\"5\":\"grey, green, yellow\",\"6\":\"orange\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tund\",\"11\":\"Toong\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Mace Windu\",\"2\":\"188\",\"3\":\"84.0\",\"4\":\"none\",\"5\":\"dark\",\"6\":\"brown\",\"7\":\"72.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Haruun Kal\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Ki-Adi-Mundi\",\"2\":\"198\",\"3\":\"82.0\",\"4\":\"white\",\"5\":\"pale\",\"6\":\"yellow\",\"7\":\"92.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Cerea\",\"11\":\"Cerean\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Kit Fisto\",\"2\":\"196\",\"3\":\"87.0\",\"4\":\"none\",\"5\":\"green\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Glee Anselm\",\"11\":\"Nautolan\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Eeth Koth\",\"2\":\"171\",\"3\":\"NA\",\"4\":\"black\",\"5\":\"brown\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Iridonia\",\"11\":\"Zabrak\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Adi Gallia\",\"2\":\"184\",\"3\":\"50.0\",\"4\":\"none\",\"5\":\"dark\",\"6\":\"blue\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Coruscant\",\"11\":\"Tholothian\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Saesee Tiin\",\"2\":\"188\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"pale\",\"6\":\"orange\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Iktotch\",\"11\":\"Iktotchi\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Yarael Poof\",\"2\":\"264\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"white\",\"6\":\"yellow\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Quermia\",\"11\":\"Quermian\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Plo Koon\",\"2\":\"188\",\"3\":\"80.0\",\"4\":\"none\",\"5\":\"orange\",\"6\":\"black\",\"7\":\"22.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Dorin\",\"11\":\"Kel Dor\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Mas Amedda\",\"2\":\"196\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"blue\",\"6\":\"blue\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Champala\",\"11\":\"Chagrian\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Gregar Typho\",\"2\":\"185\",\"3\":\"85.0\",\"4\":\"black\",\"5\":\"dark\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Naboo\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Cordé\",\"2\":\"157\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Naboo\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Cliegg Lars\",\"2\":\"183\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"82.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Tatooine\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Poggle the Lesser\",\"2\":\"183\",\"3\":\"80.0\",\"4\":\"none\",\"5\":\"green\",\"6\":\"yellow\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Geonosis\",\"11\":\"Geonosian\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Luminara Unduli\",\"2\":\"170\",\"3\":\"56.2\",\"4\":\"black\",\"5\":\"yellow\",\"6\":\"blue\",\"7\":\"58.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Mirial\",\"11\":\"Mirialan\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Barriss Offee\",\"2\":\"166\",\"3\":\"50.0\",\"4\":\"black\",\"5\":\"yellow\",\"6\":\"blue\",\"7\":\"40.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Mirial\",\"11\":\"Mirialan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Dormé\",\"2\":\"165\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Naboo\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Dooku\",\"2\":\"193\",\"3\":\"80.0\",\"4\":\"white\",\"5\":\"fair\",\"6\":\"brown\",\"7\":\"102.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Serenno\",\"11\":\"Human\",\"12\":\"<chr [2]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Bail Prestor Organa\",\"2\":\"191\",\"3\":\"NA\",\"4\":\"black\",\"5\":\"tan\",\"6\":\"brown\",\"7\":\"67.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Alderaan\",\"11\":\"Human\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Jango Fett\",\"2\":\"183\",\"3\":\"79.0\",\"4\":\"black\",\"5\":\"tan\",\"6\":\"brown\",\"7\":\"66.0\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Concord Dawn\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Zam Wesell\",\"2\":\"168\",\"3\":\"55.0\",\"4\":\"blonde\",\"5\":\"fair, green, yellow\",\"6\":\"yellow\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Zolan\",\"11\":\"Clawdite\",\"12\":\"<chr [1]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Dexter Jettster\",\"2\":\"198\",\"3\":\"102.0\",\"4\":\"none\",\"5\":\"brown\",\"6\":\"yellow\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Ojom\",\"11\":\"Besalisk\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Lama Su\",\"2\":\"229\",\"3\":\"88.0\",\"4\":\"none\",\"5\":\"grey\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Kamino\",\"11\":\"Kaminoan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Taun We\",\"2\":\"213\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"grey\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Kamino\",\"11\":\"Kaminoan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Jocasta Nu\",\"2\":\"167\",\"3\":\"NA\",\"4\":\"white\",\"5\":\"fair\",\"6\":\"blue\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Coruscant\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Ratts Tyerell\",\"2\":\"79\",\"3\":\"15.0\",\"4\":\"none\",\"5\":\"grey, blue\",\"6\":\"unknown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Aleen Minor\",\"11\":\"Aleena\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"R4-P17\",\"2\":\"96\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"silver, red\",\"6\":\"red, blue\",\"7\":\"NA\",\"8\":\"none\",\"9\":\"feminine\",\"10\":\"NA\",\"11\":\"Droid\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Wat Tambor\",\"2\":\"193\",\"3\":\"48.0\",\"4\":\"none\",\"5\":\"green, grey\",\"6\":\"unknown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Skako\",\"11\":\"Skakoan\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"San Hill\",\"2\":\"191\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"grey\",\"6\":\"gold\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Muunilinst\",\"11\":\"Muun\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Shaak Ti\",\"2\":\"178\",\"3\":\"57.0\",\"4\":\"none\",\"5\":\"red, blue, white\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Shili\",\"11\":\"Togruta\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Grievous\",\"2\":\"216\",\"3\":\"159.0\",\"4\":\"none\",\"5\":\"brown, white\",\"6\":\"green, yellow\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Kalee\",\"11\":\"Kaleesh\",\"12\":\"<chr [1]>\",\"13\":\"<chr [1]>\",\"14\":\"<chr [1]>\"},{\"1\":\"Tarfful\",\"2\":\"234\",\"3\":\"136.0\",\"4\":\"brown\",\"5\":\"brown\",\"6\":\"blue\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Kashyyyk\",\"11\":\"Wookiee\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Raymus Antilles\",\"2\":\"188\",\"3\":\"79.0\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Alderaan\",\"11\":\"Human\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Sly Moore\",\"2\":\"178\",\"3\":\"48.0\",\"4\":\"none\",\"5\":\"pale\",\"6\":\"white\",\"7\":\"NA\",\"8\":\"NA\",\"9\":\"NA\",\"10\":\"Umbara\",\"11\":\"NA\",\"12\":\"<chr [2]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Tion Medon\",\"2\":\"206\",\"3\":\"80.0\",\"4\":\"none\",\"5\":\"grey\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"Utapau\",\"11\":\"Pau'an\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Finn\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"black\",\"5\":\"dark\",\"6\":\"dark\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Rey\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"hazel\",\"7\":\"NA\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"NA\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Poe Dameron\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"NA\",\"8\":\"male\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Human\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [1]>\"},{\"1\":\"BB8\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"none\",\"5\":\"none\",\"6\":\"black\",\"7\":\"NA\",\"8\":\"none\",\"9\":\"masculine\",\"10\":\"NA\",\"11\":\"Droid\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Captain Phasma\",\"2\":\"NA\",\"3\":\"NA\",\"4\":\"unknown\",\"5\":\"unknown\",\"6\":\"unknown\",\"7\":\"NA\",\"8\":\"NA\",\"9\":\"NA\",\"10\":\"NA\",\"11\":\"NA\",\"12\":\"<chr [1]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [0]>\"},{\"1\":\"Padmé Amidala\",\"2\":\"165\",\"3\":\"45.0\",\"4\":\"brown\",\"5\":\"light\",\"6\":\"brown\",\"7\":\"46.0\",\"8\":\"female\",\"9\":\"feminine\",\"10\":\"Naboo\",\"11\":\"Human\",\"12\":\"<chr [3]>\",\"13\":\"<chr [0]>\",\"14\":\"<chr [3]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nLet’s look at some correlations:\nPearson vs. Spearman (not a Boxing Match)\nTo compute pearsons correlation, we use the cor function in R. Instead of filtering out NA values beforehand, which would result in a correlation of NA, we can use use = \"complete.obs\" to ignore the NA is in the computation.\n\n\npearson <- cor(starwars$mass, starwars$height, use = \"complete.obs\")\npearson\n\n\n[1] 0.1338842\n\nThere is another way we can specify which features to correlate. corr also takes a matrix or data frame as it’s x argument instead of x and y:\n\n\ncorr_matrix <- cor(starwars[c(\"mass\", \"height\")], use = \"complete.obs\")\ncorr_matrix\n\n\n            mass    height\nmass   1.0000000 0.1338842\nheight 0.1338842 1.0000000\n\nThis is known as a correlation matrix, and we can create it for more than two features, as long as all features are numeric (after all, what is the correlation between 1,4 and “cat” “dog?”). If you need this for your analysis, it will be handy to know how to convert this matrix to a tibble:\n\n\nas_tibble(corr_matrix)\n\n\n# A tibble: 2 x 2\n   mass height\n  <dbl>  <dbl>\n1 1      0.134\n2 0.134  1    \n\nLooses the information about the rownames, because tibbles have no rownames. However, we can tell as_tibble to create a new column out of what previously where rownames.\n\n\nas_tibble(corr_matrix, rownames = \"feature1\")\n\n\n# A tibble: 2 x 3\n  feature1  mass height\n  <chr>    <dbl>  <dbl>\n1 mass     1      0.134\n2 height   0.134  1    \n\nNow we could even turn it into a tidy format to make a heatmap:\n\n\nas_tibble(corr_matrix, rownames = \"feature1\") %>% \n  pivot_longer(-feature1, names_to = \"feature2\", values_to = \"corr\") %>% \n  ggplot(aes(feature1, feature2, fill = corr, label = corr)) +\n  geom_raster() +\n  geom_text(color = \"white\")\n\n\n\n\nIf you are working a log with correlations, it is certainly worth checking out the corrr package from the tidymodels framework: https://corrr.tidymodels.org/\nApart from cor, there is also cor.test, which gives more information.\n\n\ncor_test <- cor.test(starwars$mass, starwars$height, use = \"complete.obs\")\ncor_test\n\n\n\n    Pearson's product-moment correlation\n\ndata:  starwars$mass and starwars$height\nt = 1.02, df = 57, p-value = 0.312\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1265364  0.3770395\nsample estimates:\n      cor \n0.1338842 \n\nIf we so fancy, we can use broom to turn the test output into a tidy format as well:\n\n\nbroom::tidy(cor_test)\n\n\n\n\n\n\n{\"columns\":[{\"label\":[\"estimate\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"statistic\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"p.value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"parameter\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"method\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"alternative\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"0.1338842\",\"2\":\"1.019986\",\"3\":\"0.3120447\",\"4\":\"57\",\"5\":\"-0.1265364\",\"6\":\"0.3770395\",\"7\":\"Pearson's product-moment correlation\",\"8\":\"two.sided\",\"_row\":\"cor\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nWhen I first did this I was surprised that the correlation was so low. We are after all talking about height and mass, which I assumed to be highly correlated. Let us look at the data to see what is going on.\n\n\nlabel_text <- glue(\"Pearson correlation: {round(pearson, 2)}\")\n\njabba <- filter(starwars, str_detect(name, \"Jabba\"))\njabba_text <- list(x = 1100, y = 120)\n\nstarwars %>% \n  ggplot(aes(mass, height)) +\n  geom_point() +\n  annotate(geom = \"text\", x = 500, y = 75, label = label_text,\n           hjust = 0) +\n  annotate(geom = \"curve\",\n           x = jabba_text$x, y = jabba_text$y,\n           xend = jabba$mass, yend = jabba$height,\n           curvature = .3,\n           arrow = arrow(length = unit(2, \"mm\"))) +\n  annotate(geom = \"text\",\n           x = jabba_text$x,\n           y = jabba_text$y, label = \"Jabba the Hutt\",\n           hjust = 1.1) +\n  xlim(0, 1500) +\n  labs(x = \"mass [kg]\",\n       y = \"height [cm]\")\n\n\n\n\nThis is the culprit! We have a massive outlier, in all senses of the word “massive.” At this point it is fair to say, Jabba the Hutt could use some workout to loose weight. Luckily, there is another method to asses correlation. Spearman’s method is more resistant to outliers, because the data is transformed into ranks first, which negates the massive effect of outliers. Visually, this is what the points look like after rank transformation:\n\n\nspearman <- cor(starwars$mass, starwars$height,\n                method = \"spearman\",\n                use = \"complete.obs\")\n\nlabel_text <- glue(\"Spearman rank correlation: {round(spearman, 2)}\")\n\nstarwars %>% \n  mutate(mass = rank(mass),\n         height = rank(height)) %>% \n  ggplot(aes(mass, height)) +\n  geom_point() +\n  annotate(geom = \"text\", x = 0, y = 75, label = label_text,\n           hjust = 0) +\n  labs(x = \"rank(mass)\",\n       y = \"rank(height)\")\n\n\n\n\nLinear Regression\nFinally, linear regression is a related concept, because both correlation and linear regression quantify the strength of a linear relationship. However, there are key differences. When we fit a linear model like y ~ a + b * x, there is no error in x. We assume x is something that is fixed, like the temperature we set for an experiment or the dosage we used. Y on the other hand is a random variable. In cov(X,Y) and cor(X,Y), X and Y are both random variables, usually things we observed, not set ourselves.\nWhile the correlation coefficient is symmetrical and translation-scale-invariant, meaning \\(corr(X,Y)=corr(Y,X)\\) and \\(corr(X,Y)=corr(X * a +b,Y * c + d)\\), linear models are not!\nIn the data folder we find the IMDB ratings for 10 Star Wars movies (plus more features).\n\n\nstarwars_movies <- read_rds(\"data/starwars_movies.rds\")\nstarwars_movies\n\n\n# A tibble: 10 x 25\n   Title Rated Released   Runtime Genre Director Writer Actors Plot \n   <chr> <chr> <date>     <chr>   <chr> <chr>    <chr>  <chr>  <chr>\n 1 Star… PG    1977-05-25 121 min Acti… George … Georg… Mark … Luke…\n 2 Star… PG    1980-06-20 124 min Acti… Irvin K… Leigh… Mark … Afte…\n 3 Star… PG    1983-05-25 131 min Acti… Richard… Lawre… Mark … Afte…\n 4 Star… PG-13 2015-12-18 138 min Acti… J.J. Ab… Lawre… Harri… As a…\n 5 Star… PG    1999-05-19 136 min Acti… George … Georg… Liam … Two …\n 6 Star… PG-13 2005-05-19 140 min Acti… George … Georg… Ewan … Thre…\n 7 Star… PG    2002-05-16 142 min Acti… George … Georg… Ewan … Ten …\n 8 Star… PG-13 2017-12-15 152 min Acti… Rian Jo… Rian … Mark … Rey …\n 9 Rogu… PG-13 2016-12-16 133 min Acti… Gareth … Chris… Felic… The …\n10 Star… PG-13 2019-12-20 141 min Acti… J.J. Ab… Chris… Carri… The …\n# … with 16 more variables: Language <chr>, Country <chr>,\n#   Awards <chr>, Poster <chr>, Ratings <list>, Metascore <chr>,\n#   imdbRating <dbl>, imdbVotes <dbl>, imdbID <chr>, Type <chr>,\n#   DVD <date>, BoxOffice <chr>, Production <chr>, Website <chr>,\n#   Response <chr>, year <dbl>\n\nWe can fit a linear model to see if the production year has an effect on the rating.\n\n\nmodel <- lm(imdbRating ~ year, data = starwars_movies)\n\nbroom::augment(model) %>%\n  ggplot(aes(year, imdbRating)) +\n  geom_smooth(method = \"lm\", alpha = 0.3, color = \"darkviolet\") +\n  geom_point() +\n  geom_segment(aes(x = year, y = .fitted,\n                   xend = year, yend = imdbRating),\n               alpha = 0.4)\n\n\n\n\nWhat I added here as gray segments are the so called residuals. They are what makes linear regression work. It’s full name is Ordinary Least Squares and the squares in question are the squares of these residuals, the word least indicates that these squares are minimized in order to find the best fit line.\n\nI am yet to encounter Extraordinary Least Squares but I am sure someone in machine learning will soon need more words to fuel the hype and it will become a thing.\n\n\n\nbroom::tidy(model)\n\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic p.value\n  <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)  74.7      28.9         2.59  0.0322\n2 year         -0.0335    0.0144     -2.33  0.0484\n\nLooks like every year decreases the estimated rating by 0.03.\nOne thing however is the same between correlation and linear regression, and that is the \\(R^2\\) value we get from both calculations:\n\n\nsummary(model)\n\n\n\nCall:\nlm(formula = imdbRating ~ year, data = starwars_movies)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.1171 -0.2631  0.1152  0.3955  0.8195 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)  \n(Intercept) 74.65951   28.85148   2.588   0.0322 *\nyear        -0.03354    0.01442  -2.326   0.0484 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7006 on 8 degrees of freedom\nMultiple R-squared:  0.4035,    Adjusted R-squared:  0.329 \nF-statistic: 5.412 on 1 and 8 DF,  p-value: 0.04843\n\nWe can interpret \\(R^2\\) as the fraction of the variance of the response variable y that can be explained by the predictor x.\nNon-linear Least Squares\nSo far, we only properly dealt with linear relationships and now it is time to get non-linear. We will be creating a mechanistically driven predictive model, so we have a formula of which we want to adjust the parameters so that it fits our data.\nLet’s take classical Michaelis-Menten-Kinetics There is a dataset for enzyme reaction rates included in R. But we convert it from a dataframe to a tibble so that it prints nicer:\n\n\nas_tibble(Puromycin)\n\n\n# A tibble: 23 x 3\n    conc  rate state  \n   <dbl> <dbl> <fct>  \n 1  0.02    76 treated\n 2  0.02    47 treated\n 3  0.06    97 treated\n 4  0.06   107 treated\n 5  0.11   123 treated\n 6  0.11   139 treated\n 7  0.22   159 treated\n 8  0.22   152 treated\n 9  0.56   191 treated\n10  0.56   201 treated\n# … with 13 more rows\n\nThe initial rate \\(v_0\\) of the an enzymatic reaction was measured for a control and a sample treated with puromycin at different substrate concentrations. For every concentration we have two replicates except for one missing replicate. We can make this explicit so that we can keep track of the replicates:\n\n\npuro <- as_tibble(Puromycin) %>% \n  group_by(conc, state) %>% \n  mutate(rep = 1:n()) %>% \n  ungroup()\n\n\n\nNow we can plot the individual curves.\n\n\npuro %>% \n  ggplot(aes(conc, rate,\n             group = paste(rep, state),\n             color = state)) +\n  geom_line() +\n  geom_point()\n\n\n\n\nFrom our Biochemistry studies, we know that we can express the rate depending on the concentration with the following formula:\n\\[rate=\\frac{(Vm * conc)}{(K + conc)}\\]\nTo make it easier to work with, let’s turn it into a function:\n\n\nrate <- function(conc, Vm, K) {\n  (Vm * conc) / (K + conc)\n}\n\n\n\nLet’s pick some arbitrary starting values. For example, we see that the maximal velocity could be around 200. We also know that K is the concentration at which the half-maximal velocity is reached.\n\n\npuro %>% \n  ggplot(aes(conc, rate,\n             color = state)) +\n  geom_line(aes(group = paste(rep, state))) +\n  geom_point() +\n  geom_function(fun = ~ rate(conc = .x, Vm = 200, K = 0.2),\n                color = \"black\")\n\n\n\n\ngeom_function expects a function of x or an anonymous function where the first argument is the values on the x-axis, so this is what we did. Well, I bet we can do better than guessing the function! What R can do for us is the same it did for linear least squares and that is minimizing the distance of our curve to the datapoints. This is the job of the nls function, which stands for Nonlinear Least Squares.\n\n\nmodel <- nls(rate ~ rate(conc, Vm, K),\n    data = puro,\n    subset = state == \"treated\",\n    start = list(K = 0.1, Vm = 200))\n\nmodel\n\n\nNonlinear regression model\n  model: rate ~ rate(conc, Vm, K)\n   data: puro\n        K        Vm \n  0.06412 212.68363 \n residual sum-of-squares: 1195\n\nNumber of iterations to convergence: 6 \nAchieved convergence tolerance: 6.108e-06\n\nNlS needs starting values, so we use any guess that isn’t too far off. If it is completely wrong, the model doesn’t know in which direction it should move the parameters to improve the fit and we get an error like this: Error in nls(rate ~ rate(conc, Vm, K), data = puro, subset = state ==  : singular gradient\n\nFor this special case, R also has a self-starting model. I won’t go into it because it is not as useful as the general concept of fitting arbitry functions, but you can check out SSmicmen for a model that estimes the starting values automatically.\n\nAdditionally, nls takes an argument subset, which works just like the dplyr verb filter so that we can fit the model on a subset of the data without having to create it beforehand.\nThere are now multiple ways of displaying our model. With broom::augments we can add the predictions to the original data (which is just the treated state):\n\n\nbroom::augment(model) %>% \n  ggplot(aes(conc, rate)) +\n  geom_point() + \n  geom_line(aes(y = .fitted))\n\n\n\n\nBut this has the obvious disadvantage of only adding a point (or a nick in the line) where we previously had datapoints. We have the parameters and the complete function, so we can calculate an arbitrary amount of values in between to make a smooth function.\n\n\nbroom::tidy(model)\n\n\n# A tibble: 2 x 5\n  term  estimate std.error statistic  p.value\n  <chr>    <dbl>     <dbl>     <dbl>    <dbl>\n1 K       0.0641   0.00828      7.74 1.57e- 5\n2 Vm    213.       6.95        30.6  3.24e-11\n\nSo we could pull the estimates of K and Vm out with broom and then use them in our function. Or, we make use of the predict function. It takes a model and some new data and generates the predicions. If we don’t give it new data, we just get predictions for the data that we used to fit the model.\n\n\npredict(model)\n\n\n [1]  50.56606  50.56606 102.81102 102.81102 134.36165 134.36165\n [7] 164.68470 164.68470 190.83289 190.83289 200.96878 200.96878\n\n\n\npredictions <- tibble(\n  conc = seq(0, 1, by = 0.01),\n  rate = predict(model, newdata = list(conc =  conc))\n)\n\npuro %>% \n  filter(state == \"treated\") %>% \n  ggplot(aes(conc, rate)) +\n  geom_point() +\n  geom_line(data = predictions, color = \"darkviolet\")\n\n\n\n\nWe can also use a combination of this and geom_function, which I think feel pretty natural once you are comfortable with writing functions on the fly.\n\n\npuro %>% \n  filter(state == \"treated\") %>% \n  ggplot(aes(conc, rate)) +\n  geom_point() +\n  geom_function(fun = ~ predict(model,\n                                newdata = list(conc = .x)),\n                color = \"darkviolet\")\n\n\n\n\nNow, what if we want to fit the model for both states? We can resort back to our trusty purrr package like we did in an earlier lecture.\n\n\npuro_models <- puro %>% \n  nest(-state) %>% \n  mutate(\n    model = map(data, ~ nls(rate ~ rate(conc, Vm, K), data = .x,\n                            start = list(Vm = 200, K = 0.1))),\n    tidy = map(model, broom::tidy),\n    glance = map(model, broom::glance)\n  )\n\npuro_models\n\n\n# A tibble: 2 x 5\n  state     data              model  tidy             glance          \n  <fct>     <list>            <list> <list>           <list>          \n1 treated   <tibble [12 × 3]> <nls>  <tibble [2 × 5]> <tibble [1 × 9]>\n2 untreated <tibble [11 × 3]> <nls>  <tibble [2 × 5]> <tibble [1 × 9]>\n\nNow we can inspect the estimated parameters with ease:\n\n\npuro_models %>% \n  unnest(tidy)\n\n\n# A tibble: 4 x 9\n  state data  model term  estimate std.error statistic  p.value glance\n  <fct> <lis> <lis> <chr>    <dbl>     <dbl>     <dbl>    <dbl> <list>\n1 trea… <tib… <nls> Vm    213.       6.95        30.6  3.24e-11 <tibb…\n2 trea… <tib… <nls> K       0.0641   0.00828      7.74 1.57e- 5 <tibb…\n3 untr… <tib… <nls> Vm    160.       6.48        24.7  1.38e- 9 <tibb…\n4 untr… <tib… <nls> K       0.0477   0.00778      6.13 1.73e- 4 <tibb…\n\nAnd check how the models performed. Unfortunately, I can’t get into these performance metrics because time is short.\n\n\npuro_models %>% \n  unnest(glance)\n\n\n# A tibble: 2 x 13\n  state data  model tidy  sigma isConv  finTol logLik   AIC   BIC\n  <fct> <lis> <lis> <lis> <dbl> <lgl>    <dbl>  <dbl> <dbl> <dbl>\n1 trea… <tib… <nls> <tib… 10.9  TRUE   6.09e-6  -44.6  95.3  96.7\n2 untr… <tib… <nls> <tib…  9.77 TRUE   2.31e-6  -39.6  85.2  86.4\n# … with 3 more variables: deviance <dbl>, df.residual <int>,\n#   nobs <int>\n\nNow, we could use the estimated parameters to or the models with predict to plot all (well, both) model fit lines over the original data, but there is an easier way. geom_smooth can take “nls” as a method as well, we just need to make sure to pass the correct arguments. And it can be confusing, because when we are specifying the formula in geom_smooth, it always needs to be a formula of y ~ x, whereas in the normal nls we did earlier, we specified the variables in terms of their actual names (rate and conc).\n\n\npuro %>% \n  ggplot(aes(conc, rate, color = state)) +\n  geom_point() +\n  geom_smooth(\n    method       = \"nls\",\n    formula      = y ~ rate(conc = x, Vm = Vm, K = K),\n    method.args  = list(start = list(Vm = 200, K = 0.1)),\n    se           = FALSE\n  )\n\n\n\n\nWe also need se = FALSE, because by default R would try to plot a confidence interval around the fit-line like it did for the linear model, but nls doesn’t return one, so we would get an error.\nThe unfortunate thing about this method is that we end up fitting the model twice, once to get the estimated parameters and the likes for ourselves and a second time in ggplot to display the fitted lines. But in most cases this is not a problem, because the model is not very computationally expensive.\nExercises\nThe Datasaurus Dozen\nThe Datasaurus Dozen (Matejka and Fitzmaurice 2017) is a dataset crafted to illustrate certain concepts. It can be accessed from R via the datasauRus package.\n\n\ndatasauRus::datasaurus_dozen\n\n\n\nExplore the dataset before looking at the publication above (it contains spoilers…):\nIt actually contains 13 different datasets, denoted by the column dataset, in one tibble. What are the means for x and y for the different datasets? What are the standard deviations for x and y for the different datasets? What are the correlations coefficients for the different datasets? I bet you notice a pattern by now.\nNow create one (or multiple) scatterplots of the data. What do you notice? what conclusions do you draw from this observation?\n\nThere is another dataset in the package to illustrate a different point:\n\n\ndatasauRus::box_plots\n\n\n\nFirst, turn it into a tidy format, much like the datasaurus_dozen tibble.\nNow, visualize the distributions of the values for the 5 different groups. Try out different versions of your plot until you are satisfied, but be sure to also include a boxplot and compare it to your approaches.\nPreparing for the Christmas Special\nWhat datasets would you find interesting? Maybe you already have some data you collected or maybe just an idea (in the second case I might also do an episode on getting data from the internet via webscarping), or maybe there is a dataset in the tidytuesday repository that speaks to you: https://github.com/rfordatascience/tidytuesday\n\n\n\nMatejka, Justin, and George Fitzmaurice. 2017. “The Datasaurus Dozen - Same Stats, Different Graphs | Autodesk Research.” https://doi.org/http://dx.doi.org/10.1145/3025453.3025912.\n\n\n“Survivorship Bias.” 2020. Wikipedia, December.\n\n\nWald, Abraham. 1980. “A Reprint of ’A Method of Estimating Plane Vulnerability Based on Damage of Survivors.” CRC-432. CENTER FOR NAVAL ANALYSES ALEXANDRIA VA OPERATIONS EVALUATION GROUP.\n\n\nZiemann, Mark, Yotam Eren, and Assam El-Osta. 2016. “Gene Name Errors Are Widespread in the Scientific Literature.” Genome Biology 17 (1): 177. https://doi.org/10.1186/s13059-016-1044-7.\n\n\n\n\n",
    "preview": "lectures/lecture7/img/survivorship-bias.png",
    "last_modified": "2020-12-14T11:21:20+01:00",
    "input_file": "lecture7.utf8.md",
    "preview_width": 1427,
    "preview_height": 1063
  },
  {
    "path": "lectures/lecture6/",
    "title": "Lecture 6",
    "description": "... in which we explore continuous distributions with spotify data,\nfind out about the central limit theorem and related statistical tests\nand become N-dimensional whale sharks.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-12-07",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nSome Preparation\nSidenote on Reproducible Environments with renv\n\nSay Hello to Spotify Data\nVisualising Continuous Distributions\nSummary Statistics…\n… or: How to Lie with Graphs\n\nGraphic Devices, Fonts and the ggplot Book\nggplot book\nGraphics Devics\n\nThe Normal Distribution and the Central Limit Theorem\nLog-normality\n\nThe T-Distribution\nStudent’s T-Test\nWilcoxon rank-sum test\nDirection of Testing\nConfidence Intervals\n\nChrunching Dimensions with Dimensionality Reduction: PCA\n\nExercises\nThe Plotty Horror Picture Show\nTake a Sad Plot and Make it Better\nStats Time\n\nResources\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen. Press ? for a list of keyboard shortcuts.\n\n\nknitr::include_url(\"slides6.html\")\n\n\n\n\n\nScript\n\nDisclaimer: As I wrote this lecture, the scope gradually increased because there was always the next thing I wanted to include. And it was kind of hard to stop. The exercises today will very unrestrictive, so that you can explore in your own tempo and so that we have more time for questions on Friday.\n\nSome Preparation\nToday, we will explore the process of modeling and look at different types of models. In part, we will do so using the tidymodels framework. The tidymodels framework extends the tidyverse with specialized tools for all kinds of modeling tasks that fit neatly in with all the tools we already know. Go ahead and install them with:\n\n\ninstall.packages(\"tidymodels\")\n\n\n\nSidenote on Reproducible Environments with renv\nAt this point, we have installed quite a lot of packages. On one hand, this is great fun because the extend what we can do and make tedious tasks fun. On the other hand, every package that we add introduces what is called a dependency. If a user doesn’t have the package installed, our analysis will not run. If we are feeling experimental and use functions from packages that are under active development and might change in the future, we will run into trouble when we update the package. But never updating anything ever again is no fun! I will show you, how to get the best of both worlds: All the packages and functions that your heart desires while maintaining complete reproducibility. This is to make sure that you can come back to your old projects 2 years from now and they still just run as they did at the time.\n \nThis solution is a package called renv. The idea is as follows: Instead of installing all your packages into one place, where you can only have one version of a package at a time, renv installs packages locally in your project folder. It also meticulously writes down the version numbers of all the packages you installed and keeps a cache, so it will not copy the same version twice.\nIt is an R package like any other, so first, we install it with:\n\n\ninstall.packages(\"renv\")\n\n\n\nThen, in our RStudio project in the R console, we initialize the project to use renv with:\n\n\nrenv::init()\n\n\n\nThis does a couple of things. It creates a file named .Rprofile, in which it writes source(\"renv/activate.R\"). The R-profile file is run automatically every time you start a R session in this folder, so it makes sure renv is active every time you open the project. It also creates a folder called renv. This is the where it will install packages you want to use in the project. The most important file is the renv.lock file. You can have a look at it, it is just a text file with all the packages and their exact versions.\nYou notice, that after initializing renv, we have no packages, so for example we can’t load the tidyverse as usual. We will have to install it again! However, in this case it should be fairly fast, because renv knows that it was already installed globally so it simply copies the files, which is fast. After having installed a new package, we call:\n\n\nrenv::snapshot()\n\n\n\nRenv tells us, what we changed in our environment and after we confirm, it notes down the changes.\nNot it is also really easy to collaborate with other people. Because after we send them our project folder, all they have to do is run:\n\n\nrenv::restore()\n\n\n\nTo install all packages noted down in the lockfile. We can also use this ourselves if we installed a few to many packages or did an update we regret and want to go back to what is written in the lockfile.\nFinally, renv also provides functions to update or install new packages. They work like install.packages, but a bit more versatile. For example, let me show you the different locations from which we can install packages.\nThe main location is CRAN (The Comprehensive R Archive Network). This is also from where you installed R itself. R packages on there are subject to certain standards and usually stable and tested.\nWe can also install packages directly from the source code other people uploaded. GitHub is a platform where you can upload code and track changes to it. A lot of times, you can find the current developement version of an R package, or packages that are not yet on CRAN on GitHub.\nrenv can install packages from GitHub as well, for example let us say, we want to test out the latest version of the purrr package to give feedback to the developers.\nhttps://github.com/tidyverse/purrr here it says:\n\n\n# ...\n# Or the the development version from GitHub:\n# install.packages(\"devtools\")\ndevtools::install_github(\"tidyverse/purrr\")\n\n\n\nWell, we don’t need devtools for this, because renv can do this with the regular install function:\n\nrenv::install(\"tidyverse/purrr\")\n``` = <- \n\nGiving  it just a package name installs a package from CRAN,\na pattern of `\"username/packgename\"` installs from GitHub.\nNow, back to the actual topic of today!\n\nAfter having initialized `renv` we need to install\nthe packages that we need for the project even\nif we already have them in our global package cache,\njust so that `renv` knows about them.\n\n## All models are wrong, but some are useful\n\nSuch goes the quote but statistician George Box.\n\n> »All models are wrong, but some are useful«\n> — George Box\n\nWhat this means is that any model is but a simplification\nof reality and must always omit details.\nNo model can depict the complete underlying\nreality. However, models are useful, and to\nunderstand what they are useful for, we must first look at\nthe different types of models out there.\n\n### Types of Models\n\nThe [tidymodels book](https://www.tmwr.org/software-modeling.html#types-of-models)\nnames three types of models,\nwhere any particular model can fall into multiple\ncategories at once:\n\n<aside>\n<a href=\"https://www.tidymodels.org/\">\n<img src=\"img/tidymodels.svg\">\n<\/a>\n<\/aside>\n\n1. **Descriptive Models**\\ \n  are purely used to describe the underlying\n  data to make patters easier to see.\n  When we add a smooth line to a ggplot\n  with `geom_smooth`, the default\n  method is a so called LOESS curve, which\n  stands for Locally Estimated Scatterplot\n  Smoothing. It does produce insights \n  by revealing patterns to us,\n  but by itself can not be used \n  e.g. to make predictions. It is\n  just a pretty looking smooth line.\n  \n<aside>\n\n\n\n\n\nInferential Models  are designed to test hypothesis or make decisions. They rely heavily on our assumptions about the data (e.g. what probability distribution the populations follows) and will be most likely encountered by you to answer research questions. They are the models that typically produce a p-value, which you compare to a threshold like we did last week\nPredictive Models  are designed to process the data we have and make predictions about some response variable upon receiving new data. When done correctly, we also hold out on some of the data that our model never gets to see, until it is time to evaluate and test how it performs on unseen data. Depending on how much we know (or want to know) about the underlying processes, we differentiate between mechanistic models like fitting a physically meaningful function to data and empirically driven models, which are mainly concerned with creating good predictions, no matter the underlying mechanism.\nWe will now explore different examples. First, let me introduce our dataset for today:\nSay Hello to Spotify Data\nI created a playlist on spotify, which is quite diverse so that we can look at a range of features. You can even listen to it here while you do the exercises if you want. I am doing so, as I write this. The cool thing about spotify is, that they have an API, an Application Interface. APIs are ways for computer programs to talk to each other. So while we use the spotify app to look up songs, computers use the API to talk to the spotify server. And because R has a rich ecosystem of packages, someone already wrote a package that allows R to talk to this API: spotifyr.\nIf you check out the R folder in this lecture, you can see how I downloaded and processed that data about the playlist. Note that the script will not work for you right away, because you first need to register with spotify as a developer and then get a so called token, like a username and password in one long text, to be allowed to send bots their way. You probably just want to download the data from my github repository the usual way.\nLet’s have a look, shall we?\n\n\nlibrary(tidyverse)\n\n\n\n\n\nsongs <- read_csv(\"data/spotify_playlist.csv\")\n\n\n\nWe can get a quick overview of all columns with:\n\n\nglimpse(songs, width = 60)\n\n\nRows: 347\nColumns: 17\n$ track_name        <chr> \"Africa\", \"Take on Me\", \"Wake M…\n$ track_artists     <chr> \"TOTO\", \"a-ha\", \"Wham!\", \"Elton…\n$ danceability      <dbl> 0.671, 0.573, 0.620, 0.504, 0.3…\n$ energy            <dbl> 0.373, 0.902, 0.573, 0.904, 0.8…\n$ key               <dbl> 9, 6, 0, 6, 8, 10, 2, 4, 6, 4, …\n$ loudness          <dbl> -18.064, -7.638, -11.893, -6.86…\n$ mode              <dbl> 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0…\n$ speechiness       <dbl> 0.0323, 0.0540, 0.0423, 0.1790,…\n$ acousticness      <dbl> 0.257000, 0.018000, 0.271000, 0…\n$ instrumentalness  <dbl> 8.01e-05, 1.25e-03, 0.00e+00, 1…\n$ liveness          <dbl> 0.0481, 0.0928, 0.0607, 0.1400,…\n$ valence           <dbl> 0.732, 0.876, 0.897, 0.772, 0.6…\n$ tempo             <dbl> 92.718, 84.412, 81.548, 176.808…\n$ time_signature    <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4…\n$ track_duration_ms <dbl> 295893, 225280, 231333, 183440,…\n$ track_popularity  <dbl> 83, 83, 79, 79, 59, 61, 71, 83,…\n$ track_year        <dbl> 1982, 1985, 1984, 1983, 2020, 2…\n\nFinally some decent numbers! Not just these measly discrete values we had last week. For each song in the playlist, we get the artist, the year it arrived and a number of features like how danceable, how loud or fast the song is. You can easily imagine spotify using these numbers to suggest new songs based on the features of those that you have listened to. And in fact, we are going to lay the foundations for such an algorithm today.\nVisualising Continuous Distributions\nWhen dealing with a continuous distribution, like we have for a lot of our features in the spotify songs dataset, there are always multiple ways to represent the same data. First, we just look at the numbers. We will use the valence values for our songs:\n\n\nhead(songs$valence)\n\n\n[1] 0.732 0.876 0.897 0.772 0.668 0.324\n\nNotice anything interesting in the numbers? I don’t either. Our brain is way better suited for looking at graphical representations, so: To the ggplot cave!\n\n\nsongs %>% \n  ggplot(aes(x = factor(0), valence)) +\n  geom_point()\n\n\n\n\nThis is kind of hard to see, because points overlap. We can get a better picture of the distribution by using transparency or a bit of jitter:\n\n\nsongs %>% \n  ggplot(aes(x = factor(0), valence)) +\n  geom_jitter(width = 0.05)\n\n\n\n\nUsing a histogram, we can put the points into bins and get a plot similar to what we got for discrete values. Note that the plot is flipped on it’s side now.\n\n\nsongs %>% \n  ggplot(aes(valence)) +\n  geom_histogram()\n\n\n\n\nAnd we might want to play around with the bin size to get a better feel for the distribution. Another way is to apply a smoothing function and estimate the density of points along a continuous range, even in places where we originally had no points:\n\n\nsongs %>% \n  ggplot(aes(valence)) +\n  geom_density(fill = \"darkblue\", alpha = 0.3)\n\n\n\n\nBoth of these plots can be misleading, if the original number of points is quite small, and in most cases, we are better off, showing the actual individual points as well. This is the reason, why the first plots I did where vertical, because there is a cool way of showing both the points and the distribution, while still having space to show multiple distributions next to each other. Imagine taking the density plot, turning it 90 degrees and then mirroring through the middle. What we get is a so called violin plot. To overlay the points on top, we will use something a little more predictable than jitter this time: From the ggbeeswarm package I present: geom_quasirandom.\n\n\nsongs %>% \n  ggplot(aes(factor(0), valence)) +\n  geom_violin(fill = \"darkblue\", alpha = 0.3) +\n  ggbeeswarm::geom_quasirandom(alpha = 0.6)\n\n\n\n\nThis is cool, because now we can easily compare two different distributions next to each other and still see all the individual points. For example, we might ask:\n“Do songs in major cord have a higher valence than songs in minor cord in our dataset?”\n\n\nsongs %>% \n  ggplot(aes(factor(mode), valence)) +\n  geom_violin(fill = \"darkblue\", alpha = 0.3) +\n  ggbeeswarm::geom_quasirandom(alpha = 0.6) +\n  labs(x = \"Mode (Minor/Major)\")\n\n\n\n\n\nNote: This jittering only works, because the feature on the x-axis is discrete. If it where continuous, we would be changing the data by jittering on the x-axis.\n\nWe might also want to add summaries like the mean for each group to the plot with an additional marker. This leads us to the general concept of summary statistics. There is a number of them, and they can be quite useful to, well, summarise a complex distribution. But they can also be very misleading, as can any simplification be.\nSummary Statistics…\nLet us start by considering different things we can say about our distribution in one number. First, we might look at the range of our numbers, the maximum and minimum. We will do this per mode, so we can compare the values.\n\n\nsongs %>% \n  group_by(mode) %>% \n  summarise(\n    max = max(valence),\n    min = min(valence)\n  )\n\n\n# A tibble: 2 x 3\n   mode   max    min\n  <dbl> <dbl>  <dbl>\n1     0 0.877 0.0271\n2     1 0.965 0.0176\n\nIt appears the valence can assume values between 0 and 1. A shortcut for this is the range function:\n\n\nrange(songs$valence)\n\n\n[1] 0.0176 0.9650\n\nNext, we want to know the centers of the points. There are different notions of being at the center of the distribution. The mean or average is the sum of all values divided by the number of values. The median is what we call a quantile, a point that divides a distribution in equally sized parts, specifically such that 50% values are below and 50% are above the median.\n\n\nsongs %>% \n  group_by(mode) %>% \n  summarise(\n    mean(valence),\n    median(valence)\n  )\n\n\n# A tibble: 2 x 3\n   mode `mean(valence)` `median(valence)`\n  <dbl>           <dbl>             <dbl>\n1     0           0.399             0.395\n2     1           0.299             0.258\n\nThe median is just one of the many percentiles we can think of. If we display the 50th as well as the 25th and 75th percentile on one plot, we get what is called a boxplot:\n\n\nsongs %>% \n  add_row(mode = 1, valence = 1.2) %>% \n  ggplot(aes(factor(mode), valence)) +\n  geom_boxplot(fill = \"darkblue\",\n               alpha = 0.3,\n               outlier.alpha = 1) +\n  annotate(geom = \"curve\", x = 1.8, y = 1.25, xend = 1.95, yend = 1.19,\n           curvature = .3, arrow = arrow(length = unit(2, \"mm\"))) +\n  annotate(\"text\", x = 1.75, y = 1.25,\n           label = \"outlier\\n (that I added because there where none)\",\n           vjust = 0.5, hjust = 1) +\n  coord_cartesian(clip = \"off\")\n\n\n\n\nThe “whiskers” of the box extend to 1.5 times the box size or to the last data point, whichever makes smaller whiskers. Points that are more extreme than the whiskers are labeled outliers by the boxplot and usually displayed as their own points. Like with the violin plot, we also have the option to plot the original un-summarized points on top. In this case, we need to make sure to change the outlier color for the boxplot to NA, because otherwise we are plotting them twice:\n\n\nsongs %>% \n  add_row(mode = 1, valence = 1.2) %>% \n  ggplot(aes(factor(mode), valence)) +\n  geom_boxplot(fill = \"darkblue\", alpha = 0.3,\n               outlier.color =  NA) +\n  ggbeeswarm::geom_quasirandom(alpha = 0.6)\n\n\n\n\nThis hints at one downside of boxplots: The box is a very prominent focus point of the plot, but by definition, it only contains 50% of all datapoints. The rest is delegated to thin whiskers.\nFinally, we want to know, how far the values scatter around their means and the potential population mean. This is encompassed in two closely related measures: the variance and the standard deviation.\nFor illustrative purposes, we can plot all datapoints for e.g the valence in the order in which they appear in the data and add a line for the mean.\n\n\nsongs %>%\n  mutate(index = 1:n()) %>% \n  ggplot(aes(index, valence)) +\n  geom_segment(aes(y = mean(songs$valence),\n                   yend = mean(songs$valence),\n                   x = 0,\n                   xend = length(songs$valence))) +\n  geom_segment(aes(xend = index, yend = mean(songs$valence)),\n               color = \"darkred\", alpha = 0.6) +\n  annotate(\"text\", x = length(songs$valence) + 13, y = mean(songs$valence),\n           label = \"Mean\") +\n  geom_point()\n\n\n\n\n\nThe variance is the expected value of the squared deviation of a random variable from its mean.\n\nIn other words: Take the distance of all points to the mean and sum them (add all red lines in the plot above together) and then divide by \\(n-1\\).\n\\[var(X) = \\frac{\\sum_{i=0}^{n}{(x_i-\\bar x)^2}}{(n-1)}\\]\n“Hang on!” I hear you saying: “Why \\(n-1\\)?” And it is an excellent question. The first statement talked about an expected value. (One example of an expected value is the mean, which is the expected value of… well, the values). And indeed, and expected value often has the term \\(1/n\\). But the statement was talking about the expected value (of the squared deviation) for the whole population. We can only use the uncorrected version when we have the whole population (e.g. all songs that ever existed) and want to talk about that population. But usually, all we have is a sample, from which we want to draw conclusions about the population. But when we are using the sample to estimate the variance of the population, it will be biased. We can correct for this bias by using \\(n-1\\) instead of \\(n\\). This is known as Bessel’s correction. I am yet to come by a really intuitive explanation, but here is one idea: The thing we are dividing by is not necessarily the sample size any time we want to try to calculate the expected value of an estimator, it just happens to be the sample size in a bunch of cases. What the term really represents here is the degrees of freedom (DF) of the deviations. DFs can be thought of as the number of independent things. The degrees of freedom are \\(n\\) reduced by \\(1\\), because if we know the mean of a sample (we use it in our calculation), once we know all but \\(1\\) of the individual values, the last value is automatically known and thus doesn’t count towards the degrees of freedom.\nNext up: The Standard Deviation (SD) is the square root of the variance. Which is more commonly used on error bars, because the square root inverts the squaring that was done to get the variance. So we are back in the dimensions of the data.\n\\[\\sigma_X=\\sqrt{var(X)}\\]\nFinally, we have the Standard Error of the Mean, sometimes only called Standard Error (SEM, SE). It is also used very commonly in error bars. The reason for a lot of people to favor it over the SD might just be, that it is smaller, but they have distinct use-cases.\n\\[SEM=\\sigma / \\sqrt{n}\\]\nWe take the standard deviation and divide it by the square-root of \\(n\\). Imagine this: We actually have the whole population available. Like for example all penguins on earth. And then we repeatedly take samples of size \\(n\\). The means of these individual samples will vary, so it will have it’s own mean, standard deviation and variance. The standard error is the standard deviation of these means. So it is a measure of how far the means of repeated samples scatter around the true population mean. However, we don’t usually have the whole population! Measuring some property of all penguins in the world takes a long time, and running an experiment in the lab for all cells that exist and will ever exist takes an infinite amount of time. This is probably more than our research grant money can finance. So, instead, the Standard Error of the Mean used the standard deviation of our sample in the formula above. It is our best estimate for the standard deviation of the whole population. So, when you are trying so make inferences about the mean of the whole population based on your sample, it makes sense to also give the SEM as a way of quantifying the uncertainty.\nWhile R has functions for sd, mean and var, there is not built in function for the sem, but we can easily write one ourselves:\n\n\nsem <- function(x) sd(x)/sqrt(length(x))\n\n\n\n… or: How to Lie with Graphs\nHowever, be very wary of simple bar graphs with error bars; there is a lot that can be misleading about them.\n\n\nsongs %>% \n  group_by(mode) %>%\n  summarise(across(speechiness, list(m = mean, sd = sd, sem = sem))) %>% \n  ggplot(aes(factor(mode), speechiness_m, fill = factor(mode))) +\n  geom_errorbar(aes(ymin = speechiness_m - speechiness_sem,\n                    ymax = speechiness_m + speechiness_sem,\n                    color = factor(mode)),\n                size = 1.3, width = 0.3, show.legend = FALSE) +\n  geom_col(size = 1.3, show.legend = FALSE) +\n  coord_cartesian(ylim = c(0.06, 0.08)) +\n  scale_fill_manual(values = c(\"#1f6293\", \"#323232\")) +\n  scale_color_manual(values = c(\"#1f6293\", \"#323232\")) +\n  labs(title = \"Don't Do This at Home!\",\n       y = \"Speechiness\",\n       x = \"Mode (Minor / Major)\") +\n  theme(\n    plot.title = element_text(size = 44, family = \"Daubmark\",\n                              color = \"darkred\")\n  )\n\n\n\n\nWhen people say “The y-axis has to include 0,” this is the reason for it. It is no always true, when there is another sensible baseline that is not 0, but especially for barplots not having the y-axis start at 0 is about the most misleading thing you can do. The main reason for this is that humans perceive the height of the bars via their area, and this is no longer proportional when the bars don’t start at 0. This plot also makes no indication of the type of error-bars used or the sample size in each group. It uses the speechiness feature, but it hides the actual distribution behind just 2 numbers (mean and SEM) per group:\n\n\nsongs %>% \n  ggplot(aes(speechiness, color = factor(mode),\n             fill = factor(mode))) +\n  geom_density(alpha = 0.3) \n\n\n\n\nSo the next time you see a barplot ask the question:\n(“Artwork by @allison_horst” 2020)I hope you can take some inspiration from this chapter and now have the vocabulary to know where to look when it comes to your own data.\nGraphic Devices, Fonts and the ggplot Book\nI had a lot of fun making the graphs for today’s session. Naturally, there will be a couple of questions as to how they where done. There is two pointers I want to give you.\nggplot book\nFirstly, for all things ggplot, the third edition of the ggplot book is currently being worked on by three absolute legends of their craft (“Welcome | Ggplot2,” n.d.; Wickham 2016). Hadley Wickham is the author of the original ggplot and ggplot2 package, Danielle Navaro makes amazing artwork with and teaches ggplot and Thomas Lin Pedersen is the current maintainer of ggplot2 and constantly makes cool features for it. The under-development book is already available online for free: https://ggplot2-book.org/.\nGraphics Devics\nSecondly, we need to briefly talk about a concept we have only brushed by: graphics devices are to R what your printer is to your computer. When we create a plot in R, it starts out as mere numbers, but something has to turn these numbers into pixels (in the case of raster-images) or vectors (in the case of vector images; you might know svg or pdf files. Sorry, but these are not the vectors in R but rather descriptions of lines). This is the job ob the graphics device. When we use the ggsave function for example, it figures out what to use based on the file extension, but we can also specify it manually. I am mentioning this here, because in the plot I just showed you, I used a different font than the default. This is something that can be incredibly tricky for graphics devices, because fonts are handled differently on every operating system. Luckily, it is about to get way easier, because Thomas Lin Pedersen is working on another package, a graphics device, that is both really fast and works well with fonts. You can check the current development version here: https://ragg.r-lib.org/\nThe Normal Distribution and the Central Limit Theorem\nThere are many different distributions out there. Luckily, one of them is quite special and can be used in a multitude of settings. It is the harmlessly named Normal Distribution. R has the usual functions for it (density, probability, quantile, random).\n\n\ntibble(x = seq(-3, 3, 0.01)) %>% \n  ggplot(aes(x)) +\n  geom_function(fun = dnorm) +\n  stat_function(geom = \"area\", fun = dnorm,\n              fill = \"darkblue\", alpha = 0.3) +\n  labs(y = \"density\", title = \"Normal Distribution Density\")\n\ntibble(x = seq(-3, 3, 0.01)) %>% \n  ggplot(aes(x)) +\n  geom_function(fun = pnorm) +\n  labs(y = \"probability\", title = \"Cummulative Probability\")\n\n\n\n\nNow, why is is distribution so special?\n\nThe Central Limit Theorem (CLT) states that the sample mean of a sufficiently large number of independent random variables is approximately normally distributed. The larger the sample, the better the approximation.\n\nFor a great visualization of the central limit theorem, check out this interactive tutorial by Seeing Theory.\nBecause a lot of values we measure are actually the sum of many random processes, distributions of things we measure can often be approximated with a normal distribution.\nWe can visually test if some values follow the normal distribution by using a quantile-quantile plot, which plots the quantiles of our sample against where the quantiles should be on the normal distribution. A straight line means it is perfectly normal.\n\n\nvalence <- songs %>% filter(mode == 1) %>% pull(valence)\nqqnorm(valence)\nqqline(valence)\n\n\n\n\nThe values close to the mean are pretty normal, but the tails of the distribution stray further from the normal distribution. There are way more very small and very large values than would be expected from a normal distribution.\nLog-normality\nThere is one thing that comes up a lot in biological data: because a lot of processes in biology are reliant on signal cascades, they tend to be the result of many multiplicative effects, rather than additive effects, as would be required for the Central Limit Theorem. As a result, they are not distributed normally, but rather log-normally, because taking the logarithm of all values transforms multiplicative effects into additive effects!\nThe T-Distribution\nThe CLT is only valid for large sample sizes. For smaller sample sizes, the distribution of means has fatter tails than a normal distribution. This is why for most statistical tests, we use the t-distribution instead of the normal distribution. As the degrees of freedom get higher, the t-distribution approaches the normal distribution.\n\n\nbase <- ggplot() + xlim(-5, 5)\n\nbase +\n  geom_function(aes(colour = \"normal\"), fun = dnorm, size = 1.2) +\n  geom_function(aes(colour = \"t, df = 1\"), fun = dt, args = list(df = 1), size = 1.2) +\n  geom_function(aes(colour = \"t, df = 3\"), fun = dt, args = list(df = 3), size = 1.2) +\n  geom_function(aes(colour = \"t, df = 30\"), fun = dt, args = list(df = 30), size = 1.2) +\n  guides(color = guide_legend(title = \"\"))\n\n\n\n\nFigure 1: t-distribution in red, normal distribution in black.\n\n\n\nRemember the valence plot by mode?\n\n\nsongs %>% \n  ggplot(aes(factor(mode), valence)) +\n  geom_violin(fill = \"darkblue\", alpha = 0.3) +\n  ggbeeswarm::geom_quasirandom(alpha = 0.6)\n\n\n\n\nFor demonstrative purposes I am going to cheat a little and pretend that both distributions are approximatley normal so that we can look at some hypothesis tests:\nStudent’s T-Test\nThe first test is called student’s t-test. “Student” was the pseudonym of it’s inventor. And the “t” stands for the t-distribution. We can use it to test the null hypothesis, that two samples come from the same (approximately normal) distribution\n\n\nt.test(valence ~ mode, data = songs)\n\n\n\n    Welch Two Sample t-test\n\ndata:  valence by mode\nt = 3.9287, df = 328.06, p-value = 0.0001042\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.04999479 0.15027858\nsample estimates:\nmean in group 0 mean in group 1 \n      0.3988897       0.2987530 \n\nWe receive a p-value for the probability to get a difference in means as extreme or more extreme as observed in our samples. Here, the p-value is small, not because the difference is very large, but because we have a lot of values.\nTests, that rely on the assumption of normality are called parametric tests, but when this assumption can not be met, we need non-parametric tests.\nWilcoxon rank-sum test\nThe Wilcoxon rank-sum test, or Mann–Whitney U test, is one of these. I get’s around the assumption of normality by transforming the data into ranks first. i.e. all points (independent of group) are ordered and their values replaced by their position in the ordering (their rank). If we think of the t-test as testing for a difference in means, we can think of the Wilcoxon rank-sum test as testing for a difference in medians.\nFor example, let us test for a difference in speechiness for the two modes (Minor/Major):\n\n\nwilcox.test(speechiness ~ mode, data = songs)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  speechiness by mode\nW = 17918, p-value = 0.0003848\nalternative hypothesis: true location shift is not equal to 0\n\nDirection of Testing\nBoth tests have the argument alternative, which can be any of c(\"two.sided\", \"less\", \"greater\"). This is the direction of our alternative hypothesis. Are we testing, for x being greater or less than y? Or are we testing for a difference in any direction (the default)? Having a hypothesis about the direction beforehand will result in smaller p-values (half of the two-sided ones), but you need to have this hypothesis before looking at the data, and especially not after running e.g. the two sided test and then deciding, that you want a smaller p-value! This is not how p-values work.\nIf you are unsure about how to tell the functions, which of two groups is supposed to be greater or lesser, you can also supply the data as x and y instead of using the formula interface as I did above:\n\n\nspeechiness_minor <- songs %>% filter(mode == 0) %>% pull(speechiness)\nspeechiness_major <- songs %>% filter(mode == 1) %>% pull(speechiness)\nwilcox.test(speechiness_minor, speechiness_major)\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  speechiness_minor and speechiness_major\nW = 17918, p-value = 0.0003848\nalternative hypothesis: true location shift is not equal to 0\n\nIf we save the result of the test, we can inspect the object further and extract information from it:\n\n\nw_test <- wilcox.test(speechiness_minor, speechiness_major)\nw_test$p.value\n\n\n[1] 0.0003848449\n\nConfidence Intervals\nThe t.test on a lonely sample can also be used to create confidence intervals around a mean. In short for example a 95% confidence interval is the range in which we would expect the mean of a sample to fall in 95% of cases when we repeat an experiment an infinite amount of times. These confidence intervals are also sometimes used as error bars in plots.\n\n\nvalence_minor <- songs %>% filter(mode == 0) %>% pull(valence)\ntest <- t.test(valence_minor)\ntest\n\n\n\n    One Sample t-test\n\ndata:  valence_minor\nt = 21.508, df = 144, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.3622315 0.4355478\nsample estimates:\nmean of x \n0.3988897 \n\n\n\ntest$conf.int\n\n\n[1] 0.3622315 0.4355478\nattr(,\"conf.level\")\n[1] 0.95\n\nLastly for today, we are going a bit out of scope. We are leaving the realm of looking at individual features and try to condense all the information into as little space as possible.\nChrunching Dimensions with Dimensionality Reduction: PCA\nThe general notion of Dimensionality Reduction is to take all the features that we have and construct new features from them, so that we can represent our data with fewer features while loosing little information.\nFor example, when two features are highly correlated i.e. one changes when the other does, we might be better off replacing them with a single new feature, that goes along the axis of maximum variance between the two. A number along this line accounts for most of the variance in these points, and the rest can be accounted for by a number describing the distance to that line (a perpendicular axis), which is less important than the first axis we found.\n\n\nsongs %>% \n  ggplot(aes(x = energy,\n             y = loudness,\n             label = track_name)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\nImagine you are whale shark\n(“Artwork by @allison_horst” 2020)And want to orient your mouth in such a way that you can eat the greatest amount of krill in one sweep\n(“Artwork by @allison_horst” 2020)This is your first principal component. The second is perpendicular to the first. This is a throwback to “Math for Natural Scientists” and liner algebra, we are defining a new coordinate system here.\nBut whale sharks swim in 3 dimensions, not 2, and our data has even more dimensions, with one features being represented as one dimension.\n\nIt can be quite hard for humans to imaging being an N-dimensional whale shark.\n\nBut R and tidymodels has us covered:\n\n\nlibrary(tidymodels)\n\n\n\nPCA is not a model in itself, but rather a data preprocessing step that generates new features (the principal components), which we can later use for other models. But today, we will do just the preprocessing by itself.\nIn tidymodels, preprocessing is done by defining a recipe:\n\n\nsongs_rec <- recipe( ~ ., data = songs) %>% \n  update_role(track_name, track_artists, new_role = \"id\") %>% \n  step_normalize(all_predictors()) %>%\n  step_pca(all_predictors())\n\n\n\nWe then take the recipe and prepare it.\n\n\nsongs_prep <- prep(songs_rec)\nsongs_prep\n\n\nData Recipe\n\nInputs:\n\n      role #variables\n        id          2\n predictor         15\n\nTraining data contained 347 data points and no missing data.\n\nOperations:\n\nCentering and scaling for danceability, energy, key, ... [trained]\nPCA extraction with danceability, energy, key, ... [trained]\n\nFrom this prepared recipe, we extract a tidy form of the step we care about (usually the last one) to see, what happened to our data.\n\n\nsongs_compontents <- tidy(songs_prep, 2)\nsongs_compontents\n\n\n# A tibble: 225 x 4\n   terms              value component id       \n   <chr>              <dbl> <chr>     <chr>    \n 1 danceability     -0.300  PC1       pca_2cVIF\n 2 energy           -0.376  PC1       pca_2cVIF\n 3 key              -0.0498 PC1       pca_2cVIF\n 4 loudness         -0.373  PC1       pca_2cVIF\n 5 mode              0.153  PC1       pca_2cVIF\n 6 speechiness      -0.146  PC1       pca_2cVIF\n 7 acousticness      0.364  PC1       pca_2cVIF\n 8 instrumentalness  0.359  PC1       pca_2cVIF\n 9 liveness         -0.123  PC1       pca_2cVIF\n10 valence          -0.318  PC1       pca_2cVIF\n# … with 215 more rows\n\nThe original features where replace by Principal Components that explain most of the variance. We can see, which features ended up contributing to which components:\n\n\nsongs_compontents %>% \n  mutate(terms = tidytext::reorder_within(terms, by = value, within = component)) %>% \n  filter(component %in% paste0(\"PC\", 1:3)) %>% \n  ggplot(aes(value, terms, fill = value > 0)) +\n  geom_col() +\n  facet_wrap(~ component, scales = \"free\") +\n  ggthemes::scale_fill_colorblind() +\n  guides(fill = \"none\") +\n  tidytext::scale_y_reordered()\n\n\n\n\nWe had to use 2 little helper functions from the tidytext package to properly order the bar. The first component is largely comprised of a high acousticness and instrumentalness and less energy in the positive direction. So we expect e.g. classical music to be very high on that axis. A high value on the second component means a high danceability while being low in tempo.\nWe can now explore, how the data looks like in these new dimensions. We do so, by baking the prepared recipe. We set new_data to NULL, because we want to use the data that was already used to prepare the recipe (i.e. calculate the principal components).\n\n\nsongs_baked <- bake(songs_prep, new_data = NULL)\nsongs_baked %>% rmarkdown::paged_table()\n\n\n\n\n{\"columns\":[{\"label\":[\"track_name\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"track_artists\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"PC1\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"PC2\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"PC3\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"PC4\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"PC5\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Africa\",\"2\":\"TOTO\",\"3\":\"-0.41262647\",\"4\":\"-3.0023608356\",\"5\":\"-1.0408577134\",\"6\":\"-1.420060380\",\"7\":\"-1.321381665\"},{\"1\":\"Take on Me\",\"2\":\"a-ha\",\"3\":\"-2.31217097\",\"4\":\"-2.3074216533\",\"5\":\"-0.8626261786\",\"6\":\"-0.914062026\",\"7\":\"-2.015860999\"},{\"1\":\"Wake Me Up Before You Go-Go\",\"2\":\"Wham!\",\"3\":\"-1.03232858\",\"4\":\"-2.9846711184\",\"5\":\"-2.6273337451\",\"6\":\"0.071577348\",\"7\":\"-0.798310136\"},{\"1\":\"I'm Still Standing\",\"2\":\"Elton John\",\"3\":\"-2.08223201\",\"4\":\"-0.0126256135\",\"5\":\"-2.7516847581\",\"6\":\"-1.434921061\",\"7\":\"-1.634459629\"},{\"1\":\"Wolf Totem (feat. Jacoby Shaddix of Papa Roach)\",\"2\":\"The HU;Papa Roach\",\"3\":\"-2.43418141\",\"4\":\"2.7371780138\",\"5\":\"0.4972086978\",\"6\":\"2.301374327\",\"7\":\"-0.931506591\"},{\"1\":\"Yuve Yuve Yu\",\"2\":\"The HU\",\"3\":\"-1.66797778\",\"4\":\"-0.0529048602\",\"5\":\"1.4100151974\",\"6\":\"-0.781166473\",\"7\":\"-0.357632500\"},{\"1\":\"The Search\",\"2\":\"NF\",\"3\":\"-1.96605081\",\"4\":\"0.6558530841\",\"5\":\"-1.7028563506\",\"6\":\"-1.256348680\",\"7\":\"1.896763670\"},{\"1\":\"Stressed Out\",\"2\":\"Twenty One Pilots\",\"3\":\"-2.79519264\",\"4\":\"0.2321587685\",\"5\":\"-0.8832262585\",\"6\":\"-1.223966413\",\"7\":\"-0.243697298\"},{\"1\":\"Ride\",\"2\":\"Twenty One Pilots\",\"3\":\"-1.81130734\",\"4\":\"-1.8935029621\",\"5\":\"0.0784024211\",\"6\":\"0.139974457\",\"7\":\"1.026002368\"},{\"1\":\"Heathens\",\"2\":\"Twenty One Pilots\",\"3\":\"-1.61250666\",\"4\":\"-1.7067522505\",\"5\":\"0.3568674885\",\"6\":\"-0.182938746\",\"7\":\"0.032852603\"},{\"1\":\"Jumpsuit\",\"2\":\"Twenty One Pilots\",\"3\":\"-1.44119737\",\"4\":\"-0.1694991871\",\"5\":\"1.7528574615\",\"6\":\"-0.575751092\",\"7\":\"-0.630206409\"},{\"1\":\"Chlorine\",\"2\":\"Twenty One Pilots\",\"3\":\"-1.68114959\",\"4\":\"-0.0873081408\",\"5\":\"1.9512751045\",\"6\":\"0.209886969\",\"7\":\"-0.624460754\"},{\"1\":\"Diggy Diggy Hole\",\"2\":\"Wind Rose\",\"3\":\"-1.17960761\",\"4\":\"0.2714433292\",\"5\":\"0.3628028744\",\"6\":\"0.358909335\",\"7\":\"0.444662713\"},{\"1\":\"Feel Invincible\",\"2\":\"Skillet\",\"3\":\"-2.45446306\",\"4\":\"0.2767979208\",\"5\":\"0.3498428761\",\"6\":\"0.324838037\",\"7\":\"-0.516430242\"},{\"1\":\"Monster\",\"2\":\"STARSET\",\"3\":\"-1.11156062\",\"4\":\"-0.6785493533\",\"5\":\"-0.1011626211\",\"6\":\"0.487557907\",\"7\":\"0.205588654\"},{\"1\":\"Through The Fire And Flames\",\"2\":\"DragonForce\",\"3\":\"-1.33632350\",\"4\":\"2.7285070652\",\"5\":\"-1.2644068048\",\"6\":\"1.526601442\",\"7\":\"-1.971861168\"},{\"1\":\"When Legends Rise\",\"2\":\"Godsmack\",\"3\":\"-2.44367897\",\"4\":\"1.3240557459\",\"5\":\"-0.7744564962\",\"6\":\"-1.660242119\",\"7\":\"0.627736999\"},{\"1\":\"Legend\",\"2\":\"The Score\",\"3\":\"-1.60666232\",\"4\":\"-1.8330161011\",\"5\":\"-0.5416273498\",\"6\":\"0.759189793\",\"7\":\"1.314191887\"},{\"1\":\"For the Glory\",\"2\":\"All Good Things\",\"3\":\"-2.21847014\",\"4\":\"0.2078427205\",\"5\":\"-0.5156347241\",\"6\":\"0.165255378\",\"7\":\"-0.231942193\"},{\"1\":\"Eye Of The Storm\",\"2\":\"Watt White\",\"3\":\"-2.31356421\",\"4\":\"-0.4931819033\",\"5\":\"-0.1265461498\",\"6\":\"0.441017130\",\"7\":\"0.052531795\"},{\"1\":\"Last to Leave\",\"2\":\"Humblebee\",\"3\":\"-0.16751028\",\"4\":\"0.3943233541\",\"5\":\"0.2879131250\",\"6\":\"-0.114739306\",\"7\":\"-0.551468860\"},{\"1\":\"Pigments\",\"2\":\"Norabel\",\"3\":\"1.13069669\",\"4\":\"-1.2578605732\",\"5\":\"-0.2878980143\",\"6\":\"0.134787311\",\"7\":\"1.369366524\"},{\"1\":\"Cognac Carousel\",\"2\":\"A P O L L O\",\"3\":\"-1.40439586\",\"4\":\"-0.0117296672\",\"5\":\"1.2292210715\",\"6\":\"-1.622864586\",\"7\":\"-0.457607207\"},{\"1\":\"Eclipse\",\"2\":\"Carter Fox\",\"3\":\"-0.34696689\",\"4\":\"-0.5064478868\",\"5\":\"0.0061184454\",\"6\":\"-0.365065050\",\"7\":\"0.697694574\"},{\"1\":\"High Noon\",\"2\":\"Toby Tranter\",\"3\":\"-1.14878797\",\"4\":\"0.6706060254\",\"5\":\"1.4318169750\",\"6\":\"-0.772579648\",\"7\":\"-1.011831808\"},{\"1\":\"Heliolingus\",\"2\":\"Ooyy\",\"3\":\"-0.18943610\",\"4\":\"0.8094302435\",\"5\":\"-1.0224531426\",\"6\":\"1.060579358\",\"7\":\"0.576512079\"},{\"1\":\"Sense\",\"2\":\"Cushy\",\"3\":\"-0.39282649\",\"4\":\"-0.4114804330\",\"5\":\"0.7064161525\",\"6\":\"0.056136522\",\"7\":\"-0.064274404\"},{\"1\":\"Recenseo\",\"2\":\"Humblebee\",\"3\":\"-1.37864096\",\"4\":\"-0.1384184188\",\"5\":\"1.0781115763\",\"6\":\"-0.385573772\",\"7\":\"-0.423698041\"},{\"1\":\"Autumn Mournings to Winter Nights\",\"2\":\"DJ DENZ The Rooster\",\"3\":\"0.36754190\",\"4\":\"-0.9257227228\",\"5\":\"2.2922928143\",\"6\":\"-0.967323588\",\"7\":\"-0.173946808\"},{\"1\":\"Neon Gravestones\",\"2\":\"Twenty One Pilots\",\"3\":\"-1.11638542\",\"4\":\"0.9036782592\",\"5\":\"0.2942036484\",\"6\":\"-2.952480583\",\"7\":\"0.143669588\"},{\"1\":\"Radioactive\",\"2\":\"Imagine Dragons\",\"3\":\"-1.80561035\",\"4\":\"1.6680185998\",\"5\":\"0.8048991688\",\"6\":\"2.010074371\",\"7\":\"-1.004455668\"},{\"1\":\"Leave a Light On\",\"2\":\"Tom Walker\",\"3\":\"-1.32485408\",\"4\":\"-1.2612255340\",\"5\":\"-0.0571893433\",\"6\":\"-0.074092150\",\"7\":\"1.477322797\"},{\"1\":\"No Good\",\"2\":\"KALEO\",\"3\":\"-2.10052383\",\"4\":\"0.5056383541\",\"5\":\"-0.0797544533\",\"6\":\"-0.861517815\",\"7\":\"0.878779970\"},{\"1\":\"New Shoes\",\"2\":\"Paolo Nutini\",\"3\":\"-1.93783782\",\"4\":\"-0.6892118938\",\"5\":\"-0.9001958911\",\"6\":\"-1.155740332\",\"7\":\"-0.025057024\"},{\"1\":\"The Fear\",\"2\":\"The Score\",\"3\":\"-1.67419902\",\"4\":\"0.6780181747\",\"5\":\"1.1605774743\",\"6\":\"0.799686094\",\"7\":\"-0.873807001\"},{\"1\":\"Flowers\",\"2\":\"Other People's Heartache;Bastille;Rationale;James Arthur\",\"3\":\"-0.95693856\",\"4\":\"1.4989056051\",\"5\":\"-1.3464199848\",\"6\":\"0.449895728\",\"7\":\"0.536375355\"},{\"1\":\"Pinkish\",\"2\":\"Gerard Way\",\"3\":\"-0.50241425\",\"4\":\"1.9452812039\",\"5\":\"-1.5307875786\",\"6\":\"0.542730685\",\"7\":\"0.703426906\"},{\"1\":\"Blood Runs Red\",\"2\":\"78rpm\",\"3\":\"-2.12342214\",\"4\":\"0.9072789541\",\"5\":\"0.4962059449\",\"6\":\"0.767497358\",\"7\":\"-0.781097847\"},{\"1\":\"Weight of the World\",\"2\":\"Battle Tapes\",\"3\":\"-1.15791969\",\"4\":\"0.3265681567\",\"5\":\"-1.2992352188\",\"6\":\"0.697978183\",\"7\":\"1.296140465\"},{\"1\":\"Kerosene Dreams\",\"2\":\"X Ambassadors\",\"3\":\"-0.34907631\",\"4\":\"-0.8301707520\",\"5\":\"-0.5418976804\",\"6\":\"1.161681000\",\"7\":\"1.103537094\"},{\"1\":\"The Run and Go\",\"2\":\"Twenty One Pilots\",\"3\":\"-1.53526679\",\"4\":\"-1.3054994912\",\"5\":\"1.4599839410\",\"6\":\"-0.914705403\",\"7\":\"-0.444934070\"},{\"1\":\"Way down We Go\",\"2\":\"KALEO\",\"3\":\"-1.19568491\",\"4\":\"0.4869775253\",\"5\":\"0.6160803077\",\"6\":\"-1.700841167\",\"7\":\"-0.628579636\"},{\"1\":\"Judgement Day\",\"2\":\"Blues Saraceno\",\"3\":\"0.13650250\",\"4\":\"-1.1191657674\",\"5\":\"1.6421047416\",\"6\":\"-0.684522696\",\"7\":\"-0.257713561\"},{\"1\":\"Cha-Ching (Till We Grow Older)\",\"2\":\"Imagine Dragons\",\"3\":\"-0.78055171\",\"4\":\"-0.6228292863\",\"5\":\"0.0185411565\",\"6\":\"-0.022025712\",\"7\":\"0.463781798\"},{\"1\":\"Flame\",\"2\":\"Sundara Karma\",\"3\":\"-1.38976535\",\"4\":\"-0.3037322656\",\"5\":\"0.5351734382\",\"6\":\"0.881770269\",\"7\":\"0.509336042\"},{\"1\":\"How to Save a Life\",\"2\":\"The Fray\",\"3\":\"-1.45629102\",\"4\":\"-1.3859101757\",\"5\":\"0.1506532746\",\"6\":\"-0.630731165\",\"7\":\"-0.142467596\"},{\"1\":\"Automobile\",\"2\":\"KALEO\",\"3\":\"-0.90785571\",\"4\":\"-0.2467355303\",\"5\":\"-0.5990897140\",\"6\":\"1.384756299\",\"7\":\"0.359713599\"},{\"1\":\"Cornfield Chase\",\"2\":\"Hans Zimmer\",\"3\":\"2.75888187\",\"4\":\"-0.3108144866\",\"5\":\"1.6772822487\",\"6\":\"-0.903077023\",\"7\":\"-0.664916204\"},{\"1\":\"Fringe Society\",\"2\":\"Sami Matar\",\"3\":\"0.85078691\",\"4\":\"-1.0445136331\",\"5\":\"1.1597243053\",\"6\":\"0.318858012\",\"7\":\"0.738688920\"},{\"1\":\"Synthblade\",\"2\":\"Cyberpunkers\",\"3\":\"-1.40241065\",\"4\":\"0.9877327965\",\"5\":\"-0.0083604176\",\"6\":\"-1.317133094\",\"7\":\"0.567119270\"},{\"1\":\"Blood Magic\",\"2\":\"Daniel Deluxe\",\"3\":\"-0.66690418\",\"4\":\"-1.0227272744\",\"5\":\"-0.4352748763\",\"6\":\"0.934386261\",\"7\":\"1.053273533\"},{\"1\":\"Pacific Coast Highway\",\"2\":\"Fukkk Offf\",\"3\":\"-0.82418516\",\"4\":\"0.4637631586\",\"5\":\"1.3447520355\",\"6\":\"1.472755192\",\"7\":\"-0.031191372\"},{\"1\":\"Blade Runner - End Titles\",\"2\":\"Vangelis\",\"3\":\"0.61619308\",\"4\":\"-0.4731808173\",\"5\":\"0.0883925080\",\"6\":\"0.334123039\",\"7\":\"-2.190476998\"},{\"1\":\"All My Heroes\",\"2\":\"Naeleck;Sarah Rebecca\",\"3\":\"-0.21614226\",\"4\":\"-1.1345433834\",\"5\":\"1.5457463044\",\"6\":\"-0.355708917\",\"7\":\"1.040369993\"},{\"1\":\"66 MHz\",\"2\":\"Waveshaper\",\"3\":\"-1.27530459\",\"4\":\"0.5049954679\",\"5\":\"1.7156800187\",\"6\":\"0.487986650\",\"7\":\"-0.870375548\"},{\"1\":\"Synthetic\",\"2\":\"Duke & Jones\",\"3\":\"1.51545349\",\"4\":\"-0.7316042433\",\"5\":\"-0.4353954534\",\"6\":\"0.771602616\",\"7\":\"0.989837799\"},{\"1\":\"Holograms\",\"2\":\"M83\",\"3\":\"3.55028495\",\"4\":\"-0.2315672097\",\"5\":\"-0.1690918277\",\"6\":\"-0.542152533\",\"7\":\"0.936464249\"},{\"1\":\"Cyberworld\",\"2\":\"Boisterous Pop\",\"3\":\"-1.14723468\",\"4\":\"-0.3411149351\",\"5\":\"1.2178459795\",\"6\":\"0.403181890\",\"7\":\"-0.242851244\"},{\"1\":\"Burn Out\",\"2\":\"Imagine Dragons\",\"3\":\"-1.20058943\",\"4\":\"-0.2085542447\",\"5\":\"1.3065801962\",\"6\":\"-1.043448216\",\"7\":\"-0.373892736\"},{\"1\":\"Don't Threaten Me with a Good Time\",\"2\":\"Panic! At The Disco\",\"3\":\"-2.63155203\",\"4\":\"0.9485341212\",\"5\":\"-1.0557694214\",\"6\":\"0.401847670\",\"7\":\"-0.699116401\"},{\"1\":\"Take Over\",\"2\":\"League of Legends;MAX;Jeremy McKinnon of A Day To Remember;Henry\",\"3\":\"-1.59509709\",\"4\":\"0.8771232988\",\"5\":\"-0.3272988657\",\"6\":\"-1.863254954\",\"7\":\"0.756821093\"},{\"1\":\"Level of Concern\",\"2\":\"Twenty One Pilots\",\"3\":\"-2.19041009\",\"4\":\"-0.7366470040\",\"5\":\"0.1450667835\",\"6\":\"-0.095741282\",\"7\":\"-0.102717258\"},{\"1\":\"Warriors\",\"2\":\"Imagine Dragons\",\"3\":\"-1.49655642\",\"4\":\"-0.5647738744\",\"5\":\"0.5466687985\",\"6\":\"0.585500441\",\"7\":\"-0.213679300\"},{\"1\":\"Into the Unknown - Panic! At The Disco Version\",\"2\":\"Panic! At The Disco\",\"3\":\"-1.48759682\",\"4\":\"-0.1671893958\",\"5\":\"-0.8761353336\",\"6\":\"1.194733031\",\"7\":\"1.003896721\"},{\"1\":\"Centuries\",\"2\":\"Fall Out Boy\",\"3\":\"-2.39321156\",\"4\":\"0.5662477599\",\"5\":\"-0.5463535822\",\"6\":\"-0.193950515\",\"7\":\"-0.733358963\"},{\"1\":\"My Demons\",\"2\":\"STARSET\",\"3\":\"-0.98299313\",\"4\":\"0.6978094300\",\"5\":\"0.0005226694\",\"6\":\"-0.124598004\",\"7\":\"-0.846459105\"},{\"1\":\"Born For This\",\"2\":\"The Score\",\"3\":\"-1.92701434\",\"4\":\"-0.5111635059\",\"5\":\"0.3522645951\",\"6\":\"-0.211870635\",\"7\":\"-0.134479314\"},{\"1\":\"Mouth Of The River\",\"2\":\"Imagine Dragons\",\"3\":\"-1.22188935\",\"4\":\"-0.8504951224\",\"5\":\"0.5942229122\",\"6\":\"0.223204401\",\"7\":\"0.798930457\"},{\"1\":\"Bang!\",\"2\":\"AJR\",\"3\":\"-2.22280210\",\"4\":\"-0.6719693593\",\"5\":\"-0.6212017576\",\"6\":\"-0.071910618\",\"7\":\"0.163765590\"},{\"1\":\"Thnks fr th Mmrs\",\"2\":\"Fall Out Boy\",\"3\":\"-2.36218083\",\"4\":\"-0.1330222261\",\"5\":\"0.3733886806\",\"6\":\"-1.170846632\",\"7\":\"-1.295652273\"},{\"1\":\"Awaken\",\"2\":\"League of Legends;Valerie Broussard;Ray Chen\",\"3\":\"-0.45786528\",\"4\":\"-1.8616215482\",\"5\":\"2.5340559086\",\"6\":\"0.330774259\",\"7\":\"-0.014298462\"},{\"1\":\"Better Days\",\"2\":\"OneRepublic\",\"3\":\"-1.52933509\",\"4\":\"-0.8363834130\",\"5\":\"0.3722600465\",\"6\":\"1.176886091\",\"7\":\"0.888605316\"},{\"1\":\"Who We Are\",\"2\":\"Imagine Dragons\",\"3\":\"-1.39302302\",\"4\":\"1.4230792849\",\"5\":\"0.4685676384\",\"6\":\"0.767642164\",\"7\":\"-1.486380078\"},{\"1\":\"Victorious\",\"2\":\"Panic! At The Disco\",\"3\":\"-2.50170858\",\"4\":\"0.0130915244\",\"5\":\"0.4301720586\",\"6\":\"1.046060991\",\"7\":\"0.044763519\"},{\"1\":\"Lane Boy\",\"2\":\"Twenty One Pilots\",\"3\":\"-2.42667923\",\"4\":\"-0.3306612166\",\"5\":\"-0.7373849959\",\"6\":\"-0.561990490\",\"7\":\"0.381804287\"},{\"1\":\"Wherever You Are\",\"2\":\"Kodaline\",\"3\":\"-1.10711282\",\"4\":\"-0.8825246643\",\"5\":\"-0.3407959762\",\"6\":\"0.413582463\",\"7\":\"1.026921320\"},{\"1\":\"Dance, Dance\",\"2\":\"Fall Out Boy\",\"3\":\"-2.69502255\",\"4\":\"-0.4714580156\",\"5\":\"0.4899299337\",\"6\":\"-2.037802480\",\"7\":\"-0.688055939\"},{\"1\":\"Gold\",\"2\":\"Imagine Dragons\",\"3\":\"-0.59229464\",\"4\":\"0.6410591866\",\"5\":\"0.1338626428\",\"6\":\"-1.806016803\",\"7\":\"-0.409802577\"},{\"1\":\"Play with Fire (feat. Yacht Money)\",\"2\":\"Sam Tinnesz;Yacht Money\",\"3\":\"-1.41964902\",\"4\":\"-1.6040829682\",\"5\":\"0.2516881702\",\"6\":\"0.375670675\",\"7\":\"0.286870609\"},{\"1\":\"Stronger\",\"2\":\"The Score\",\"3\":\"-1.15263535\",\"4\":\"2.5561468011\",\"5\":\"-1.0061505862\",\"6\":\"0.214277107\",\"7\":\"-0.558537809\"},{\"1\":\"Phoenix\",\"2\":\"League of Legends;Cailin Russo;Chrissy Costanza\",\"3\":\"-2.00507594\",\"4\":\"1.3058838626\",\"5\":\"0.5244174227\",\"6\":\"-1.784369945\",\"7\":\"-0.273527875\"},{\"1\":\"Emperor's New Clothes\",\"2\":\"Panic! At The Disco\",\"3\":\"-2.03104512\",\"4\":\"-1.3630624369\",\"5\":\"-1.2584064790\",\"6\":\"0.319106633\",\"7\":\"1.383771025\"},{\"1\":\"Machine\",\"2\":\"Imagine Dragons\",\"3\":\"-1.69672398\",\"4\":\"-1.5517048555\",\"5\":\"-0.2034659526\",\"6\":\"0.463805335\",\"7\":\"1.236085377\"},{\"1\":\"Father of All...\",\"2\":\"Green Day\",\"3\":\"-2.21193032\",\"4\":\"1.9680311841\",\"5\":\"0.3440337091\",\"6\":\"-2.597690163\",\"7\":\"0.011971638\"},{\"1\":\"S01E02.Return.Of.The.Arsonist.720p.HDTV.x264\",\"2\":\"Blood Command\",\"3\":\"-1.68975328\",\"4\":\"0.2749162326\",\"5\":\"1.2414646473\",\"6\":\"0.338917936\",\"7\":\"-0.210503219\"},{\"1\":\"Reckless Paradise\",\"2\":\"Billy Talent\",\"3\":\"-3.00105960\",\"4\":\"2.5221935176\",\"5\":\"-0.9211033218\",\"6\":\"0.489522816\",\"7\":\"-0.689908949\"},{\"1\":\"All My Friends Are Nobodies\",\"2\":\"zebrahead\",\"3\":\"-2.06541125\",\"4\":\"-0.1451862632\",\"5\":\"0.3488204653\",\"6\":\"0.149564107\",\"7\":\"0.814470298\"},{\"1\":\"Out For Blood\",\"2\":\"Sum 41\",\"3\":\"-1.36204974\",\"4\":\"0.5262186649\",\"5\":\"0.6145245786\",\"6\":\"-0.164402627\",\"7\":\"-0.273145729\"},{\"1\":\"Broken Dreams, Inc.\",\"2\":\"Rise Against\",\"3\":\"-1.90515418\",\"4\":\"1.6438225801\",\"5\":\"-1.3448777031\",\"6\":\"1.328742258\",\"7\":\"0.487689931\"},{\"1\":\"Why Worry\",\"2\":\"Set It Off\",\"3\":\"-2.28281562\",\"4\":\"-0.7357615914\",\"5\":\"-0.4263346811\",\"6\":\"0.553495694\",\"7\":\"-0.188084235\"},{\"1\":\"Fire, Ready, Aim\",\"2\":\"Green Day\",\"3\":\"-2.79322988\",\"4\":\"1.0538274063\",\"5\":\"0.5688458292\",\"6\":\"0.502657502\",\"7\":\"-0.285438734\"},{\"1\":\"Chelsea\",\"2\":\"Dragged Under\",\"3\":\"-2.14405988\",\"4\":\"1.9240663523\",\"5\":\"-0.1973222674\",\"6\":\"1.916949857\",\"7\":\"-0.951936242\"},{\"1\":\"American Attraction\",\"2\":\"Anti-Flag\",\"3\":\"-1.97393826\",\"4\":\"-0.6585802607\",\"5\":\"-1.3252597419\",\"6\":\"1.027783986\",\"7\":\"1.008241208\"},{\"1\":\"If You're Looking for Your Knife...I Think My Back Found It\",\"2\":\"zebrahead\",\"3\":\"-2.46424550\",\"4\":\"0.5847871139\",\"5\":\"1.3851856398\",\"6\":\"-0.439525030\",\"7\":\"-0.368863039\"},{\"1\":\"You're Gonna Go Far, Kid\",\"2\":\"The Offspring\",\"3\":\"-1.69101770\",\"4\":\"0.4809271709\",\"5\":\"0.7876087033\",\"6\":\"-0.431594269\",\"7\":\"-1.155009153\"},{\"1\":\"Trash Bat\",\"2\":\"AFI\",\"3\":\"-2.18194857\",\"4\":\"-0.7871959795\",\"5\":\"-1.2351441730\",\"6\":\"0.974438815\",\"7\":\"1.263150725\"},{\"1\":\"Hrsa\",\"2\":\"Bowling For Soup\",\"3\":\"-1.68353450\",\"4\":\"0.9514964189\",\"5\":\"-0.9470967316\",\"6\":\"1.927786800\",\"7\":\"0.691334013\"},{\"1\":\"Na Na Na (Na Na Na Na Na Na Na Na Na)\",\"2\":\"My Chemical Romance\",\"3\":\"-2.84132161\",\"4\":\"1.2257007602\",\"5\":\"0.3737415774\",\"6\":\"0.439590594\",\"7\":\"-1.788672359\"},{\"1\":\"Gone Away\",\"2\":\"Nomy\",\"3\":\"-0.59656173\",\"4\":\"-0.1856504241\",\"5\":\"-0.5366956146\",\"6\":\"1.165556224\",\"7\":\"1.283805633\"},{\"1\":\"A Million Miles\",\"2\":\"Goldfinger\",\"3\":\"-2.04356881\",\"4\":\"-0.3074106887\",\"5\":\"1.4331760069\",\"6\":\"-1.250885043\",\"7\":\"-0.044030657\"},{\"1\":\"The Perfect Crime\",\"2\":\"zebrahead\",\"3\":\"-2.07415552\",\"4\":\"2.5617354393\",\"5\":\"-0.2559603609\",\"6\":\"-0.201043842\",\"7\":\"0.091592949\"},{\"1\":\"Gave You Everything\",\"2\":\"The Interrupters\",\"3\":\"-2.03388856\",\"4\":\"1.2081412330\",\"5\":\"-1.1013154286\",\"6\":\"1.314455056\",\"7\":\"0.324246064\"},{\"1\":\"Get Dark\",\"2\":\"AFI\",\"3\":\"-2.19889347\",\"4\":\"-0.5297498903\",\"5\":\"1.1817719540\",\"6\":\"-0.637648824\",\"7\":\"-0.137745329\"},{\"1\":\"Quarantine\",\"2\":\"blink-182\",\"3\":\"-2.38234863\",\"4\":\"-0.1839847560\",\"5\":\"0.8598998402\",\"6\":\"0.452465231\",\"7\":\"-0.222188376\"},{\"1\":\"Knockin' On Heaven's Door\",\"2\":\"Bob Dylan\",\"3\":\"0.14452772\",\"4\":\"-2.1376121937\",\"5\":\"-1.8015961027\",\"6\":\"-0.849708540\",\"7\":\"-2.273228231\"},{\"1\":\"Surfin' U.S.A. - Remastered\",\"2\":\"The Beach Boys\",\"3\":\"-1.50046838\",\"4\":\"-2.0963739078\",\"5\":\"-3.5901912866\",\"6\":\"-0.468585185\",\"7\":\"-3.071415343\"},{\"1\":\"Main Titles\",\"2\":\"Ramin Djawadi\",\"3\":\"0.34337279\",\"4\":\"1.2207971413\",\"5\":\"-0.8305591013\",\"6\":\"-1.145199718\",\"7\":\"0.336501072\"},{\"1\":\"Another Love\",\"2\":\"Tom Odell\",\"3\":\"-0.24946016\",\"4\":\"-0.7426645530\",\"5\":\"0.1797297372\",\"6\":\"-0.141871275\",\"7\":\"-0.505558574\"},{\"1\":\"Halo\",\"2\":\"Beyoncé\",\"3\":\"-1.29048423\",\"4\":\"-1.4363640608\",\"5\":\"1.2788500542\",\"6\":\"-1.423062775\",\"7\":\"-0.575626576\"},{\"1\":\"Crazy In Love (feat. Jay-Z)\",\"2\":\"Beyoncé;JAY-Z\",\"3\":\"-2.48103353\",\"4\":\"-0.5715402640\",\"5\":\"-1.4358732062\",\"6\":\"-1.357304083\",\"7\":\"-0.210206060\"},{\"1\":\"Formation\",\"2\":\"Beyoncé\",\"3\":\"-3.36760587\",\"4\":\"0.5060361660\",\"5\":\"-0.5684239977\",\"6\":\"-1.512731646\",\"7\":\"0.188009832\"},{\"1\":\"Perfect Duet (Ed Sheeran & Beyoncé)\",\"2\":\"Ed Sheeran;Beyoncé\",\"3\":\"0.22828061\",\"4\":\"-0.9040700235\",\"5\":\"-0.0411292914\",\"6\":\"-1.046393749\",\"7\":\"1.120882447\"},{\"1\":\"Complicated\",\"2\":\"Avril Lavigne\",\"3\":\"-1.56205194\",\"4\":\"-1.3701551778\",\"5\":\"-0.3620002378\",\"6\":\"0.977947338\",\"7\":\"-0.232996037\"},{\"1\":\"Sk8er Boi\",\"2\":\"Avril Lavigne\",\"3\":\"-2.04035253\",\"4\":\"0.1364073457\",\"5\":\"-1.8349456734\",\"6\":\"1.912333524\",\"7\":\"-0.785974379\"},{\"1\":\"Girlfriend\",\"2\":\"Avril Lavigne\",\"3\":\"-2.73331280\",\"4\":\"0.3119743503\",\"5\":\"-0.9781214090\",\"6\":\"-0.161565573\",\"7\":\"-0.332031900\"},{\"1\":\"What the Hell\",\"2\":\"Avril Lavigne\",\"3\":\"-2.96225894\",\"4\":\"-0.1356126823\",\"5\":\"-0.2084140593\",\"6\":\"-0.370817974\",\"7\":\"-0.988507928\"},{\"1\":\"Head Above Water\",\"2\":\"Avril Lavigne\",\"3\":\"-1.42436545\",\"4\":\"-0.4777384855\",\"5\":\"-0.2942572547\",\"6\":\"0.107931717\",\"7\":\"1.022484605\"},{\"1\":\"Dog Days Are Over\",\"2\":\"Florence + The Machine\",\"3\":\"-1.48645804\",\"4\":\"-0.0986604603\",\"5\":\"-0.5737318312\",\"6\":\"-0.359754364\",\"7\":\"0.127692024\"},{\"1\":\"You've Got The Love\",\"2\":\"Florence + The Machine\",\"3\":\"-1.47476861\",\"4\":\"-1.4567953123\",\"5\":\"-0.3430555014\",\"6\":\"0.047951681\",\"7\":\"0.393464893\"},{\"1\":\"Shake It Out\",\"2\":\"Florence + The Machine\",\"3\":\"-1.17926838\",\"4\":\"-1.0687276368\",\"5\":\"0.6588636754\",\"6\":\"-0.284742744\",\"7\":\"0.343949647\"},{\"1\":\"Dusk Till Dawn - Radio Edit\",\"2\":\"ZAYN;Sia\",\"3\":\"-0.84435950\",\"4\":\"0.5652875890\",\"5\":\"1.1782017498\",\"6\":\"-1.005762657\",\"7\":\"-0.977797244\"},{\"1\":\"Together\",\"2\":\"Sia\",\"3\":\"-1.73216906\",\"4\":\"0.3480987029\",\"5\":\"-0.2962385268\",\"6\":\"-0.212848812\",\"7\":\"0.612049823\"},{\"1\":\"Let's Love\",\"2\":\"David Guetta;Sia\",\"3\":\"-2.44507785\",\"4\":\"0.2378600113\",\"5\":\"0.6637028785\",\"6\":\"2.529896963\",\"7\":\"0.185572385\"},{\"1\":\"Chandelier\",\"2\":\"Sia\",\"3\":\"-1.96294437\",\"4\":\"-1.5953252168\",\"5\":\"-0.6507699475\",\"6\":\"1.567880853\",\"7\":\"0.450529062\"},{\"1\":\"Cheap Thrills\",\"2\":\"Sia\",\"3\":\"-2.19619273\",\"4\":\"-0.7956436161\",\"5\":\"0.3465520881\",\"6\":\"-0.868042878\",\"7\":\"0.138896270\"},{\"1\":\"Someone Like You\",\"2\":\"Adele\",\"3\":\"0.07290446\",\"4\":\"-1.0629841199\",\"5\":\"0.2106944006\",\"6\":\"-0.602450271\",\"7\":\"0.026031639\"},{\"1\":\"Make You Feel My Love\",\"2\":\"Adele\",\"3\":\"0.79918532\",\"4\":\"-2.1684422022\",\"5\":\"0.8023825233\",\"6\":\"-0.797850997\",\"7\":\"0.346305114\"},{\"1\":\"Rolling in the Deep\",\"2\":\"Adele\",\"3\":\"-1.75633137\",\"4\":\"-1.8355105803\",\"5\":\"0.0479095903\",\"6\":\"-0.484922173\",\"7\":\"0.595560404\"},{\"1\":\"Set Fire to the Rain\",\"2\":\"Adele\",\"3\":\"-1.80244441\",\"4\":\"-1.1968739590\",\"5\":\"-0.2080461816\",\"6\":\"0.445284643\",\"7\":\"-0.443742135\"},{\"1\":\"When We Were Young\",\"2\":\"Adele\",\"3\":\"-0.56537696\",\"4\":\"-0.3096463056\",\"5\":\"-0.8276036980\",\"6\":\"0.523163813\",\"7\":\"0.505264351\"},{\"1\":\"I Want to Know What Love Is - 1999 Remaster\",\"2\":\"Foreigner\",\"3\":\"-0.23227173\",\"4\":\"-2.5102900369\",\"5\":\"-1.0505607176\",\"6\":\"-0.126982143\",\"7\":\"-1.213966017\"},{\"1\":\"Waiting for a Girl like You\",\"2\":\"Foreigner\",\"3\":\"-0.55040764\",\"4\":\"-0.4262848987\",\"5\":\"-0.8756608959\",\"6\":\"-1.767408841\",\"7\":\"-3.400519503\"},{\"1\":\"Juke Box Hero\",\"2\":\"Foreigner\",\"3\":\"-1.08520439\",\"4\":\"-0.7118137974\",\"5\":\"-1.6765422915\",\"6\":\"-1.112282959\",\"7\":\"-2.093214374\"},{\"1\":\"Cold as Ice\",\"2\":\"Foreigner\",\"3\":\"-0.79540292\",\"4\":\"-1.6922092425\",\"5\":\"-1.6783164631\",\"6\":\"-0.344731826\",\"7\":\"-2.954043122\"},{\"1\":\"Hot Blooded\",\"2\":\"Foreigner\",\"3\":\"-1.61407154\",\"4\":\"-2.0746623501\",\"5\":\"-3.1341566725\",\"6\":\"-0.039269731\",\"7\":\"-1.338548586\"},{\"1\":\"The Phoenix\",\"2\":\"Fall Out Boy\",\"3\":\"-2.79579085\",\"4\":\"1.5809517772\",\"5\":\"0.3888552129\",\"6\":\"1.966557613\",\"7\":\"-1.581159482\"},{\"1\":\"Wolf in Sheep's Clothing\",\"2\":\"Set It Off;William Beckett\",\"3\":\"-2.95454831\",\"4\":\"1.5307208097\",\"5\":\"1.0031513182\",\"6\":\"-0.059913998\",\"7\":\"-1.635204888\"},{\"1\":\"Bob Dylan\",\"2\":\"Fall Out Boy\",\"3\":\"-1.95515372\",\"4\":\"0.0732262486\",\"5\":\"0.9114759177\",\"6\":\"0.889945791\",\"7\":\"0.385521836\"},{\"1\":\"Don't Stop the Devil\",\"2\":\"Dead Posey\",\"3\":\"-1.79732039\",\"4\":\"-0.8547551181\",\"5\":\"0.4423224505\",\"6\":\"-0.354208623\",\"7\":\"0.895530651\"},{\"1\":\"You're Gonna Know My Name\",\"2\":\"Watt White\",\"3\":\"-1.45754804\",\"4\":\"0.0873613549\",\"5\":\"-0.7074522904\",\"6\":\"-0.193091127\",\"7\":\"0.810438984\"},{\"1\":\"Sinners\",\"2\":\"Barns Courtney\",\"3\":\"-1.78172879\",\"4\":\"-0.4516759121\",\"5\":\"0.7156246341\",\"6\":\"-0.873549704\",\"7\":\"0.246458062\"},{\"1\":\"Hero of Our Time\",\"2\":\"NateWantsToBattle\",\"3\":\"-2.87804969\",\"4\":\"1.2997707185\",\"5\":\"1.5132363227\",\"6\":\"0.375109660\",\"7\":\"-1.384387443\"},{\"1\":\"Catch Me If You Can\",\"2\":\"Set It Off\",\"3\":\"-2.29947324\",\"4\":\"-0.1851955240\",\"5\":\"0.4509606658\",\"6\":\"0.411218585\",\"7\":\"0.029196131\"},{\"1\":\"Any Other Way\",\"2\":\"We The Kings\",\"3\":\"-1.35244836\",\"4\":\"-1.2412117954\",\"5\":\"0.9062159256\",\"6\":\"-0.631132843\",\"7\":\"0.763989033\"},{\"1\":\"E.T.\",\"2\":\"First to Eleven\",\"3\":\"-1.83086509\",\"4\":\"1.3336942695\",\"5\":\"0.5034142078\",\"6\":\"0.979097208\",\"7\":\"-0.974795699\"},{\"1\":\"Toss A Coin To Your Witcher\",\"2\":\"Sonya Belousova;Giona Ostinelli;Joey Batey\",\"3\":\"-0.26523644\",\"4\":\"-0.7382926368\",\"5\":\"0.6913093359\",\"6\":\"-0.111222435\",\"7\":\"-0.145711948\"},{\"1\":\"Genius\",\"2\":\"Written by Wolves\",\"3\":\"-2.87046671\",\"4\":\"0.7677302948\",\"5\":\"0.9040970290\",\"6\":\"-0.055616791\",\"7\":\"-0.974592553\"},{\"1\":\"Finish Line\",\"2\":\"Skillet\",\"3\":\"-2.04732311\",\"4\":\"-0.3485222488\",\"5\":\"0.9838355484\",\"6\":\"0.940221376\",\"7\":\"-0.291660012\"},{\"1\":\"All Eyes on You\",\"2\":\"Smash Into Pieces\",\"3\":\"-1.29597519\",\"4\":\"-0.9108637785\",\"5\":\"0.5638534505\",\"6\":\"0.389346660\",\"7\":\"0.327747534\"},{\"1\":\"Bells\",\"2\":\"The Unlikely Candidates\",\"3\":\"-0.71748510\",\"4\":\"-1.1902642573\",\"5\":\"0.6116701558\",\"6\":\"0.293984268\",\"7\":\"1.097397455\"},{\"1\":\"Death of Me\",\"2\":\"SAINT PHNX\",\"3\":\"-1.59246623\",\"4\":\"-0.3121537231\",\"5\":\"-1.0117320909\",\"6\":\"0.826083976\",\"7\":\"1.125351797\"},{\"1\":\"Arcadia\",\"2\":\"Smash Into Pieces\",\"3\":\"-2.45450370\",\"4\":\"0.6018035196\",\"5\":\"0.2855151156\",\"6\":\"2.088612443\",\"7\":\"-0.503278290\"},{\"1\":\"Carry On\",\"2\":\"The Score;AWOLNATION\",\"3\":\"-1.36801409\",\"4\":\"-0.9928964186\",\"5\":\"-0.6893692994\",\"6\":\"1.558540440\",\"7\":\"1.236175907\"},{\"1\":\"Pegasus Seiya\",\"2\":\"The Struts\",\"3\":\"-1.40661795\",\"4\":\"0.6075932734\",\"5\":\"-0.0257136506\",\"6\":\"-0.059306517\",\"7\":\"0.373359857\"},{\"1\":\"Can't Go to Hell\",\"2\":\"Sin Shake Sin\",\"3\":\"-2.73271903\",\"4\":\"0.0746434883\",\"5\":\"0.1481436099\",\"6\":\"0.722320623\",\"7\":\"-0.729886041\"},{\"1\":\"Monster\",\"2\":\"Imagine Dragons\",\"3\":\"-1.35753086\",\"4\":\"0.4435699936\",\"5\":\"-1.2860924385\",\"6\":\"0.290582214\",\"7\":\"0.320756432\"},{\"1\":\"Under The Pressure\",\"2\":\"The Score\",\"3\":\"-2.53169741\",\"4\":\"2.6632103232\",\"5\":\"-1.0111544742\",\"6\":\"-1.262739237\",\"7\":\"0.612800486\"},{\"1\":\"Elastic Heart (Rock Version)\",\"2\":\"Written by Wolves\",\"3\":\"-1.41508342\",\"4\":\"0.0059261018\",\"5\":\"0.6210052160\",\"6\":\"-0.045142494\",\"7\":\"-0.460081394\"},{\"1\":\"Your Turn to Roll (Critical Role Theme)\",\"2\":\"Ashley Johnson;Laura Bailey;Sam Riegel\",\"3\":\"-2.66663443\",\"4\":\"-0.3075878124\",\"5\":\"1.3606165098\",\"6\":\"-0.843819346\",\"7\":\"-0.480738847\"},{\"1\":\"Bad Apple!!\",\"2\":\"RichaadEB;Cristina Vee\",\"3\":\"-1.77056325\",\"4\":\"1.9146350182\",\"5\":\"-0.2876470686\",\"6\":\"3.586140226\",\"7\":\"-0.695818738\"},{\"1\":\"Made For This\",\"2\":\"City Wolf\",\"3\":\"-1.95591358\",\"4\":\"0.4390336363\",\"5\":\"-0.7946168875\",\"6\":\"1.361200889\",\"7\":\"1.153160306\"},{\"1\":\"This Is Our War\",\"2\":\"Halocene\",\"3\":\"-0.41884027\",\"4\":\"1.7198378445\",\"5\":\"-1.0531516803\",\"6\":\"-0.487117001\",\"7\":\"-0.152801577\"},{\"1\":\"Toss a Coin to Your Witcher (Metal Version)\",\"2\":\"Dan Vasc\",\"3\":\"-1.02723735\",\"4\":\"-0.6754950191\",\"5\":\"0.6356824409\",\"6\":\"0.138406327\",\"7\":\"0.932492766\"},{\"1\":\"Dear Future Self (Hands Up)\",\"2\":\"Fall Out Boy;Wyclef Jean\",\"3\":\"-3.08100886\",\"4\":\"1.2081120255\",\"5\":\"-1.4354771121\",\"6\":\"-1.884243855\",\"7\":\"1.183332469\"},{\"1\":\"Run Like A Rebel\",\"2\":\"The Score\",\"3\":\"-1.66146574\",\"4\":\"0.6534484473\",\"5\":\"0.2746568226\",\"6\":\"0.440534848\",\"7\":\"0.077081744\"},{\"1\":\"Animal In Me\",\"2\":\"Solence\",\"3\":\"-2.40291017\",\"4\":\"1.0391242130\",\"5\":\"0.1062584091\",\"6\":\"-0.024536535\",\"7\":\"-0.342623603\"},{\"1\":\"House of Memories\",\"2\":\"Panic! At The Disco\",\"3\":\"-1.98797559\",\"4\":\"-1.0131901980\",\"5\":\"1.4032340982\",\"6\":\"-1.165130360\",\"7\":\"-0.313938879\"},{\"1\":\"Toss a Coin to Your Witcher\",\"2\":\"Ghost Fight\",\"3\":\"-1.66016548\",\"4\":\"0.1055857666\",\"5\":\"1.3077599552\",\"6\":\"-1.290714815\",\"7\":\"0.244247631\"},{\"1\":\"The Greatest Show\",\"2\":\"Panic! At The Disco\",\"3\":\"-2.31009683\",\"4\":\"-0.0181478655\",\"5\":\"1.0805755814\",\"6\":\"0.761740721\",\"7\":\"-0.336510582\"},{\"1\":\"Lonely Dance\",\"2\":\"Set It Off\",\"3\":\"-2.04574945\",\"4\":\"0.0670171109\",\"5\":\"1.9051807136\",\"6\":\"-0.166120495\",\"7\":\"-0.467311181\"},{\"1\":\"I'm Dangerous\",\"2\":\"The EverLove\",\"3\":\"-2.52613784\",\"4\":\"-0.2832024267\",\"5\":\"1.2831445162\",\"6\":\"0.293113026\",\"7\":\"-0.516736359\"},{\"1\":\"Best Part\",\"2\":\"The Score\",\"3\":\"-1.22482499\",\"4\":\"0.4255713386\",\"5\":\"-0.7827764817\",\"6\":\"1.213539402\",\"7\":\"0.589276678\"},{\"1\":\"My Name Is..\",\"2\":\"Once Monsters\",\"3\":\"-1.98056754\",\"4\":\"0.7228826376\",\"5\":\"-2.0715741479\",\"6\":\"0.035905486\",\"7\":\"1.074154881\"},{\"1\":\"Phantom\",\"2\":\"NateWantsToBattle\",\"3\":\"-2.03682759\",\"4\":\"2.8836315130\",\"5\":\"-1.6710254452\",\"6\":\"1.479078906\",\"7\":\"-0.080880158\"},{\"1\":\"Six Feet\",\"2\":\"Patent Pending\",\"3\":\"-2.37663545\",\"4\":\"-0.1345783424\",\"5\":\"0.8473447718\",\"6\":\"-0.793318476\",\"7\":\"-0.530029328\"},{\"1\":\"In My Bones\",\"2\":\"The Score\",\"3\":\"-1.42478673\",\"4\":\"-1.0630690149\",\"5\":\"0.4910847038\",\"6\":\"0.417374575\",\"7\":\"0.221683206\"},{\"1\":\"Stay Frosty Royal Milk Tea\",\"2\":\"Fall Out Boy\",\"3\":\"-2.36742767\",\"4\":\"0.7602411626\",\"5\":\"-0.5786470962\",\"6\":\"0.893173349\",\"7\":\"-0.497045180\"},{\"1\":\"Revolution\",\"2\":\"The Score\",\"3\":\"-1.98771923\",\"4\":\"-1.0286895343\",\"5\":\"1.0662153335\",\"6\":\"-0.616450047\",\"7\":\"-0.019867553\"},{\"1\":\"Stand Up\",\"2\":\"The Cab\",\"3\":\"-0.87830635\",\"4\":\"-1.5588015244\",\"5\":\"-1.0236860130\",\"6\":\"0.946476349\",\"7\":\"1.153576588\"},{\"1\":\"Killer In The Mirror\",\"2\":\"Set It Off\",\"3\":\"-2.71592966\",\"4\":\"0.5573320609\",\"5\":\"0.0100014548\",\"6\":\"1.553593171\",\"7\":\"-0.272243077\"},{\"1\":\"Night of Your Life\",\"2\":\"WAR*HALL\",\"3\":\"-1.43356129\",\"4\":\"-1.0581444221\",\"5\":\"0.1733935198\",\"6\":\"-0.169460812\",\"7\":\"1.030454810\"},{\"1\":\"Protector\",\"2\":\"City Wolf\",\"3\":\"-1.59623167\",\"4\":\"-1.0823401079\",\"5\":\"-0.1821875161\",\"6\":\"0.075127869\",\"7\":\"1.180102493\"},{\"1\":\"Rule The World\",\"2\":\"Valley Of Wolves\",\"3\":\"-2.35302588\",\"4\":\"1.1363319572\",\"5\":\"1.7593164260\",\"6\":\"0.279672845\",\"7\":\"-1.128650687\"},{\"1\":\"A Real Life\",\"2\":\"Greek Fire\",\"3\":\"-1.73631229\",\"4\":\"0.0551811066\",\"5\":\"0.0405912333\",\"6\":\"-0.317899139\",\"7\":\"-0.451831333\"},{\"1\":\"King of the World\",\"2\":\"WAR*HALL\",\"3\":\"-1.40816893\",\"4\":\"-0.7857079438\",\"5\":\"-0.7068831264\",\"6\":\"1.573840813\",\"7\":\"1.152029874\"},{\"1\":\"Wolves\",\"2\":\"Sam Tinnesz;Silverberg\",\"3\":\"-2.10630519\",\"4\":\"-0.0650753603\",\"5\":\"1.2120388814\",\"6\":\"-1.394708360\",\"7\":\"-0.281522576\"},{\"1\":\"Ready Set Let's Go\",\"2\":\"Sam Tinnesz\",\"3\":\"-0.82650949\",\"4\":\"-1.6296913104\",\"5\":\"1.1520197645\",\"6\":\"-0.622601731\",\"7\":\"0.957222871\"},{\"1\":\"Broken Bones\",\"2\":\"KALEO\",\"3\":\"-1.31920797\",\"4\":\"-0.1101280824\",\"5\":\"-1.0604809281\",\"6\":\"-1.243415431\",\"7\":\"1.139768781\"},{\"1\":\"Glass House\",\"2\":\"KALEO\",\"3\":\"-1.76084069\",\"4\":\"0.3496425002\",\"5\":\"-0.7044074412\",\"6\":\"-0.998761369\",\"7\":\"1.401934287\"},{\"1\":\"Hot Blood\",\"2\":\"KALEO\",\"3\":\"-1.56905612\",\"4\":\"0.4431720035\",\"5\":\"-1.3708791383\",\"6\":\"0.332895805\",\"7\":\"0.814800161\"},{\"1\":\"All the Pretty Girls\",\"2\":\"KALEO\",\"3\":\"-0.03349493\",\"4\":\"-1.6028288352\",\"5\":\"-0.5369556491\",\"6\":\"1.016164704\",\"7\":\"1.081537538\"},{\"1\":\"Vor í Vaglaskógi\",\"2\":\"KALEO\",\"3\":\"0.46698266\",\"4\":\"-0.5671176853\",\"5\":\"1.0057689431\",\"6\":\"0.368634957\",\"7\":\"-0.412188868\"},{\"1\":\"Save Yourself\",\"2\":\"KALEO\",\"3\":\"0.20525309\",\"4\":\"-0.7646669913\",\"5\":\"0.5182549329\",\"6\":\"-0.147124424\",\"7\":\"0.543660477\"},{\"1\":\"I Can't Go on Without You\",\"2\":\"KALEO\",\"3\":\"0.52305614\",\"4\":\"-0.8269970252\",\"5\":\"1.3565539054\",\"6\":\"-0.631423960\",\"7\":\"-0.302219282\"},{\"1\":\"42\",\"2\":\"Mumford & Sons\",\"3\":\"-0.02715294\",\"4\":\"-0.8176814252\",\"5\":\"0.2119907494\",\"6\":\"0.606671735\",\"7\":\"0.941440475\"},{\"1\":\"Guiding Light\",\"2\":\"Mumford & Sons\",\"3\":\"-0.98984399\",\"4\":\"-1.1535172472\",\"5\":\"0.3169714995\",\"6\":\"-0.114947336\",\"7\":\"1.087579470\"},{\"1\":\"Woman\",\"2\":\"Mumford & Sons\",\"3\":\"0.06957160\",\"4\":\"0.1171593762\",\"5\":\"-0.2424226283\",\"6\":\"0.424622423\",\"7\":\"-0.466074988\"},{\"1\":\"Beloved\",\"2\":\"Mumford & Sons\",\"3\":\"-1.04845907\",\"4\":\"0.8007201157\",\"5\":\"-1.1772211550\",\"6\":\"0.889778021\",\"7\":\"0.281534025\"},{\"1\":\"The Wild\",\"2\":\"Mumford & Sons\",\"3\":\"1.71298489\",\"4\":\"0.0252739669\",\"5\":\"-0.6136602365\",\"6\":\"1.472783555\",\"7\":\"0.426463522\"},{\"1\":\"October Skies\",\"2\":\"Mumford & Sons\",\"3\":\"1.35887818\",\"4\":\"-0.2796418553\",\"5\":\"-1.1843633198\",\"6\":\"0.522353855\",\"7\":\"0.796289053\"},{\"1\":\"Slip Away\",\"2\":\"Mumford & Sons\",\"3\":\"-0.40158228\",\"4\":\"0.1486633318\",\"5\":\"-0.8375634599\",\"6\":\"0.831317073\",\"7\":\"0.572500336\"},{\"1\":\"Rose Of Sharon\",\"2\":\"Mumford & Sons\",\"3\":\"-0.71625089\",\"4\":\"-0.6153324513\",\"5\":\"-0.8935182891\",\"6\":\"0.475581665\",\"7\":\"0.865087348\"},{\"1\":\"Picture You\",\"2\":\"Mumford & Sons\",\"3\":\"-0.57657404\",\"4\":\"0.3479657087\",\"5\":\"-0.3541534342\",\"6\":\"-0.194581688\",\"7\":\"0.528158265\"},{\"1\":\"Darkness Visible\",\"2\":\"Mumford & Sons\",\"3\":\"-0.18892409\",\"4\":\"0.6748878512\",\"5\":\"1.3353027241\",\"6\":\"-1.335367282\",\"7\":\"-0.684849749\"},{\"1\":\"If I Say\",\"2\":\"Mumford & Sons\",\"3\":\"0.06215426\",\"4\":\"-0.6480639294\",\"5\":\"0.3826685091\",\"6\":\"0.440552967\",\"7\":\"0.103171448\"},{\"1\":\"Wild Heart\",\"2\":\"Mumford & Sons\",\"3\":\"0.90123689\",\"4\":\"-1.0970212097\",\"5\":\"1.2455032201\",\"6\":\"-0.834618809\",\"7\":\"0.068774963\"},{\"1\":\"Forever\",\"2\":\"Mumford & Sons\",\"3\":\"0.37737904\",\"4\":\"-0.0902329615\",\"5\":\"1.0004461802\",\"6\":\"-0.558508859\",\"7\":\"0.407431648\"},{\"1\":\"Delta\",\"2\":\"Mumford & Sons\",\"3\":\"0.04439906\",\"4\":\"-0.6973986577\",\"5\":\"-0.5349075255\",\"6\":\"0.600453661\",\"7\":\"1.053435477\"},{\"1\":\"Alligator\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.76279616\",\"4\":\"-0.6782932524\",\"5\":\"0.2764371189\",\"6\":\"-0.237426971\",\"7\":\"0.970761172\"},{\"1\":\"Ahay\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.29032977\",\"4\":\"0.2962147570\",\"5\":\"-0.0701908604\",\"6\":\"-0.384811558\",\"7\":\"0.539594116\"},{\"1\":\"Róróró\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.61511111\",\"4\":\"-0.9393032690\",\"5\":\"0.9109857526\",\"6\":\"-0.134455343\",\"7\":\"0.035561792\"},{\"1\":\"Waiting For The Snow\",\"2\":\"Of Monsters and Men\",\"3\":\"1.44175502\",\"4\":\"-1.3797829852\",\"5\":\"-0.3704533205\",\"6\":\"0.695864826\",\"7\":\"1.295790411\"},{\"1\":\"Vulture, Vulture\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.63922151\",\"4\":\"-0.7826728959\",\"5\":\"0.1385234341\",\"6\":\"0.394527747\",\"7\":\"0.231768331\"},{\"1\":\"Wild Roses\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.79379208\",\"4\":\"-0.0764058413\",\"5\":\"0.9679502073\",\"6\":\"0.424304326\",\"7\":\"-0.362444833\"},{\"1\":\"Stuck In Gravity\",\"2\":\"Of Monsters and Men\",\"3\":\"-0.29351187\",\"4\":\"-1.0606225322\",\"5\":\"1.2971204869\",\"6\":\"-0.641060851\",\"7\":\"1.065443963\"},{\"1\":\"Sleepwalker\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.71240525\",\"4\":\"-0.3655062707\",\"5\":\"-0.1732243611\",\"6\":\"1.974671112\",\"7\":\"0.723995657\"},{\"1\":\"Wars\",\"2\":\"Of Monsters and Men\",\"3\":\"-2.28098076\",\"4\":\"0.3224503399\",\"5\":\"0.9678254340\",\"6\":\"0.923979125\",\"7\":\"-0.669219959\"},{\"1\":\"Under A Dome\",\"2\":\"Of Monsters and Men\",\"3\":\"-0.33521460\",\"4\":\"-0.1665722896\",\"5\":\"1.1736899079\",\"6\":\"-0.262991396\",\"7\":\"-0.302643802\"},{\"1\":\"Soothsayer\",\"2\":\"Of Monsters and Men\",\"3\":\"-1.53151492\",\"4\":\"-0.6551563055\",\"5\":\"1.9213461989\",\"6\":\"-0.658349742\",\"7\":\"-0.171118632\"},{\"1\":\"What's Up Danger (with Black Caviar)\",\"2\":\"Blackway;Black Caviar\",\"3\":\"-1.32199018\",\"4\":\"-1.3963946790\",\"5\":\"-0.3758031189\",\"6\":\"0.896837066\",\"7\":\"1.298912481\"},{\"1\":\"Sunflower - Spider-Man: Into the Spider-Verse\",\"2\":\"Post Malone;Swae Lee\",\"3\":\"-1.79445416\",\"4\":\"-2.0591582947\",\"5\":\"-0.9738094090\",\"6\":\"0.113123965\",\"7\":\"1.297755853\"},{\"1\":\"Way Up\",\"2\":\"Jaden\",\"3\":\"-2.78534476\",\"4\":\"0.6006217752\",\"5\":\"0.8937157965\",\"6\":\"-1.197038574\",\"7\":\"-0.234299147\"},{\"1\":\"Familia (with Anuel Aa, feat. Bantu) - Spider-Man: Into the Spider-Verse\",\"2\":\"Nicki Minaj;Anuel AA;Bantu\",\"3\":\"-3.57048051\",\"4\":\"-0.0235055550\",\"5\":\"1.5957905084\",\"6\":\"0.362895153\",\"7\":\"-0.795469742\"},{\"1\":\"Invincible\",\"2\":\"Aminé\",\"3\":\"-2.50136354\",\"4\":\"0.3488683264\",\"5\":\"0.6015856154\",\"6\":\"-2.765369804\",\"7\":\"0.791210314\"},{\"1\":\"Start a Riot\",\"2\":\"Duckwrth;Shaboozey\",\"3\":\"-3.00049286\",\"4\":\"0.2912222327\",\"5\":\"-1.9344637772\",\"6\":\"-0.783964506\",\"7\":\"1.372075108\"},{\"1\":\"Hide (feat. Seezyn)\",\"2\":\"Juice WRLD;Seezyn\",\"3\":\"-1.96145168\",\"4\":\"0.0373728097\",\"5\":\"0.2834670640\",\"6\":\"-0.218010498\",\"7\":\"-0.264960772\"},{\"1\":\"Memories\",\"2\":\"Thutmose\",\"3\":\"-1.74194849\",\"4\":\"-0.6624494488\",\"5\":\"0.6273507805\",\"6\":\"0.088958510\",\"7\":\"-0.068629486\"},{\"1\":\"Save The Day (feat. Coi Leray & LouGotCash)\",\"2\":\"Ski Mask The Slump God;Jacquees;Coi Leray;LouGotCash\",\"3\":\"-2.82486281\",\"4\":\"-0.4439059821\",\"5\":\"0.0631577016\",\"6\":\"-0.949223481\",\"7\":\"-0.093988215\"},{\"1\":\"Let Go\",\"2\":\"Beau Young Prince\",\"3\":\"-0.80221647\",\"4\":\"-1.2838403171\",\"5\":\"0.3975406003\",\"6\":\"-0.234382944\",\"7\":\"1.153703836\"},{\"1\":\"Scared of the Dark (feat. XXXTENTACION)\",\"2\":\"Lil Wayne;Ty Dolla $ign;XXXTENTACION\",\"3\":\"-1.11313005\",\"4\":\"-0.4587690942\",\"5\":\"0.0847033629\",\"6\":\"1.211246537\",\"7\":\"0.141529336\"},{\"1\":\"Elevate (feat. Denzel Curry, YBN Cordae, SwaVay, Trevor Rich)\",\"2\":\"DJ Khalil;Denzel Curry;Cordae;Swavay;Trevor Rich\",\"3\":\"-3.41480297\",\"4\":\"2.7848300712\",\"5\":\"-0.1119101405\",\"6\":\"-0.336843768\",\"7\":\"-0.469828514\"},{\"1\":\"Home\",\"2\":\"Vince Staples;Richie Kohan\",\"3\":\"-1.77357867\",\"4\":\"-0.4846303220\",\"5\":\"1.3798168830\",\"6\":\"-0.906695785\",\"7\":\"-0.245980340\"},{\"1\":\"2049\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.81775810\",\"4\":\"-0.4153831107\",\"5\":\"-0.7908287889\",\"6\":\"0.178656175\",\"7\":\"1.456610215\"},{\"1\":\"Sapper's Tree\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.33192397\",\"4\":\"-1.2226264174\",\"5\":\"-0.5879356078\",\"6\":\"0.481714901\",\"7\":\"1.182838173\"},{\"1\":\"Flight to LAPD\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"1.44121624\",\"4\":\"0.9268272633\",\"5\":\"-1.8705880402\",\"6\":\"-0.358987715\",\"7\":\"0.722942237\"},{\"1\":\"Summer Wind\",\"2\":\"Frank Sinatra\",\"3\":\"0.30857063\",\"4\":\"-0.5579260616\",\"5\":\"0.6936783500\",\"6\":\"0.145706347\",\"7\":\"0.642113069\"},{\"1\":\"Rain\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.51448650\",\"4\":\"-1.4462658626\",\"5\":\"0.6824169895\",\"6\":\"-0.764207200\",\"7\":\"1.020368775\"},{\"1\":\"Wallace\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.22653053\",\"4\":\"0.4181338858\",\"5\":\"0.1855275482\",\"6\":\"-1.003550088\",\"7\":\"0.763869335\"},{\"1\":\"Memory\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.95316989\",\"4\":\"-0.7912833681\",\"5\":\"1.4058953829\",\"6\":\"-0.830386144\",\"7\":\"-0.108008062\"},{\"1\":\"Mesa\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.73435277\",\"4\":\"-0.1387615057\",\"5\":\"-1.0760412885\",\"6\":\"0.345698598\",\"7\":\"1.340415574\"},{\"1\":\"Orphanage\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.79137364\",\"4\":\"0.7284440015\",\"5\":\"-1.9879516756\",\"6\":\"-2.322427292\",\"7\":\"2.173683056\"},{\"1\":\"Furnace\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.23975649\",\"4\":\"-0.2163769200\",\"5\":\"-0.8962048718\",\"6\":\"-0.075303336\",\"7\":\"1.442095625\"},{\"1\":\"Someone Lived This\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.41486457\",\"4\":\"-0.9823395527\",\"5\":\"0.9968193891\",\"6\":\"-0.354379899\",\"7\":\"0.957940344\"},{\"1\":\"Joi\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.84745854\",\"4\":\"-0.3597339041\",\"5\":\"-1.0551442122\",\"6\":\"-0.022143603\",\"7\":\"1.452785478\"},{\"1\":\"Pilot\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.85600019\",\"4\":\"-0.3849801497\",\"5\":\"-0.2590706316\",\"6\":\"0.183203869\",\"7\":\"0.746280274\"},{\"1\":\"Suspicious Minds\",\"2\":\"Elvis Presley\",\"3\":\"-0.79000596\",\"4\":\"-0.4027555669\",\"5\":\"0.1488505171\",\"6\":\"0.223469384\",\"7\":\"0.457970794\"},{\"1\":\"Can't Help Falling in Love\",\"2\":\"Elvis Presley;The Jordanaires\",\"3\":\"1.48432704\",\"4\":\"-0.4408917490\",\"5\":\"-1.1721259207\",\"6\":\"-0.309267780\",\"7\":\"1.278412496\"},{\"1\":\"One For My Baby (And One More For The Road)\",\"2\":\"Frank Sinatra\",\"3\":\"2.70691890\",\"4\":\"1.4187457770\",\"5\":\"-1.2319424753\",\"6\":\"-0.824620207\",\"7\":\"0.560162700\"},{\"1\":\"Hijack\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"1.92023306\",\"4\":\"0.5419909730\",\"5\":\"1.0181101115\",\"6\":\"-0.211543418\",\"7\":\"0.127214284\"},{\"1\":\"That's Why We Believe\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"3.76008507\",\"4\":\"0.0768427070\",\"5\":\"0.9085172952\",\"6\":\"-1.347590318\",\"7\":\"-0.015213860\"},{\"1\":\"Her Eyes Were Green\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"4.17256747\",\"4\":\"-0.7672641482\",\"5\":\"1.1997031087\",\"6\":\"-0.241442651\",\"7\":\"0.652492844\"},{\"1\":\"Sea Wall\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"1.71818304\",\"4\":\"-0.4193809007\",\"5\":\"0.4748144283\",\"6\":\"2.358150570\",\"7\":\"0.213807507\"},{\"1\":\"All the Best Memories Are Hers\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"4.01162615\",\"4\":\"-1.7207426457\",\"5\":\"0.2381828691\",\"6\":\"1.463801895\",\"7\":\"0.663182672\"},{\"1\":\"Tears in the Rain\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.65752743\",\"4\":\"0.0516932638\",\"5\":\"-1.4912070131\",\"6\":\"-0.079334074\",\"7\":\"1.192423431\"},{\"1\":\"Blade Runner\",\"2\":\"Hans Zimmer;Benjamin Wallfisch\",\"3\":\"2.26863137\",\"4\":\"-0.4706237791\",\"5\":\"0.3252200819\",\"6\":\"2.443638778\",\"7\":\"0.152892772\"},{\"1\":\"Almost Human - from the Original Motion Picture Soundtrack Blade Runner 2049\",\"2\":\"Lauren Daigle\",\"3\":\"-0.68251826\",\"4\":\"0.0968384766\",\"5\":\"0.8497578512\",\"6\":\"-0.816894540\",\"7\":\"-0.470016629\"},{\"1\":\"The Great Die-Off\",\"2\":\"Rise Against\",\"3\":\"-1.64551301\",\"4\":\"1.0669589033\",\"5\":\"-0.0552539370\",\"6\":\"0.896562281\",\"7\":\"0.399940879\"},{\"1\":\"I Don’t Want To Be Here Anymore\",\"2\":\"Rise Against\",\"3\":\"-1.63082268\",\"4\":\"1.4453499797\",\"5\":\"0.3095560223\",\"6\":\"-0.107179431\",\"7\":\"-0.468699019\"},{\"1\":\"Tragedy + Time\",\"2\":\"Rise Against\",\"3\":\"-1.60469514\",\"4\":\"1.5274135333\",\"5\":\"-0.3324926603\",\"6\":\"-0.364938459\",\"7\":\"0.470943396\"},{\"1\":\"The Black Market\",\"2\":\"Rise Against\",\"3\":\"-1.61518685\",\"4\":\"2.1363335114\",\"5\":\"-0.4907496985\",\"6\":\"1.397078742\",\"7\":\"-0.435806296\"},{\"1\":\"The Eco-Terrorist In Me\",\"2\":\"Rise Against\",\"3\":\"-1.90343757\",\"4\":\"2.3919288757\",\"5\":\"0.7803649372\",\"6\":\"-0.914561159\",\"7\":\"-0.609503310\"},{\"1\":\"Sudden Life\",\"2\":\"Rise Against\",\"3\":\"-1.01296876\",\"4\":\"0.9945065921\",\"5\":\"0.1307008316\",\"6\":\"1.063099458\",\"7\":\"0.360161170\"},{\"1\":\"A Beautiful Indifference\",\"2\":\"Rise Against\",\"3\":\"-1.49636599\",\"4\":\"0.2337521911\",\"5\":\"0.4932413072\",\"6\":\"-0.016634411\",\"7\":\"0.063983908\"},{\"1\":\"Methadone\",\"2\":\"Rise Against\",\"3\":\"-1.46209322\",\"4\":\"1.2936171840\",\"5\":\"-0.9164921826\",\"6\":\"0.297253658\",\"7\":\"-0.025784030\"},{\"1\":\"Zero Visibility\",\"2\":\"Rise Against\",\"3\":\"-1.09240057\",\"4\":\"2.7135647115\",\"5\":\"-0.9907635845\",\"6\":\"-0.479157226\",\"7\":\"-0.193237527\"},{\"1\":\"Awake Too Long\",\"2\":\"Rise Against\",\"3\":\"-1.48410418\",\"4\":\"0.5862485651\",\"5\":\"-1.2988913464\",\"6\":\"0.640183037\",\"7\":\"1.088982589\"},{\"1\":\"People Live Here\",\"2\":\"Rise Against\",\"3\":\"0.65735225\",\"4\":\"-0.0983660407\",\"5\":\"0.8535669045\",\"6\":\"-1.057226445\",\"7\":\"1.219781476\"},{\"1\":\"Bridges\",\"2\":\"Rise Against\",\"3\":\"-0.38796932\",\"4\":\"2.6619118261\",\"5\":\"-2.4958945518\",\"6\":\"-2.022541800\",\"7\":\"1.378915880\"},{\"1\":\"Escape Artists\",\"2\":\"Rise Against\",\"3\":\"-1.20250684\",\"4\":\"0.1008012823\",\"5\":\"0.0244528497\",\"6\":\"0.254324454\",\"7\":\"1.099665234\"},{\"1\":\"About Damn Time\",\"2\":\"Rise Against\",\"3\":\"-1.83138188\",\"4\":\"1.7468648582\",\"5\":\"0.3260366441\",\"6\":\"-1.107642782\",\"7\":\"-0.197915775\"},{\"1\":\"We Will Never Forget\",\"2\":\"William Potter\",\"3\":\"0.20106314\",\"4\":\"5.1250389942\",\"5\":\"-2.4213931023\",\"6\":\"-5.343092416\",\"7\":\"2.606961167\"},{\"1\":\"Main Title\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"2.60873218\",\"4\":\"-1.4457633669\",\"5\":\"-2.1485721542\",\"6\":\"0.819891375\",\"7\":\"-1.908116545\"},{\"1\":\"Imperial Attack\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"3.77919486\",\"4\":\"-1.7909957433\",\"5\":\"-1.2113610694\",\"6\":\"0.001860006\",\"7\":\"-1.857230348\"},{\"1\":\"Princess Leia's Theme\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"4.42403649\",\"4\":\"-1.4149103769\",\"5\":\"-1.7318676071\",\"6\":\"-1.242963856\",\"7\":\"-1.370795013\"},{\"1\":\"The Desert and the Robot Auction\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"3.81117801\",\"4\":\"-1.6314073180\",\"5\":\"-2.2441791072\",\"6\":\"-0.121226940\",\"7\":\"-1.854783211\"},{\"1\":\"Ben's Death and TIE Fighter Attack\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"2.27220844\",\"4\":\"-2.4923261429\",\"5\":\"-0.3283172273\",\"6\":\"0.608886104\",\"7\":\"-2.978431170\"},{\"1\":\"The Little People Work\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"3.19097945\",\"4\":\"-1.3086553721\",\"5\":\"-0.9596127067\",\"6\":\"-0.430402014\",\"7\":\"-2.287719792\"},{\"1\":\"Rescue of the Princess\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"2.38667776\",\"4\":\"-0.6342925892\",\"5\":\"-1.0887816144\",\"6\":\"-0.475399241\",\"7\":\"-3.276477045\"},{\"1\":\"Inner City\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"4.01556754\",\"4\":\"-0.8505038220\",\"5\":\"-1.8802292452\",\"6\":\"-1.063342180\",\"7\":\"-1.706797256\"},{\"1\":\"Cantina Band\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"-0.69806878\",\"4\":\"-1.6777297447\",\"5\":\"-3.6054783061\",\"6\":\"-0.984388657\",\"7\":\"-1.264595765\"},{\"1\":\"The Land of the Sand People\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"2.64620473\",\"4\":\"-0.6030173418\",\"5\":\"-1.6379166998\",\"6\":\"-0.504998502\",\"7\":\"-3.170663660\"},{\"1\":\"Mouse Robot and Blasting Off\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"2.92004629\",\"4\":\"-1.4664413891\",\"5\":\"-0.9102640194\",\"6\":\"0.113414715\",\"7\":\"-2.781597900\"},{\"1\":\"The Return Home\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"3.78067649\",\"4\":\"-1.4998845739\",\"5\":\"-2.6051060197\",\"6\":\"-0.687859534\",\"7\":\"-1.109949773\"},{\"1\":\"The Walls Converge\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"4.07804428\",\"4\":\"-0.9164102110\",\"5\":\"-2.3868942406\",\"6\":\"-0.589840100\",\"7\":\"-1.542077609\"},{\"1\":\"The Princess Appears\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"5.26296892\",\"4\":\"-0.0891251254\",\"5\":\"-2.5072088736\",\"6\":\"-3.405512440\",\"7\":\"-0.821586375\"},{\"1\":\"The Last Battle\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"3.03618951\",\"4\":\"0.7945361935\",\"5\":\"-0.7362002783\",\"6\":\"1.412263240\",\"7\":\"-4.091219665\"},{\"1\":\"The Throne Room and End Title\",\"2\":\"John Williams;London Symphony Orchestra\",\"3\":\"2.82560346\",\"4\":\"-2.4890250531\",\"5\":\"-1.8683007820\",\"6\":\"0.637414966\",\"7\":\"-1.451599937\"},{\"1\":\"Dvorák: Symphony No. 1 in C Minor, B. 9, \\\"The Bells of Zlonice\\\": I. Allegro\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.44073063\",\"4\":\"2.6116783338\",\"5\":\"-0.0552672421\",\"6\":\"0.900112096\",\"7\":\"-1.038028974\"},{\"1\":\"Dvorák: Symphony No. 1 in C Minor, B. 9, \\\"The Bells of Zlonice\\\": II. Adagio di molto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.83657688\",\"4\":\"0.0257770568\",\"5\":\"1.6425145027\",\"6\":\"0.474272622\",\"7\":\"0.257166427\"},{\"1\":\"Dvorák: Symphony No. 1 in C Minor, B. 9, \\\"The Bells of Zlonice\\\": III. Allegretto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.17681402\",\"4\":\"0.1337651432\",\"5\":\"0.4161910892\",\"6\":\"1.053441546\",\"7\":\"-0.597236772\"},{\"1\":\"Dvorák: Symphony No. 1 in C Minor, B. 9, \\\"The Bells of Zlonice\\\": IV. Finale (Allegro animato)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.32033775\",\"4\":\"1.1741602712\",\"5\":\"-0.3772397739\",\"6\":\"1.925680191\",\"7\":\"-0.191757984\"},{\"1\":\"Dvorák: Slavonic Dance No. 4 in D-Flat Major, Op. 72: Allegro\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.01674298\",\"4\":\"1.6479131619\",\"5\":\"-1.5234074289\",\"6\":\"-0.082309608\",\"7\":\"0.308450981\"},{\"1\":\"Dvorák: Slavonic Dance No. 8 in A-Flat Major, Op .72: Grazioso e lento, ma non troppo, quasi tempo di valse\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.17785440\",\"4\":\"0.5730823776\",\"5\":\"0.2285977064\",\"6\":\"-1.154657387\",\"7\":\"0.621853030\"},{\"1\":\"Dvorák: 8 Slavonic Dances, Op. 46, B. 83: No. 3 in A-Flat Major\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.77484455\",\"4\":\"-0.6731365449\",\"5\":\"1.0724834298\",\"6\":\"-0.255456266\",\"7\":\"0.547818490\"},{\"1\":\"Dvorák: 8 Slavonic Dances, Op. 72, B. 147: No. 15 in C Major\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"2.21518260\",\"4\":\"0.6322973827\",\"5\":\"0.2921399244\",\"6\":\"0.234802614\",\"7\":\"-0.217771359\"},{\"1\":\"Dvorák: 8 Slavonic Dances, Op. 46, B. 83: No. 4 in F Major\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.41113050\",\"4\":\"0.4364846052\",\"5\":\"-1.0863961155\",\"6\":\"-0.427233564\",\"7\":\"0.818498047\"},{\"1\":\"Dvorák: Symphony No. 2 in B-Flat Major, Op. 4, B. 12: I. Allegro con moto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.15093598\",\"4\":\"0.7751688908\",\"5\":\"1.5719153168\",\"6\":\"-0.001285407\",\"7\":\"-0.184686404\"},{\"1\":\"Dvorák: Symphony No. 2 in B-Flat Major, Op. 4, B. 12: II. Poco adagio\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.89091284\",\"4\":\"0.3176939400\",\"5\":\"1.8530447930\",\"6\":\"0.076375855\",\"7\":\"0.052970837\"},{\"1\":\"Dvorák: Symphony No. 2 in B-Flat Major, Op. 4, B. 12: III. Scherzo (Allegro con brio)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.23407532\",\"4\":\"1.5975327341\",\"5\":\"0.6809262664\",\"6\":\"-0.916736018\",\"7\":\"0.035770458\"},{\"1\":\"Dvorák: Symphony No. 2 in B-Flat Major, Op. 4, B. 12: IV. Finale (Allegro con fuoco)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.57470415\",\"4\":\"0.6620416223\",\"5\":\"1.5277890234\",\"6\":\"0.165507244\",\"7\":\"-0.193966842\"},{\"1\":\"Dvorák: Symphony No. 3 in E-Flat Major, Op. 10, B. 34: I. Allegro moderato\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.48337659\",\"4\":\"0.8509959754\",\"5\":\"-0.3336765166\",\"6\":\"0.084509512\",\"7\":\"0.637065110\"},{\"1\":\"Dvorák: Symphony No. 3 in E-Flat Major, Op. 10, B. 34: II. Adagio molto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"5.37114333\",\"4\":\"0.3979846566\",\"5\":\"0.3955006554\",\"6\":\"1.582593521\",\"7\":\"0.311075123\"},{\"1\":\"Dvorák: Symphony No. 3 in E-Flat Major, Op. 10, B. 34: III. Finale (Allegro vivace)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.00835644\",\"4\":\"0.1565925176\",\"5\":\"1.4927774896\",\"6\":\"0.084854777\",\"7\":\"-0.028378236\"},{\"1\":\"Dvorák: Symphony No. 6 in D Major, Op. 60, B. 112: I. Allegro non tanto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.84465038\",\"4\":\"2.0187234322\",\"5\":\"-0.5359276260\",\"6\":\"0.611006090\",\"7\":\"0.071610710\"},{\"1\":\"Dvorák: Symphony No. 6 in D Major, Op. 60, B. 112: II. Adagio\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.87623440\",\"4\":\"0.3879753407\",\"5\":\"1.8040403724\",\"6\":\"0.149519928\",\"7\":\"-0.054439532\"},{\"1\":\"Dvorák: Symphony No. 6 in D Major, Op. 60, B. 112: III. Scherzo (Furiant. Presto)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.83572130\",\"4\":\"0.8983754008\",\"5\":\"-1.1032810447\",\"6\":\"-0.392735077\",\"7\":\"0.632176253\"},{\"1\":\"Dvorák: Symphony No. 6 in D Major, Op. 60, B. 112: IV. Finale (Allegro con spirito)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.27017685\",\"4\":\"0.4486152336\",\"5\":\"-0.0192599863\",\"6\":\"1.282784390\",\"7\":\"0.073871916\"},{\"1\":\"Dvorák: Symphony No. 5 in F Major, Op. 76, B. 54: I. Allegro ma non troppo\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.14713917\",\"4\":\"0.7457604524\",\"5\":\"0.6014153225\",\"6\":\"0.753005114\",\"7\":\"-0.063798182\"},{\"1\":\"Dvorák: Symphony No. 5 in F Major, Op. 76, B. 54: II. Andante con moto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.70830726\",\"4\":\"1.0388279238\",\"5\":\"1.5935796476\",\"6\":\"-0.642764105\",\"7\":\"-1.241870451\"},{\"1\":\"Dvorák: Symphony No. 5 in F Major, Op. 76, B. 54: III. Scherzo (Allegro scherzando)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.71800814\",\"4\":\"-0.2674690132\",\"5\":\"1.4368317083\",\"6\":\"-0.404279993\",\"7\":\"0.253225357\"},{\"1\":\"Dvorák: Symphony No. 5 in F Major, Op. 76, B. 54: IV. Finale (Allegro molto)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.30632977\",\"4\":\"-0.0327339228\",\"5\":\"1.0834324989\",\"6\":\"0.979173342\",\"7\":\"0.315456522\"},{\"1\":\"Dvorák: Symphony No. 4 in D Minor, Op. 13, B. 41: I. Allegro\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.34742780\",\"4\":\"1.5914336091\",\"5\":\"0.7705027106\",\"6\":\"-0.806129801\",\"7\":\"-0.007091761\"},{\"1\":\"Dvorák: Symphony No. 4 in D Minor, Op. 13, B. 41: II. Allegro sostenuto e molto cantabile\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.50151503\",\"4\":\"0.8518596463\",\"5\":\"1.2530205485\",\"6\":\"-0.332849587\",\"7\":\"-0.250954076\"},{\"1\":\"Dvorák: Symphony No. 4 in D Minor, Op. 13, B. 41: III. Scherzo (Allegro feroce)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.39131971\",\"4\":\"-0.8475403498\",\"5\":\"0.9725344535\",\"6\":\"-0.056250096\",\"7\":\"0.657855366\"},{\"1\":\"Dvorák: Symphony No. 4 in D Minor, Op. 13, B. 41: IV. Finale (Allegro con brio)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.87606616\",\"4\":\"-0.0978858597\",\"5\":\"0.1406670036\",\"6\":\"1.095955739\",\"7\":\"0.407114495\"},{\"1\":\"Dvorák : 8 Slavonic Dances Op.46 : No.8 in G minor\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"2.32015944\",\"4\":\"0.9324042531\",\"5\":\"-0.3298957341\",\"6\":\"-0.716863404\",\"7\":\"0.360223958\"},{\"1\":\"Dvorák: Symphony No. 7 in D Minor, Op.70, B. 141: I. Allegro maestoso\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.35624492\",\"4\":\"1.1531576548\",\"5\":\"1.0959868184\",\"6\":\"-0.485935305\",\"7\":\"0.199302280\"},{\"1\":\"Dvorák: Symphony No. 7 in D Minor, Op.70, B. 141: II. Poco adagio\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.58083680\",\"4\":\"1.5308661388\",\"5\":\"-0.3130257208\",\"6\":\"-0.312097203\",\"7\":\"0.241018245\"},{\"1\":\"Dvorák: Symphony No. 7 in D Minor, Op.70, B. 141: III. Scherzo (Vivace)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.75404351\",\"4\":\"0.9571980386\",\"5\":\"-0.0516130152\",\"6\":\"-0.357383792\",\"7\":\"-0.335193372\"},{\"1\":\"Dvorák: Symphony No. 7 in D Minor, Op.70, B. 141: IV. Finale (Allegro)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.46357830\",\"4\":\"0.1074080198\",\"5\":\"1.2577039272\",\"6\":\"-0.025675787\",\"7\":\"0.083281677\"},{\"1\":\"Dvorák: In Nature's Realm, Op. 91, B. 168\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.69990906\",\"4\":\"2.9033520737\",\"5\":\"-0.3461715567\",\"6\":\"0.219342147\",\"7\":\"-0.415416634\"},{\"1\":\"Dvorák: Scherzo capriccioso, Op. 66, B. 131\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.59519288\",\"4\":\"0.8056999353\",\"5\":\"0.3346459460\",\"6\":\"1.443926250\",\"7\":\"0.055562245\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 1 in D Minor\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"2.89057347\",\"4\":\"1.4170837726\",\"5\":\"-0.0499101679\",\"6\":\"0.426385775\",\"7\":\"-1.250728863\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 2 in G Major\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"4.53879126\",\"4\":\"-0.0059857242\",\"5\":\"0.2653200299\",\"6\":\"-0.997422081\",\"7\":\"0.948966592\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 3 in G Minor\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"3.71645282\",\"4\":\"0.2180883529\",\"5\":\"0.9036275207\",\"6\":\"-0.847719465\",\"7\":\"0.019656250\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 4 in C Major\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"3.66900324\",\"4\":\"-0.0003161915\",\"5\":\"-0.5349847271\",\"6\":\"1.070178765\",\"7\":\"0.454103021\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 5 in A-Flat Major\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"4.24995153\",\"4\":\"-0.3449177404\",\"5\":\"1.0439192638\",\"6\":\"-0.238074975\",\"7\":\"0.409136057\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 6 in C-Sharp Minor\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"4.11397064\",\"4\":\"-0.0061679792\",\"5\":\"0.8174380630\",\"6\":\"-0.397808220\",\"7\":\"0.229763780\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 7 in A Major\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"3.08441728\",\"4\":\"0.1233657193\",\"5\":\"1.1285555890\",\"6\":\"0.002269651\",\"7\":\"0.041382502\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 8 in F Major\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"3.31854386\",\"4\":\"0.6602776130\",\"5\":\"0.5133782051\",\"6\":\"1.110067534\",\"7\":\"-0.189523988\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 9 in D Major\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"3.76840143\",\"4\":\"0.0814367066\",\"5\":\"-0.9289358221\",\"6\":\"-0.389836995\",\"7\":\"1.019141441\"},{\"1\":\"Dvorák: 10 Legends, Op. 59, B. 122: No. 10 in B-Flat Minor\",\"2\":\"Antonín Dvořák;José Serebrier, Bournemouth Symphony Orchestra;Bournemouth Symphony Orchestra;José Serebrier\",\"3\":\"3.95613574\",\"4\":\"-0.2905248232\",\"5\":\"1.2912765000\",\"6\":\"-0.592520668\",\"7\":\"0.268733547\"},{\"1\":\"Dvorák: Symphony No. 8 in G Major, Op. 88, B. 163: I. Allegro con brio\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.71394020\",\"4\":\"1.0099134994\",\"5\":\"0.7959019016\",\"6\":\"0.536961717\",\"7\":\"-0.308175651\"},{\"1\":\"Dvorák: Symphony No. 8 in G Major, Op. 88, B. 163: II. Adagio\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.05404505\",\"4\":\"0.9404453016\",\"5\":\"-0.5537878226\",\"6\":\"1.348831460\",\"7\":\"0.058984749\"},{\"1\":\"Dvorák: Symphony No. 8 in G Major, Op. 88, B. 163: III. Allegretto grazioso\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.80457025\",\"4\":\"0.8562604847\",\"5\":\"1.0321669342\",\"6\":\"-0.767926343\",\"7\":\"-0.515557768\"},{\"1\":\"Dvorák: Symphony No. 8 in G Major, Op. 88, B. 163: IV. Allegro ma non troppo\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.86920411\",\"4\":\"0.5080404842\",\"5\":\"0.6672217749\",\"6\":\"-0.004144144\",\"7\":\"-0.001110676\"},{\"1\":\"Dvorák : 8 Slavonic Dances, Op.46 B83 : No.1 in C major [Presto]\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"2.78378742\",\"4\":\"1.3523925166\",\"5\":\"-1.2664846126\",\"6\":\"0.942357630\",\"7\":\"0.298891820\"},{\"1\":\"Dvorák: Symphony No. 9 in E Minor, Op. 95, B. 178, \\\"From the New World\\\": I. Adagio - Allegro molto\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.56330169\",\"4\":\"1.0488812079\",\"5\":\"1.1945134408\",\"6\":\"0.814301479\",\"7\":\"-1.160578181\"},{\"1\":\"Dvorák: Symphony No. 9 in E Minor, Op. 95, B. 178, \\\"From the New World\\\": II. Largo\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.88323703\",\"4\":\"0.1337600107\",\"5\":\"-0.0598227567\",\"6\":\"1.113827866\",\"7\":\"0.308664654\"},{\"1\":\"Dvorák: Symphony No. 9 in E Minor, Op. 95, B. 178, \\\"From the New World\\\": III. Molto vivace\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.34111672\",\"4\":\"1.3671162108\",\"5\":\"-0.4789756597\",\"6\":\"0.229674900\",\"7\":\"0.170404356\"},{\"1\":\"Dvorák: Symphony No. 9 in E Minor, Op. 95, B. 178, \\\"From the New World\\\": IV. Allegro con fuoco\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.25469609\",\"4\":\"0.9907397326\",\"5\":\"0.9627185110\",\"6\":\"0.608668658\",\"7\":\"-1.200497257\"},{\"1\":\"Dvorák: Czech Suite, Op. 39, B. 93: I. Preludium\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.34758817\",\"4\":\"-0.4908813992\",\"5\":\"-0.0930452757\",\"6\":\"0.582379420\",\"7\":\"0.656194120\"},{\"1\":\"Dvorák: Czech Suite, Op. 39, B. 93: II. Polka\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.43213553\",\"4\":\"0.2799486809\",\"5\":\"0.4185325078\",\"6\":\"0.296874003\",\"7\":\"-0.669081669\"},{\"1\":\"Dvorák: Czech Suite, Op. 39, B. 93: III. Sousedská\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.71946223\",\"4\":\"-0.4797289205\",\"5\":\"0.5270401960\",\"6\":\"0.362365341\",\"7\":\"0.524409526\"},{\"1\":\"Dvorák: Czech Suite, Op. 39, B. 93: IV. Romanza\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"4.27463570\",\"4\":\"-0.4661702521\",\"5\":\"0.9421469045\",\"6\":\"-0.028350571\",\"7\":\"0.472189806\"},{\"1\":\"Dvorák: Czech Suite, Op. 39, B. 93: V. Finale (Furiant)\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"2.86882242\",\"4\":\"0.6361925559\",\"5\":\"-0.2118747991\",\"6\":\"-0.517441164\",\"7\":\"-0.217134838\"},{\"1\":\"Dvorák : 8 Slavonic Dances, Op.72 : No.2 in E minor 'Starodávny' [Allegretto grazioso]\",\"2\":\"Antonín Dvořák;José Serebrier;Bournemouth Symphony Orchestra\",\"3\":\"3.97608229\",\"4\":\"0.0689351309\",\"5\":\"-0.7307675445\",\"6\":\"0.748409016\",\"7\":\"0.484679570\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nAs always, this only becomes clear with a plot:\n\n\nplt <- songs_baked %>% \n  mutate(song = paste(track_name, \",\", track_artists)) %>% \n  ggplot(aes(PC1, PC2, label = song)) +\n  geom_hline(yintercept = 0, alpha = 0.3) +\n  geom_vline(xintercept = 0, alpha = 0.3) +\n  geom_point()\n\nplotly::ggplotly(plt)\n\n\npreserve1d40387106d5cd4a\n\nYou can now imagine, using this simpler representation of the songs in principal component space, to for example propose new songs to users based on songs that are close to songs they listened to in this representation.\nLastly, I want to stress, that the principal components are not created equal. The first component is always the most important. Here, we see, that almost 40% of the variance can be explained just by the first component, so exploring more than 2 really makes little sense here.\n\n\nsdev <- songs_prep$steps[[2]]$res$sdev\npercent_variation <- sdev^2 / sum(sdev^2)\n\ntibble(component = unique(songs_compontents$component),\n       percent_var = percent_variation) %>%\n  mutate(component = fct_inorder(component)) %>%\n  ggplot(aes(component, percent_var)) +\n  geom_col() +\n  scale_y_continuous(labels = scales::percent_format()) +\n  labs(x = NULL, y = \"Percent variance explained by each PCA component\")\n\n\n\n\nExercises\nThe tidytuesday project also had a spotify dataset. This one es even more interesting, because it ranges across different playlists of various genres and is annotated with said genres. And it has more data (Over 30000 songs)! Download it here:\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md\nThe Plotty Horror Picture Show\nSometimes we have to experience true horror to see the light in the darkness. Take the spotify data and make a plot that is truly horrible! I would appreciate a couple of sentences about your thought process and what makes your plot particularly bad. You can strike terror into the reader’s heart in multiple ways. Here are some ideas, mix and match what suits you:\nMake it really ugly by experimenting with different theme options.\nMake it really misleading by defying viewer expectations and breaking all norms. You are an artist now, norms don’t apply to your art.\nTry out different geoms and combinations of aesthetics, maybe find the ones that are the worst possible choice for the features.\nTake a Sad Plot and Make it Better\nThe title of this exercise is stolen from this talk by Alison Hill.\nNow use what you learned to make a great plot! Pick some features that you are interested in and visualize them as informative and beautiful as possible, while still staying honest to the data. Maybe you are interested in changes over time, maybe you find your favorite artist and want to situate them in the context of other works. Maybe you want to explore how different features relate to each other or even want to attempt to recreate the PCA to see, if you can find clusters of genres. It is your call.\nI am curious to see, what you come up with!\nStats Time\nThere is no exercise on statistics here, but please think about the topics of today’s lecture and note down questions that come up, so we can talk about them on Friday.\nResources\nTidymodels website\nTidymodels book\nggplot book\nragg graphics device\n\n\n\n“Artwork by @allison_horst.” 2020. https://github.com/allisonhorst/stats-illustrations.\n\n\n“Welcome | Ggplot2.” n.d. https://ggplot2-book.org/.\n\n\nWickham, Hadley. 2016. Ggplot2: Elegant Graphics for Data Analysis. 2nd ed. 2016 edition. New York, NY: Springer.\n\n\n\n\n",
    "preview": "lectures/lecture6/lecture6_files/figure-html5/unnamed-chunk-38-1.png",
    "last_modified": "2020-12-07T01:26:35+01:00",
    "input_file": "lecture6.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "lectures/lecture5/",
    "title": "Lecture 5",
    "description": "... in which we reason about the nature of randomness and\ndiscover various statistical tests.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-30",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nMotivation\nStatistically Significant…\nGetting our Hands dirty with Probability\nDefinitions: Hypothesis\nTesting the Null Hypothesis with a Simulation\nGetting precise with the Binomial Distribution\nBut how much better? Understanding Effect Size and Power, False Positives and False Negatives\n\nP-Value Pitfalls\nMultiple Testing Correction\nOther forms of p-hacking\n\nBayesian Statistics and the Base Rate Fallacy\nConcepts discussed today\n\nExercises\nDiscovering a new Distribution\n\nResources\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen. Press ? for a list of keyboard shortcuts.\n\n\n\n\nScript\nMotivation\nIn the first four lectures we covered the fundamentals of handling data with R. Now, we will shift our focus away from the how and towards the why of data analysis. We will talk about different statistical tests, common mistakes, how to avoid them and how to spot them in other research. But of course, we will do so using R. So you will still learn one or the other useful function or technique along the way. In most instances it should be clear when I use R solely to demonstrate an idea from statistics and the code is just included for the curious, or whether the code is something you will likely also use for your own analysis. I am open for questions if things are unclear in any of the two cases. For purely aesthetic code I might also speed up the typing in the edit.\n\nTo understand statistics means understanding the nature of randomness first.\n\nYou might not be shocked that we will be using the tidyverse today as well, simply because it makes the data wrangling for various demonstrations easier. So if you are following along, don’t forget:\n\n\nlibrary(tidyverse)\n\n\n\nStatistically Significant…\n\n…you keep using that word. I don’t think it means what you think it means.\n\n\n\n\nFigure 1: A Meme where a person says: “Statistically significant. You keep using that word. I don’t think it means what you think it means.”\n\n\n\nYou will hear the phrases “statistically significant,” “significant” or even “very significant” thrown around quite a bit in academic literature . And while they are often used carelessly, they have a clearly defined meaning. A meaning we will uncover today. This meaning is related to the concept of so called p-values, which have an equally bad reputation for frequently being misused. The p in p-value stands for probability, so in order to understand p-values, we need to understand probability and learn how to deal with randomness, chance, or luck if you will. So…\nGetting our Hands dirty with Probability\n\n\n\nFigure 2: A ggplot chessboard\n\n\n\nSay you and you friend are playing a game of chess, when your friend proudly proclaims:\n“I am definitely the better player!”\n“Proof it!” you reply.\n“That’s easy,” she says: “I won 7 out of the 8 rounds we played to today.”\n“Pah! That’s just luck.” is your less witty and slightly stubborn response.\nAs expected, we shall be using R to resolve this vital conflict.\n\n\n\n\nFigure 3: “Artwork by @allison_horst” (2020)\n\n\n\nDefinitions: Hypothesis\nBoth of you involuntarily uttered an hypothesis, a testable assumption. And we want to test these hypothesis using statistics. The first hypothesis (“I am the better player.”) is what we call the alternative hypothesis (\\(H_1\\)). The name can be a bit confusing, because most often, this is your actual scientific hypothesis, the thing you are interested in. So, alternative to what? It is alternative to the so called null hypothesis (\\(H_0\\)), which is the second statement (“This is just luck”). The null hypothesis provides a sort of baseline for all our findings. It usually goes along the lines of “What if our observations are just based on chance alone?” where “chance” can be any source of random variation in our system.\nThe tricky part is that there is no way to directly test the alternative Hypothesis, all we can test is the null hypothesis. Because for any null hypothesis we discard, there are always multiple alternative hypothesis that could explain our data. In our example, even if we end up discarding the idea of our friend’s chess success being only down to luck, this does not prove the alternative hypothesis that she is the better player (she could still be cheating for example). Do keep this in mind when we transfer this to a more scientific setting. Just because we show that something is unlikely to have arisen by chance does not mean that your favorite alternative hypothesis is automatically true.\nSo, after these words of warning, let’s test some null hypothesis!\nTesting the Null Hypothesis with a Simulation\nWe will start off by building a little simulation. Before testing any hypothesis, it is important to have defined \\(H_0\\) and \\(H_1\\) properly, which we did in the previous section. But we need to be a little more specific. Winning by chance would entail a completely random process, which we can model with a coin flip. R has the lovely function sample to take any number of things from a vector, with or without replacement after taking each thing:\n\n\ncoin <- c(\"heads\", \"tails\")\nsample(coin)\n\n\n[1] \"tails\" \"heads\"\n\nNot giving it a number of things to draw just shuffles the vector, which is fairly boring in the case of just two tings. We can’t sample 10 things from a vector of only two elements\n\n\nsample(coin, size = 10)\n\n\nError in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\nBut we can, if we put the thing back every time:\n\n\nsample(coin, size = 10, replace = TRUE)\n\n\n [1] \"heads\" \"heads\" \"tails\" \"tails\" \"heads\" \"heads\" \"tails\" \"tails\"\n [9] \"heads\" \"heads\"\n\nSo, let’s make this a little more specific to our question:\n\n\nwinner <- c(\"you\", \"friend\")\nrandom_winners <- sample(winner, size = 8, replace = TRUE)\nrandom_winners\n\n\n[1] \"you\"    \"you\"    \"you\"    \"friend\" \"friend\" \"friend\" \"you\"   \n[8] \"you\"   \n\nThis script will look different every time I run this, so I won’t be to specific on the outcome of this. This time, you won:\n\n\nsum(random_winners == \"you\")\n\n\n[1] 5\n\ntimes, and your friend won:\n\n\nsum(random_winners == \"friend\")\n\n\n[1] 3\n\ntimes. If we were to run this script a million times, the resulting proportion of random wins for both of you would be very, very close to 50-50 because we used a fair coin. However, we don’t have the time to play this much Chess and we sure don’t have the money to run a million replicates for each experiment in the lab. But here, in our little simulated world, we have near infinite resources (our simulation is not to computationally costly).\n\nOne trick used above: When we calculate e.g. a sum or mean, R automatically converts TRUE to 1 and FALSE to 0.\n\n\n\nget_n_wins <- function(N) {\n  winner <- c(\"you\", \"friend\")\n  random_winners <- sample(winner, size = N, replace = TRUE)\n  sum(random_winners == \"friend\")\n}\n\n\n\nI created a function that returns a random number of wins your friend would have gotten by pure chance for a number of rounds N.\n\n\nget_n_wins(10)\n\n\n[1] 7\n\nThis number is different every time, so how does it change?\n\n\nset.seed(42) # setting a random seed for the script\n             # this give me the same random numbers\n             # every time\nnumber_of_wins <- map_dbl(rep(8, 1000), get_n_wins)\n\n\n\nA histogram is a type of plot that shows how often each value occurs in a vector. Usually, the values are put into bins first, grouping close values together for continuous values, but in this case it makes sense to just have one value per bin because we are dealing with discrete values (e.g. no half-wins). Histograms can either display the raw counts or the frequency e.g. as a percentage. In ggplot, we use geom_bar when we don’t need any binning, just counting occurrences, and geom_histogram when we need to bin continuous values.\n\n\ntibble(number_of_wins) %>% \n  ggplot(aes(number_of_wins)) +\n  geom_bar() +\n  scale_x_continuous(breaks = 0:8) +\n  labs(title = \"Throwing a coin 8 times\")\n\n\n\n\nAs expected, the most common number of wins out of 8 is 4 (unless I got really unlucky when compiling this script). Let us see, how this distribution changes for different values of N. First, we set up a grid of numbers (all possible combinations) so that we can run a bunch of simulations:\n\n\nsimulation <-\n  crossing(N   = 1:15,\n           rep = 1:1000) %>% \n  mutate(\n    wins = map_dbl(N, get_n_wins)\n  )\n\nhead(simulation) %>% rmarkdown::paged_table()\n\n\n\n\n{\"columns\":[{\"label\":[\"N\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"rep\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"wins\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"1\",\"3\":\"0\"},{\"1\":\"1\",\"2\":\"2\",\"3\":\"0\"},{\"1\":\"1\",\"2\":\"3\",\"3\":\"1\"},{\"1\":\"1\",\"2\":\"4\",\"3\":\"1\"},{\"1\":\"1\",\"2\":\"5\",\"3\":\"0\"},{\"1\":\"1\",\"2\":\"6\",\"3\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nAnd then we use our trusty ggplot to visualize all the distributions:\n\n\nsimulation %>% \n  ggplot(aes(wins)) +\n  geom_bar() +\n  facet_wrap(~ N) +\n  labs(title = \"Throwing a coin N times\")\n\n\n\n\nWith a fair coin, the most common number of wins should be half of the number of coin flips. Note, how it is still possible to flip a coin 15 times and and not win a single time. It is just very unlikely and the bars are so small that we can’t see them.\nLet us go back to the original debate. The first statement: “I am better.” is something that can never be definitively proven. Because there is always the possibility, no matter how small, that the same result could have arisen by pure chance alone. Even if she wins 100 times and we don’t take a single game from her, this sort of outcome is still not impossible to appear just by flipping a coin. But what we can do, is calculate, how likely a certain event is under the assumption of the null hypothesis (only chance). And we can also decide on some threshold \\(\\alpha\\) at which we reject the null hypothesis. This is called the significance threshold. When we make an observation and then calculate that the probability for an observation like this or more extreme is smaller than the threshold, we deem the result statistically significant. And the probability thus created is called the p-value.\nFrom our simulation, we find the that probability to win 7 out of 8 rounds under the null hypothesis is:\n\n\nmean(number_of_wins >= 7)\n\n\n[1] 0.025\n\nWhich is smaller than the commonly used significance threshold of \\(\\alpha=0.05\\) (i.e. \\(5\\%\\)). So with 7 out of 8 wins, we would reject the null hypothesis. Do note that this threshold, no matter how commonly and thoughtlessly it is used throughout academic research, is completely arbitrary.\nGetting precise with the Binomial Distribution\nNow, this was just from a simulation with 1000 trials, so the number can’t be arbitrarily precise, but there is a mathematical formula for this probability. What we created by counting the number of successes in a series of yes-no-trials is a binomial distribution. For the most common distributions, R provides a set of functions. the functions starting with d give us the probability density function. In the case of discrete values like counting wins, this is equivalent to the actual probability, but for continuous values we obtain the probability by taking the integral. We get these integrals with the corresponding functions starting with p (for probability).\n\n\ndbinom(x = 7, size = 8, prob = 0.5)\n\n\n[1] 0.03125\n\nThis is the probability to win exactly 7 out of 8 games. But what we wanted was the probability for 7 or more out of 8! So we move to the integral. This part can get a bit confusing, because the default for pbinom is lower.tail = TRUE, which according to the help page means that probabilities are \\(P[X \\le x]\\).\n\n\npbinom(q = 7, size = 8, prob = 0.5)\n\n\n[1] 0.9960938\n\nIf we set lower.tail to FALSE , we get \\(P[X > x]\\), so the probability for a random variable X being bigger than a number x. So to get the probability that we are interested in, we need to replace the 7 with a 6 as well:\n\n\npbinom(q = 6, size = 8, prob = 0.5, lower.tail = FALSE)\n\n\n[1] 0.03515625\n\nOur simulation was pretty close! So the exact values agrees and we reject the null hypothesis of both opponents being equally good.\n\nSidenote: For quick visualizations of function curves I sometimes use plotting functions from base-R rather than ggplot. They are not as powerful and versatile, but efficient at their own small tasks. Just make sure to note that this is not ggplot, so we can’t use our regular repertoire of themes and the likes with it.\n\nHere is the full graph for the probability density function of the binomial distribution\n\n\ncurve(dbinom(x = x, 8, prob = 0.5),\n      type = \"s\", from = 0,\n      to = 8,\n      n = 9, main = \"dbinom\")\n\n\n\n\nAnd the integral, the probability \\(P[X \\le x]\\)\n\n\ncurve(pbinom(q = x, 8, prob = 0.5),\n      type = \"s\",\n      from = 0,\n      to = 8,\n      n = 9, main = \"pbinom\")\n\n\n\n\nThere is two more function I want to showcase from this family. The third is the so called quantile function. Quantiles divide a probability distribution into pieces of equal probability. One example for a quantile is the 50th percentile, also known as the median, which divides the values such that half of the values are above and half are below. And we can keep dividing the two halves as well, so that we end up with more quantiles. Eventually, we arrive at the quantile function. It is the inverse of the probability function, so you obtain it by swapping the axis.\n\n\ncurve(qbinom(p = x, size = 8, prob = 0.5),\n      type = \"s\",\n      from = 0,\n      to = 1,\n      n = 9, main = \"qbinom\"\n      )\n\n\n\n\nQuantiles will also be useful for deciding if a random sample follows a certain distribution with quantile-quantile plots.\nLastly, there is always also an r variant of the function, which gives us any number of random numbers from the distribution.\n\n\nrbinom(n = 10, size = 8, prob = 0.5)\n\n\n [1] 4 5 5 5 5 2 3 4 6 3\n\nBut how much better? Understanding Effect Size and Power, False Positives and False Negatives\nWe decided to abandon the null hypothesis that both players are equally good, which equates to a 50% win-chance for each player. But we have not determined how much better she is. And how much better does she need to be for us to reliably discard the null hypothesis after just 8 games? The generalization of the how much better part, the true difference, is called the effect size.\nOur ability to decide that something is statistically significant when there is in fact a true difference is called the statistical power. It depends on the effect size, our significance threshold \\(\\alpha\\) and the sample size \\(n\\) (the number of games). We can explore the concept with another simulation.\n\n\nset.seed(2020)\ntrials <- 10000\nsimulation <- crossing(\n  N = c(8, 100, 1000, 10000),\n  true_prob = c(0.5, 0.8, 0.9)\n) %>%\n  rowwise() %>%\n  mutate(\n    wins = list(rbinom(size = N,\n                       prob = true_prob,\n                       n = trials)),\n    p = list(pbinom(q = wins - 1,\n                    size = N,\n                    prob = 0.5, lower.tail = FALSE))\n    ) %>% \n  ungroup()\n\nsimulation\n\n\n# A tibble: 12 x 4\n       N true_prob wins           p             \n   <dbl>     <dbl> <list>         <list>        \n 1     8       0.5 <int [10,000]> <dbl [10,000]>\n 2     8       0.8 <int [10,000]> <dbl [10,000]>\n 3     8       0.9 <int [10,000]> <dbl [10,000]>\n 4   100       0.5 <int [10,000]> <dbl [10,000]>\n 5   100       0.8 <int [10,000]> <dbl [10,000]>\n 6   100       0.9 <int [10,000]> <dbl [10,000]>\n 7  1000       0.5 <int [10,000]> <dbl [10,000]>\n 8  1000       0.8 <int [10,000]> <dbl [10,000]>\n 9  1000       0.9 <int [10,000]> <dbl [10,000]>\n10 10000       0.5 <int [10,000]> <dbl [10,000]>\n11 10000       0.8 <int [10,000]> <dbl [10,000]>\n12 10000       0.9 <int [10,000]> <dbl [10,000]>\n\nI also introduced a new piece of advanced dplyr syntax. rowwise is similar to group_by and essentially puts each row into its own group. This can be useful when working with list columns or running a function with varying arguments and allows us to treat the inside of mutate a bit like as if we where using one of the map functions. For more information, see the documentation article.\nIt leaves us with 10000 simulated numbers of wins at N games for different true probabilities of her winning (i.e. how much better our friend is). We then calculate the probability to have this or a greater number of wins under the null hypothesis (equal probability for win and loss), in other words: the p-value.\n\n\nsimulation %>%\n  unnest(c(wins, p)) %>% \n  ggplot(aes(p)) +\n  geom_histogram() +\n  facet_wrap(~ true_prob + N,\n             labeller = label_both,\n             scales = \"free_y\",\n             ncol = 4) +\n  geom_vline(xintercept = 0.05, color = \"red\") +\n  labs(x = \"p-value\",\n       y = \"frequency\") +\n  scale_y_continuous(breaks = NULL)\n\n\n\n\nWe notice a couple of things in this plot. As the number of games played approaches very high numbers, the p-values for the case where the null hypothesis is in fact true (both players have the same chance of winning), start following a uniform distribution, meaning for a true null hypothesis, all p-values are equally likely. This seems counterintuitive at first, but is a direct consequence of the definition of the p-value. The consequence of this is, that if we apply our regular significance threshold of 5%, by definition we will say that there is a true difference, even though there is none (i.e. the null hypothesis is true but we falsely reject it and favor of our alternative hypothesis). This is called a false positive. By definition, we will get at least \\(\\alpha\\) false positives in all of our experiments. Later, we will learn, why the real number of false positives is even higher. Another name for false positives is Type I errors.\nOn the other side of the coin, there are also cases where there is a true difference (we used winning probabilities of 0.8 and 0.9), but we don’t reject the null hypothesis because we get a p-values larger than \\(alpha\\). These are all false negatives and their rate is sometimes referred to as \\(\\beta\\). Another name for false negatives is Type II errors. People don’t particularly like talking about negative things like errors, so instead you will often see the inverse of \\(\\beta\\), the Statistical Power \\(1-\\beta\\). The proportion of correctly identified positives out of the actual positives is also shown on the plot below. For example, say her true win probability is 90% and we play 8 games. If this experiment runs in an infinite number of parallel universes, we will conclude that she is better than chance in 80% of those. We could set our significance threshold higher to detect more of the true positives, but this would also increase our false positives.\n\n\nsimulation %>%\n  unnest(c(wins, p)) %>%\n  group_by(true_prob, N) %>%\n  summarise(signif = mean(p <= 0.05)) %>% \n  ggplot(aes(true_prob, signif, fill = true_prob == 0.5)) +\n  geom_col(color = \"black\") +\n  geom_text(aes(label = signif), vjust = -0.2) +\n  facet_wrap(~N,\n             labeller = label_both) +\n  scale_y_continuous(expand = expansion(c(0, 0.1))) +\n  scale_fill_viridis_d() +\n  labs(y = \"Proportion of significant results\")\n\n\n\n\n\nUnfortunately, there is no free lunch in statistics.\n\nThere are also packages out there, which have a function to compute the power for the binomial test, but I think the simulation was way more approachable. The cool thing about simulations is also, that they work even when there is no analytical solution, so you can use them to play around when planning an experiment.\nP-Value Pitfalls\nLet us look into some of the pitfalls of p-values. Remember from the definition of p-values, that we will get a significant result even if there is no true difference in 5% of cases (assuming we use this as our alpha)? Well, what if we test a bunch of things? This is called Multiple Testing and there is a problem associated with it:\nIf you test 20 different things, and your statistical test will produce a significant result by chance alone in 5% of cases, the expected number of significant results is 1. So we are not very surprised. Speaking of surprised: In his book, available for free online, “Statistics done wrong”, Alex Reinhart describes p-values as a “measure of surprise”:\n\n»A p value is not a measure of how right you are, or how significant the difference is; it’s a measure of how surprised you should be if there is no actual difference between the groups, but you got data suggesting there is. A bigger difference, or one backed up by more data, suggests more surprise and a smaller p value.« — Alex Reinhart (Reinhart 2015)\n\nSo, we are not very surprised, but if you focus to hard on the one significant result, trouble ensues. In a “publish or perish” mentality, this can easily happen, and negative findings are not published nearly enough, so most published findings are likely exaggerated. John Bohannon showcased this beautifully by running a study on chocolate consumption and getting it published: I Fooled Millions Into Thinking Chocolate Helps Weight Loss. Here’s How.\nWhat can we do about this?\nMultiple Testing Correction\nThe simplest approach is to take all p-values calculate when running a large number of comparisons and dividing them by the number of tests performed. This is called the Bonferroni correction\n\n\np_values <- c(0.5, 0.05, 0.3, 0.001, 0.003)\np.adjust(p_values, method = \"bonferroni\")\n\n\n[1] 1.000 0.250 1.000 0.005 0.015\n\nOf course, this looses some statistical power (remember, no free lunch). A slightly more sophisticated approach to controlling the false discovery rate (FDR) is the Benjamini-Hochberg procedure. It retains a bit more power. Here is what happens:\nSort all p-values in ascending order.\nChoose a FDR \\(q\\) you are willing to accept and call the number of tests done \\(m\\).\nFind the largest p-value with: \\(p \\leq iq/m\\) with its index \\(i\\).\nThis is your new threshold for significance\nScale the p-values accordingly\nAnd this is how you do it in R:\n\n\np.adjust(p_values, method = \"BH\")\n\n\n[1] 0.50000000 0.08333333 0.37500000 0.00500000 0.00750000\n\nOther forms of p-hacking\nThis sort of multiple testing is fairly obvious. You will notice it, when you end up with a large number of p-values, for example when doing a genetic screening and testing thousands of genes. Other related problems are harder to spot. For a single research question there are often different statistical tests that you could run, but trying them all out and then choosing the one that best agrees with your hypothesis is not an option! Likewise, simply looking at your data is a form of comparison if it influences your choice of statistical test. Ideally, you first run some exploratory experiments that are not meant to test your hypothesis, then decide on the tests you need, the sample size you want for a particular power and then run the actual experiments designed to test your hypothesis.\nAt this point, here is another shout-out to Alex Reinharts book (Reinhart 2015). It is a very pleasant read and also shines more light on some of the other forms of p-hacking.\nBayesian Statistics and the Base Rate Fallacy\nThere is another more subtle problem called the base rate fallacy. As an example, we assume a medical test, testing for a certain condition. In medical testing, different words are used for the same concepts we defined above1.\nHere, we have:\nSensitivity = Power = true positive rate = \\(1-\\beta\\)\nSpecificity = true negative rate = \\(1-\\alpha\\)\nLet us assume a test with a sensitivity of 90% and a specificity of 92%. When we visit the doctor to get a test, and get a positive result, what is the probability, that we are in fact positive (i.e. a true positive)? Well, the test has a specificity of 92%, so if we where negative, it would have detected that in 92% of cases, does this mean, that we can be 92% certain, that we are actually positive?\nWell, no. What we are ignoring here is base rate, which for diseases is called the prevalence. It is the proportion at which a disease exists in the general population.\nSo, let us say, we are picking 1000 people at random from the population and testing them. We are dealing with a hypothetical condition that affects 1% of people, so we assume 10 people in our sample to be positive. Of those 10 people, 9 will be tested positive (due to our sensitivity), those will be our true positives. The remaining 1 will be a false negative. However, we are of course also testing the negatives (if we knew ahead of time there would be no point in testing) and of those due to our specificity, 8% will also be tested positive, which is 0.08 * 990, so we get 79 false positives. Because there are so many negatives in our sample, even a relatively high specificity will produce a lot of false positives. So that actual probability of being positive with a positive test result is\n\\[\\frac{true~positives}{true~positives + false~positives}=10\\%\\]\n\n\n\nFormally, this is described by Bayes’s Formula\n\\[P(A|B)=\\frac{P(B|A)*P(A)}{P(B)}\\]\nRead: The probability of A given B is the probability of B given A times the probability of A divided by the probability of B.\nIn bayesian statistics, the prevalences are known as priors.\nConcepts discussed today\nAfter today you should be familiar with the following concepts:\nNull and alternative hypothesis\nP-values and statistical significance\nBinomial distribution\nProbability density, probability and quantile functions\nEffect size and statistical power\nFalse positives, false negatives\nMultiple testing and p-hacking\nBayes’s Theorem\nExercises\nJust by itself this is quite a bit of material to take in, so I try to limit the exercises for today.\nDiscovering a new Distribution\nThe binomial distribution was concerned with sampling with replacement (you can get head or tails any number of times without using up the coin). In this exercise you will explore sampling without replacement. The common model for this is an urn with two different colored balls in it. The resulting distribution is called the hypergeometric distribution and the corresponding R functions are <r/d/p/q>hyper Unfortunately, I couldn’t think of a game that could be modeled by sampling without replacement, let me know, if you find one!\nImagine you are a zoo manager.\nGet yourselves in the mood by watching some cute animal videos and having a cup of tee or coffee. Here are two red pandas having fun in the snow.\nWe got a gift from another zoo! It consists of 8 red pandas and 2 giant pandas. What is the probability that they end up properly separated, if we randomly take 8 animals, put them in one enclosure and put the rest in another?\nOur penguin colony hatched eggs and we have a bunch of newcomers. We have have 15 males and 10 females. If we look at a random subset of 12 penguins, what does the distribution of the number of males look like? Which number is most likely? How likely is it, to get at least 9 males in the sample?\n\nResources\nhttps://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108\nhttps://jimgruman.netlify.app/post/education-r/\nP-Value histograms blogpost by David Robinson\n“Statistics done wrong”\n\n\n\n“Artwork by @allison_horst.” 2020. https://github.com/allisonhorst/stats-illustrations.\n\n\nReinhart, Alex. 2015. Statistics Done Wrong: The Woefully Complete Guide. 1 edition. San Francisco: No Starch Press.\n\n\nThis is a slightly annoying trend in statistics; as it enters different fields, people come up with new names for old things (perhaps the most notorious field for this is machine learning).↩︎\n",
    "preview": "lectures/lecture5/img/statistically-significant.jpg",
    "last_modified": "2020-11-30T02:20:27+01:00",
    "input_file": "lecture5.utf8.md"
  },
  {
    "path": "lectures/lecture4/",
    "title": "Lecture 4",
    "description": "... which is all about functions, bringing the whole tidyverse together and\nexploring advanced dplyr data wrangling techniques.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-22",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nMotivation\nIteration\nFunctional Programming\nThe Imperative Programming Approach\n\n“If you copy and paste the same code more than three times, write a function.”\nNoticing a Pattern\nWhere to put your Functions\n\nMany Models\nAdvanced dplyr\n\nExercises\nThe whole Deal\nRoman emperors\nDairy Products in the US\n\n\nResources\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen. Press ? for a list of keyboard shortcuts.\n\n\nknitr::include_url(\"slides4.html\")\n\n\n\n\n\nScript\nMotivation\nMy goal today is to bring together everything we learned so far and solidify our understanding of wrangling data in the tidyverse. If all goes according to plan, we will then have more mental capacity freed up for the statistics starting next week. And our understanding of data will hopefully enable us to experiment and play with statistical concepts without getting stuck too much on data wrangling. This also means that today’s lecture might be the most challenging so far, because everything learned up until now will – in one way or another – be relevant.\nAs you might be able to tell, mental models are one of my favorite topics. We are starting today with a powerful mental model teased at last week. I am talking about iteration.\nIteration\nIteration is the basic idea of doing one thing multiple times. This is an area where computers shine, so in this chapter we will learn to fully utilize the power at our fingertips.\nWe had our first encounter with iteration in a very implicit form. When we use R’s basic math operators, the computer is iterating behind the scenes. Take this expression:\n\n\n1:3 + 1:3\n\n\n[1] 2 4 6\n\nThis operation is vectorized. Without us having to tell R to do so, R will add the first element of the first vector to the first element of the second vector and so forth.\nNotice, how it looks like the operation happens all at the same time. But in reality, this is not what happens. The computer is just really fast at adding numbers, one after the other.\nThe mathematical operations in R call another programming language that does the actual addition. This other programming language is closer to the way computers think, making it less fun to write for us humans, but also faster because the instructions are easier to translate into actions for our computer processor.\nWhen we find a task that we want to apply to multiple things, and this task is not already vectorized, we need to make our own iteration. There are actually two schools of though on how to talk about iteration and consequently, how to write it in code.\nI will use a realworld example to illustrate this: Reading in Multiple Files\nFunctional Programming\nRemember the gapminder dataset? Well, we are working with it again, but this time, our collaborator sent us one csv-file for each continent. As usual, we load the tidyverse first. For the script I also load the rmarkdown package and the knitr package to have more control over printing tables.\n\n\nlibrary(tidyverse)\nlibrary(rmarkdown)\nlibrary(knitr)\n\n\n\nWe already know how to read in one csv-file:\n\n\n# n_max = 3 is just here for the script\nread_csv(\"data/Africa.csv\", n_max = 3)\n\n\n# A tibble: 3 x 5\n  country  year lifeExp      pop gdpPercap\n  <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n1 Algeria  1952    43.1  9279525     2449.\n2 Algeria  1957    45.7 10270856     3014.\n3 Algeria  1962    48.3 11000948     2551.\n\nWe have a function (read_csv) that takes a file path and returns (spits out) the data. In this first school of thought, the Functional Programming style, the next idea is to have a function, that takes two things: a function and a vector (atomic or list). And it feeds the individual elements of the vector to the function, one after another. In mathematics, the relation between a set of inputs and a set of outputs is called a map, which is where the name of the following family of functions comes from. In the tidyverse, these functional programming concepts live in the purrr package.\n\n\n\n\n\nFirst, we create the vector of things that we want to iterate over, the things that will be fed into our function one after the other:\n\n\npaths <- dir(\"data\", full.names = TRUE)\npaths\n\n\n[1] \"data/Africa.csv\"   \"data/Americas.csv\" \"data/Asia.csv\"    \n[4] \"data/Europe.csv\"   \"data/Oceania.csv\" \n\nNow we have 5 file paths. We can test our understanding by passing just one of them to read_csv to make sure our function works:\n\n\nread_csv(paths[[1]], n_max = 3)\n\n\n# A tibble: 3 x 5\n  country  year lifeExp      pop gdpPercap\n  <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n1 Algeria  1952    43.1  9279525     2449.\n2 Algeria  1957    45.7 10270856     3014.\n3 Algeria  1962    48.3 11000948     2551.\n\nIt is time for the map function!\n\n\nall_datasets <- map(paths, read_csv)\n\n\n\nThat’s it! We now have a list that contains all five datasets.\nBut we lost the information about which file the elements of the list came from, which is the name if the continent! We can fix this by using a named list instead of a regular list to pass to map:\n\n\nnames(paths) <- basename(paths) %>%\n  str_remove(\"\\\\.csv\")\n\nmy_data <- map(paths, read_csv)\n\n\n\nThe function str_remove is part of the stringr package in the tidyverse. It’s functions, which handle all kinds of operations on text, start with str_.\n\n\n\n\n\nAnd now we can combine them into one big dataset using bind_rows, which stacks tibbles on top of each other. The extra argument .id determines the name for the column in which we store the names of the list items.\n\n\nmy_data %>%\n  bind_rows(.id = \"continent\")\n\n\n# A tibble: 1,704 x 6\n   continent country  year lifeExp      pop gdpPercap\n   <chr>     <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 Africa    Algeria  1952    43.1  9279525     2449.\n 2 Africa    Algeria  1957    45.7 10270856     3014.\n 3 Africa    Algeria  1962    48.3 11000948     2551.\n 4 Africa    Algeria  1967    51.4 12760499     3247.\n 5 Africa    Algeria  1972    54.5 14760787     4183.\n 6 Africa    Algeria  1977    58.0 17152804     4910.\n 7 Africa    Algeria  1982    61.4 20033753     5745.\n 8 Africa    Algeria  1987    65.8 23254956     5681.\n 9 Africa    Algeria  1992    67.7 26298373     5023.\n10 Africa    Algeria  1997    69.2 29072015     4797.\n# … with 1,694 more rows\n\nThere is yet another shortcut we can employ. The purrr package contains various variants of the map function. map itself will always return a list, whereas variants like map_chr always return an atomic character vector,map_dbl always returns numbers, map_lgl always return logical (yes or no, TRUE / FALSE) vectors. Combining a list into one dataframe (by rows) is so common that there is also a special map function for this: map_dfr.\n\n\ngapminder <- map_dfr(paths, read_csv, .id = \"continent\")\ngapminder\n\n\n# A tibble: 1,704 x 6\n   continent country  year lifeExp      pop gdpPercap\n   <chr>     <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 Africa    Algeria  1952    43.1  9279525     2449.\n 2 Africa    Algeria  1957    45.7 10270856     3014.\n 3 Africa    Algeria  1962    48.3 11000948     2551.\n 4 Africa    Algeria  1967    51.4 12760499     3247.\n 5 Africa    Algeria  1972    54.5 14760787     4183.\n 6 Africa    Algeria  1977    58.0 17152804     4910.\n 7 Africa    Algeria  1982    61.4 20033753     5745.\n 8 Africa    Algeria  1987    65.8 23254956     5681.\n 9 Africa    Algeria  1992    67.7 26298373     5023.\n10 Africa    Algeria  1997    69.2 29072015     4797.\n# … with 1,694 more rows\n\nNow that was efficient! It only took us a couple of lines. We can even do the whole thing in one chain of functions using the pipe. But keep in mind that this is not the way we came up with it. No one expects you to come up with the shortest and most concise solution on the first go. But sometimes it can pay off to revisit your first solution that involves multiple temporary variables we don’t really need for the rest of the script and clean it up a bit. This might make it easier to come back to your code in the future and be able to read what is going on faster (because there are less lines to read).\n\n\ngapminder <-\n  dir(\"data\", full.names = TRUE) %>% \n  set_names(function(name) basename(name) %>% str_remove(\"\\\\.csv\")) %>%\n  map_dfr(read_csv, .id = \"continent\")\n\n\n\nI want to take a moment to introduce yet another shortcut we can take. Notice, how in set_names I created a function to process the names without giving it a name. This is called an anonymous function. Sometimes people also call it a lambda function, because it originates from something called lambda calculus. Because the tilde symbol ~ is the closest we get to \\(\\lambda\\) on an English keyboard, this is used to create anonymous functions on the fly. The don’t even have to worry about names for our arguments, it automatically creates a function where the argument is named “.x” (and “.y” if you need multiple arguments). See the documentation of map, especially the .f argument, for more information.\n\n\ngapminder <-\n  dir(\"data\", full.names = TRUE) %>% \n  set_names(~ basename(.x) %>% str_remove(\"\\\\.csv\")) %>%\n  map_dfr(read_csv, .id = \"continent\")\n\n\n\nThe Imperative Programming Approach\nThere are other ways we could have gone about this. A common construct in programming languages is the so called for-loop. For every element of a vector, the body of the loop runs. For our example, it would look like this:\n\n\npaths <- dir(\"data\", full.names = TRUE)\nresults <- vector(\"list\", length(paths))\n\nfor (i in 1:length(paths)) {\n  data <- read_csv(paths[i])\n  results[[i]] <- data\n}\n\nnames(results) <- basename(paths) %>% str_remove(\"\\\\.csv\")\ngapminder <- bind_rows(results, .id = \"continent\")\n\n\n\nThe for-loop-version has a lot more code, especially boilerplate, code that is just there to make the construct work and doesn’t convey our intentions with the code. Furthermore, the loop focuses the object that is iterated over (the file paths), while the map-version focuses on what is happening (the function, read_csv). But the loop still works. If you can’t think of a way to solve a problem with a map function, it is absolutely OK to use for-loops.\nThe first approach with the map function comes from Functional Programming, whereas the second approach is considered Imperative Programming. In general, in Functional Programming, we tell the computer what we want, while in Imperative Programming, we tell the computer what steps to do. So keep in mind:\n\n»Of course someone has to write for-loops. It doesn’t have to be you.« — Jenny Bryan\n\nAnd don’t miss the amazing purrr cheatsheet: link\n“If you copy and paste the same code more than three times, write a function.”\nNoticing a Pattern\nWriting our own functions can be very helpful for making our code more readable. It allows us to separate certain steps of your analysis from the rest, look at them in isolation to test and validate them, and also allows us to give them reasonable names. Let’s look at a couple of examples and get you writing functions! Say we have this idea, where we filter the gapminder dataset for one country, check how linear the relationship between year and life expectancy is and then create a plot.\n\n\nfilterd_data <- gapminder %>% \n  filter(country == \"Norway\")\n\nmodel <- lm(lifeExp ~ year, data = filterd_data)\n\n\n\nThese three function from the broom package tell us more about our linear model created with lm. It is part of the tidymodels framework.\n\n\nbroom::tidy(model)\n\n\n# A tibble: 2 x 5\n  term        estimate std.error statistic      p.value\n  <chr>          <dbl>     <dbl>     <dbl>        <dbl>\n1 (Intercept) -185.     16.2         -11.4 0.000000460 \n2 year           0.132   0.00819      16.1 0.0000000176\n\n\n\nbroom::augment(model)\n\n\n# A tibble: 12 x 8\n   lifeExp  year .fitted  .resid .std.resid   .hat .sigma .cooksd\n     <dbl> <dbl>   <dbl>   <dbl>      <dbl>  <dbl>  <dbl>   <dbl>\n 1    72.7  1952    72.2  0.455       1.11  0.295   0.483 0.256  \n 2    73.4  1957    72.9  0.566       1.31  0.225   0.470 0.250  \n 3    73.5  1962    73.5 -0.0640     -0.143 0.169   0.516 0.00209\n 4    74.1  1967    74.2 -0.114      -0.249 0.127   0.515 0.00450\n 5    74.3  1972    74.9 -0.513      -1.10  0.0991  0.484 0.0671 \n 6    75.4  1977    75.5 -0.143      -0.306 0.0851  0.514 0.00434\n 7    76.0  1982    76.2 -0.203      -0.433 0.0851  0.511 0.00872\n 8    75.9  1987    76.8 -0.943      -2.03  0.0991  0.396 0.226  \n 9    77.3  1992    77.5 -0.172      -0.377 0.127   0.512 0.0103 \n10    78.3  1997    78.2  0.168       0.376 0.169   0.512 0.0144 \n11    79.0  2002    78.8  0.238       0.553 0.225   0.508 0.0443 \n12    80.2  2007    79.5  0.725       1.76  0.295   0.429 0.649  \n\n\n\nbroom::glance(model)\n\n\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl>\n1     0.963         0.959 0.490      260. 1.76e-8     1  -7.37  20.7\n# … with 4 more variables: BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>\n\nThe \\(R^2\\) value tells us, how well a straight line fits to our data. It can assume values between 0 and 1.\n\n\nmodel_glance <- broom::glance(model)\n\ntext <- substitute(R^2 == rsq,\n                   list(rsq = round(model_glance$r.squared, 2)))\n\nfilterd_data %>% \n  ggplot(aes(year, lifeExp)) +\n  geom_smooth(method = \"lm\") +\n  geom_line() +\n  geom_point() +\n  theme_classic() +\n  labs(\n    x = \"Year\",\n    y = \"Life Expectancy\",\n    title = \"Norway\",\n    subtitle = text\n  )\n\n\n\n\nThen we get curious and want to know how this graph looks for another country. So we copy and paste our code and replace the name of the country. And yet again, we want to see this plot for another country, so we copy and paste our code, change the country name and keep going. This is when we remember, that there is an easier way to deal with this repetition. We look at our code again and identify the things that stay the same and the things that change during each copy and pasting. The things that stay the same will be the body of our function, the things that change will be variables in the body that we pass to the function as arguments. In our example, there is only one thing that changes every time: the name of the country. So we build the following function:\n\n\nplot_life_exp_for_country <- function(country_name) {\n  filterd_data <- gapminder %>% \n    filter(country == country_name)\n  \n  model <- lm(lifeExp ~ year, data = filterd_data)\n  model_glance <- broom::glance(model)\n  text <- substitute(R^2 == rsq,\n                     list(rsq = round(model_glance$r.squared, 2)))\n  \n  filterd_data %>% \n    ggplot(aes(year, lifeExp)) +\n    geom_smooth(method = \"lm\") +\n    geom_line() +\n    geom_point() +\n    theme_classic() +\n    labs(\n      x = \"Year\",\n      y = \"Life Expectancy\",\n      title = country_name,\n      subtitle = text\n    )\n}\n\n\n\nThen we test the function a bunch to make sure it works for different cases:\n\n\nplot_life_exp_for_country(\"India\")\nplot_life_exp_for_country(\"Mali\")\n\n\n\n\nWhere to put your Functions\nAt this point you might wonder where to put this function. A good starting point is to collect your functions near the top of your document or script, below where you load all packages. Another approach, especially if you have functions that you can use for multiple projects, is to put them in a .R file and load this file at the beginning of your document. You can do so using the function source(\"path/to/file.R\"). It runs the R file in your current sessions, so any functions and variables defined in there are now available to you.\n\n\nsource(\"R/my_funs.R\")\n\n\n\nJust like this.\n\n\nsay_hello()\n\n\n[1] \"Hello!\"\n\nI like to store my regular R files (as opposed to Rmd files) in a folder of my project called R. This makes it already look like an R package, in case I decide later on that the functions could be helpful for others as well or I want to share them more easily with colleagues. You can read more about creating your own R packages here (Wickham 2015).\nMany Models\nLet us use the techniques above to shine light on how life expectancies changed over time. This time, we will utilize the nested data format to store our data alongside models for the data.\n\n\nnested_gapminder <- gapminder %>%\n  nest(-country, -continent) %>% \n  mutate(\n    model = map(data, ~ lm(lifeExp ~ year, data = .x))\n  )\n\nnested_gapminder\n\n\n# A tibble: 142 x 4\n   continent country                  data              model \n   <chr>     <chr>                    <list>            <list>\n 1 Africa    Algeria                  <tibble [12 × 4]> <lm>  \n 2 Africa    Angola                   <tibble [12 × 4]> <lm>  \n 3 Africa    Benin                    <tibble [12 × 4]> <lm>  \n 4 Africa    Botswana                 <tibble [12 × 4]> <lm>  \n 5 Africa    Burkina Faso             <tibble [12 × 4]> <lm>  \n 6 Africa    Burundi                  <tibble [12 × 4]> <lm>  \n 7 Africa    Cameroon                 <tibble [12 × 4]> <lm>  \n 8 Africa    Central African Republic <tibble [12 × 4]> <lm>  \n 9 Africa    Chad                     <tibble [12 × 4]> <lm>  \n10 Africa    Comoros                  <tibble [12 × 4]> <lm>  \n# … with 132 more rows\n\nThen, we extract information about the model with some functions form the broom package.\n\n\nnested_gapminder %>% \n  mutate(\n    glance = map(model, broom::glance)\n  )\n\n\n# A tibble: 142 x 5\n   continent country              data            model glance        \n   <chr>     <chr>                <list>          <lis> <list>        \n 1 Africa    Algeria              <tibble [12 × … <lm>  <tibble [1 × …\n 2 Africa    Angola               <tibble [12 × … <lm>  <tibble [1 × …\n 3 Africa    Benin                <tibble [12 × … <lm>  <tibble [1 × …\n 4 Africa    Botswana             <tibble [12 × … <lm>  <tibble [1 × …\n 5 Africa    Burkina Faso         <tibble [12 × … <lm>  <tibble [1 × …\n 6 Africa    Burundi              <tibble [12 × … <lm>  <tibble [1 × …\n 7 Africa    Cameroon             <tibble [12 × … <lm>  <tibble [1 × …\n 8 Africa    Central African Rep… <tibble [12 × … <lm>  <tibble [1 × …\n 9 Africa    Chad                 <tibble [12 × … <lm>  <tibble [1 × …\n10 Africa    Comoros              <tibble [12 × … <lm>  <tibble [1 × …\n# … with 132 more rows\n\nThen we go ahead and unnest the information about the model. We can now see, which countries stray the farthest from a straight line by arranging by the \\(R^2\\) values.\n\n\ngapminder_modeled <- nested_gapminder %>% \n  mutate(\n    glance = map(model, broom::glance)\n  ) %>% \n  unnest(glance) %>% \n  arrange(r.squared)\n\ngapminder_modeled\n\n\n# A tibble: 142 x 16\n   continent country data  model r.squared adj.r.squared sigma\n   <chr>     <chr>   <lis> <lis>     <dbl>         <dbl> <dbl>\n 1 Africa    Rwanda  <tib… <lm>     0.0172      -0.0811   6.56\n 2 Africa    Botswa… <tib… <lm>     0.0340      -0.0626   6.11\n 3 Africa    Zimbab… <tib… <lm>     0.0562      -0.0381   7.21\n 4 Africa    Zambia  <tib… <lm>     0.0598      -0.0342   4.53\n 5 Africa    Swazil… <tib… <lm>     0.0682      -0.0250   6.64\n 6 Africa    Lesotho <tib… <lm>     0.0849      -0.00666  5.93\n 7 Africa    Cote d… <tib… <lm>     0.283        0.212    3.93\n 8 Africa    South … <tib… <lm>     0.312        0.244    4.74\n 9 Africa    Uganda  <tib… <lm>     0.342        0.276    3.19\n10 Africa    Congo,… <tib… <lm>     0.348        0.283    2.43\n# … with 132 more rows, and 9 more variables: statistic <dbl>,\n#   p.value <dbl>, df <dbl>, logLik <dbl>, AIC <dbl>, BIC <dbl>,\n#   deviance <dbl>, df.residual <int>, nobs <int>\n\nFor a more detailed walk-trough, check out the chapter on “many models” in R for Data Science here (Wickham and Grolemund 2017).\nLet’s use this information to build a visualization.\n\n\nnon_linear_countries <- gapminder_modeled %>% \n  filter(r.squared < 0.2) %>% \n  unnest(data)\n\nnon_linear_countries\n\n\n# A tibble: 72 x 19\n   continent country  year lifeExp    pop gdpPercap model r.squared\n   <chr>     <chr>   <dbl>   <dbl>  <dbl>     <dbl> <lis>     <dbl>\n 1 Africa    Rwanda   1952    40   2.53e6      493. <lm>     0.0172\n 2 Africa    Rwanda   1957    41.5 2.82e6      540. <lm>     0.0172\n 3 Africa    Rwanda   1962    43   3.05e6      597. <lm>     0.0172\n 4 Africa    Rwanda   1967    44.1 3.45e6      511. <lm>     0.0172\n 5 Africa    Rwanda   1972    44.6 3.99e6      591. <lm>     0.0172\n 6 Africa    Rwanda   1977    45   4.66e6      670. <lm>     0.0172\n 7 Africa    Rwanda   1982    46.2 5.51e6      882. <lm>     0.0172\n 8 Africa    Rwanda   1987    44.0 6.35e6      848. <lm>     0.0172\n 9 Africa    Rwanda   1992    23.6 7.29e6      737. <lm>     0.0172\n10 Africa    Rwanda   1997    36.1 7.21e6      590. <lm>     0.0172\n# … with 62 more rows, and 11 more variables: adj.r.squared <dbl>,\n#   sigma <dbl>, statistic <dbl>, p.value <dbl>, df <dbl>,\n#   logLik <dbl>, AIC <dbl>, BIC <dbl>, deviance <dbl>,\n#   df.residual <int>, nobs <int>\n\nI also like to use this opportunity to mention a couple of packages to take your visualizations the the next level. Today, these are ggrepel to produce labels that dodge each other, and the fisualize package, which contains color scales of tropical fish.\n\n\nplt <- gapminder %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line(alpha = 0.2) +\n  geom_line(data = non_linear_countries,\n            mapping = aes(color = country),\n            size = 1.7) +\n  fishualize::scale_color_fish_d() +\n  labs(y = \"Life Expectancy at Birth\") +\n  ggrepel::geom_text_repel(data = filter(non_linear_countries, year == max(year)),\n            aes(label = country, color = country),\n            hjust = 0, direction = \"y\") +\n  expand_limits(x = 2015) +\n  theme_minimal() +\n  guides(color = \"none\")\n\nplt\n\n\n\n\nSometimes it is also very handy (and probably impressive to whoever receives your report) to turn a plot into an interactive graphic. plotly is a library that produces interactive plots, but we don’t even have to learn about its intricacies because it comes with a function to convert a ggplot to the interactive format that works quite well for a range (but not all) of use-cases:\n\n\nplotly::ggplotly(plt)\n\n\n\n{\"x\":{\"data\":[{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007,null,1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[28.801,30.332,31.997,34.02,36.088,38.438,39.854,40.822,41.674,41.763,42.129,43.828,null,55.23,59.28,64.82,66.22,67.69,68.93,70.42,72,71.581,72.95,75.651,76.423,null,43.077,45.685,48.303,51.407,54.518,58.014,61.368,65.799,67.744,69.152,70.994,72.301,null,30.015,31.999,34,35.985,37.928,39.483,39.942,39.906,40.647,40.963,41.003,42.731,null,62.485,64.399,65.142,65.634,67.065,68.481,69.942,70.774,71.868,73.275,74.34,75.32,null,69.12,70.33,70.93,71.1,71.93,73.49,74.74,76.32,77.56,78.83,80.37,81.235,null,66.8,67.48,69.54,70.14,70.63,72.17,73.18,74.94,76.04,77.51,78.98,79.829,null,50.939,53.832,56.923,59.923,63.3,65.593,69.052,70.75,72.601,73.925,74.795,75.635,null,37.484,39.348,41.216,43.453,45.252,46.923,50.009,52.819,56.018,59.412,62.013,64.062,null,68,69.24,70.25,70.94,71.44,72.8,73.93,75.35,76.46,77.53,78.32,79.441,null,38.223,40.358,42.618,44.885,47.014,49.19,50.904,52.337,53.919,54.777,54.406,56.728,null,40.414,41.89,43.428,45.032,46.714,50.023,53.859,57.251,59.957,62.05,63.883,65.554,null,53.82,58.45,61.93,64.79,67.45,69.86,70.69,71.14,72.178,73.244,74.09,74.852,null,47.622,49.618,51.52,53.298,56.024,59.319,61.484,63.622,62.745,52.556,46.634,50.728,null,50.917,53.285,55.665,57.632,59.504,61.489,63.336,65.205,67.057,69.388,71.006,72.39,null,59.6,66.61,69.51,70.42,70.9,70.81,71.08,71.34,71.19,70.32,72.14,73.005,null,31.975,34.906,37.814,40.697,43.591,46.137,48.122,49.557,50.26,50.324,50.65,52.295,null,39.031,40.533,42.045,43.548,44.057,45.91,47.471,48.211,44.736,45.326,47.36,49.58,null,39.417,41.366,43.415,45.415,40.317,31.22,50.957,53.914,55.803,56.534,56.752,59.723,null,38.523,40.428,42.643,44.799,47.049,49.355,52.961,54.985,54.314,52.199,49.856,50.43,null,68.75,69.96,71.3,72.13,72.88,74.21,75.76,76.86,77.95,78.61,79.77,80.653,null,35.463,37.464,39.475,41.478,43.457,46.775,48.295,50.485,49.396,46.066,43.308,44.741,null,38.092,39.881,41.716,43.601,45.569,47.383,49.517,51.051,51.724,51.573,50.525,50.651,null,54.745,56.074,57.924,60.523,63.441,67.052,70.565,72.492,74.126,75.816,77.86,78.553,null,44,50.54896,44.50136,58.38112,63.11888,63.96736,65.525,67.274,68.69,70.426,72.028,72.961,null,50.643,55.118,57.863,59.963,61.623,63.837,66.653,67.768,68.421,70.313,71.682,72.889,null,40.715,42.46,44.467,46.472,48.944,50.939,52.933,54.926,57.939,60.66,62.974,65.152,null,39.143,40.652,42.122,44.056,45.989,47.804,47.784,47.412,45.548,42.587,44.966,46.462,null,42.111,45.053,48.435,52.04,54.907,55.625,56.695,57.47,56.433,52.962,52.97,55.322,null,57.206,60.026,62.842,65.424,67.849,70.75,73.45,74.752,75.713,77.26,78.123,78.782,null,40.477,42.469,44.93,47.35,49.801,52.374,53.983,54.655,52.044,47.991,46.832,48.328,null,61.21,64.77,67.13,68.5,69.61,70.64,70.46,71.52,72.527,73.68,74.876,75.748,null,59.421,62.325,65.246,68.29,70.723,72.649,73.717,74.174,74.414,76.151,77.158,78.273,null,66.87,69.03,69.9,70.38,70.29,70.71,70.96,71.58,72.4,74.01,75.51,76.486,null,70.78,71.81,72.35,72.96,73.47,74.69,74.63,74.8,75.33,76.11,77.18,78.332,null,34.812,37.328,39.693,42.074,44.366,46.519,48.812,50.04,51.604,53.157,53.373,54.791,null,45.928,49.828,53.459,56.751,59.631,61.788,63.727,66.046,68.457,69.957,70.847,72.235,null,48.357,51.356,54.64,56.678,58.796,61.31,64.342,67.231,69.613,72.312,74.173,74.994,null,41.893,44.444,46.992,49.293,51.137,53.319,56.006,59.797,63.674,67.217,69.806,71.338,null,45.262,48.57,52.307,55.855,58.207,56.696,56.604,63.154,66.798,69.535,70.734,71.878,null,34.482,35.983,37.485,38.987,40.516,42.024,43.662,45.664,47.545,48.245,49.348,51.579,null,35.928,38.047,40.158,42.189,44.142,44.535,43.89,46.453,49.991,53.378,55.24,58.04,null,34.078,36.667,40.059,42.115,43.515,44.51,44.916,46.684,48.091,49.402,50.725,52.947,null,66.55,67.49,68.75,69.83,70.87,72.52,74.55,74.83,75.7,77.13,78.37,79.313,null,67.41,68.93,70.51,71.55,72.38,73.83,74.89,76.34,77.46,78.64,79.59,80.657,null,37.003,38.999,40.489,44.598,48.69,52.79,56.564,60.19,61.366,60.461,56.761,56.735,null,30,32.065,33.896,35.857,38.308,41.842,45.58,49.265,52.644,55.861,58.041,59.448,null,67.5,69.1,70.3,70.8,71,72.5,73.8,74.847,76.07,77.34,78.67,79.406,null,43.149,44.779,46.452,48.072,49.875,51.756,53.744,55.729,57.501,58.556,58.453,60.022,null,65.86,67.86,69.51,71,72.34,73.68,75.24,76.67,77.03,77.869,78.256,79.483,null,42.023,44.142,46.954,50.016,53.738,56.029,58.137,60.782,63.373,66.322,68.978,70.259,null,33.609,34.558,35.753,37.197,38.842,40.762,42.891,45.552,48.576,51.455,53.676,56.007,null,32.5,33.489,34.488,35.492,36.486,37.465,39.327,41.245,43.266,44.873,45.504,46.388,null,37.579,40.696,43.59,46.243,48.042,49.923,51.461,53.636,55.089,56.671,58.137,60.916,null,41.912,44.665,48.041,50.924,53.884,57.402,60.909,64.492,66.399,67.659,68.565,70.198,null,60.96,64.75,67.65,70,72,73.6,75.45,76.2,77.601,80,81.495,82.208,null,64.03,66.41,67.96,69.5,69.76,69.95,69.39,69.58,69.17,71.04,72.59,73.338,null,72.49,73.47,73.68,73.73,74.46,76.11,76.99,77.23,78.77,78.95,80.5,81.757,null,37.373,40.249,43.605,47.193,50.651,54.208,56.596,58.553,60.223,61.765,62.879,64.698,null,37.468,39.918,42.518,45.964,49.203,52.702,56.159,60.137,62.681,66.041,68.588,70.65,null,44.869,47.181,49.325,52.469,55.234,57.702,59.62,63.04,65.742,68.042,69.451,70.964,null,45.32,48.437,51.457,54.459,56.95,60.413,62.038,65.044,59.461,58.811,57.046,59.545,null,66.91,68.9,70.29,71.08,71.28,72.03,73.1,74.36,75.467,76.122,77.783,78.885,null,65.39,67.84,69.39,70.75,71.63,73.06,74.45,75.6,76.93,78.269,79.696,80.745,null,65.94,67.81,69.24,71.06,72.19,73.48,74.98,76.42,77.44,78.82,80.24,80.546,null,58.53,62.61,65.61,67.51,69,70.11,71.21,71.77,71.766,72.262,72.047,72.567,null,63.03,65.5,68.73,71.43,73.42,75.38,77.11,78.67,79.36,80.69,82,82.603,null,43.158,45.669,48.126,51.629,56.528,61.134,63.739,65.869,68.015,69.772,71.263,72.535,null,42.27,44.686,47.949,50.654,53.559,56.155,58.766,59.339,59.285,54.407,50.992,54.11,null,50.056,54.081,56.656,59.942,63.983,67.159,69.1,70.647,69.978,67.727,66.662,67.297,null,47.453,52.681,55.292,57.716,62.612,64.766,67.123,69.81,72.244,74.647,77.045,78.623,null,55.565,58.033,60.47,64.624,67.712,69.343,71.309,74.174,75.19,76.156,76.904,77.588,null,55.928,59.489,62.094,63.87,65.421,66.099,66.983,67.926,69.292,70.265,71.028,71.993,null,42.138,45.047,47.747,48.492,49.767,52.208,55.078,57.18,59.685,55.558,44.593,42.592,null,38.48,39.486,40.502,41.536,42.614,43.764,44.852,46.027,40.802,42.221,43.753,45.678,null,42.723,45.289,47.808,50.227,52.773,57.442,62.155,66.234,68.755,71.555,72.737,73.952,null,36.681,38.865,40.848,42.881,44.851,46.881,48.969,49.35,52.214,54.978,57.286,59.443,null,36.256,37.207,38.41,39.487,41.766,43.767,45.642,47.457,49.42,47.495,45.009,48.303,null,48.463,52.102,55.737,59.371,63.01,65.256,68,69.5,70.693,71.938,73.044,74.241,null,33.685,35.307,36.936,38.487,39.977,41.714,43.916,46.364,48.388,49.903,51.818,54.467,null,40.543,42.338,44.248,46.289,48.437,50.852,53.599,56.145,58.333,60.43,62.247,64.164,null,50.986,58.089,60.246,61.557,62.944,64.93,66.711,68.74,69.745,70.736,71.954,72.801,null,50.789,55.19,58.299,60.11,62.361,65.032,67.405,69.498,71.455,73.67,74.902,76.195,null,42.244,45.248,48.251,51.253,53.754,55.491,57.489,60.222,61.271,63.625,65.033,66.803,null,59.164,61.448,63.728,67.178,70.636,73.066,74.101,74.865,75.435,75.445,73.981,74.543,null,42.873,45.423,47.924,50.335,52.862,55.73,59.65,62.677,65.393,67.66,69.615,71.164,null,31.286,33.779,36.161,38.113,40.328,42.495,42.795,42.861,44.284,46.344,44.026,42.082,null,36.319,41.905,45.108,49.379,53.07,56.059,58.056,58.339,59.32,60.328,59.908,62.069,null,41.725,45.226,48.386,51.159,53.867,56.437,58.968,60.835,61.999,58.909,51.479,52.906,null,36.157,37.686,39.393,41.472,43.971,46.748,49.594,52.537,55.727,59.426,61.34,63.785,null,72.13,72.99,73.23,73.82,73.75,75.24,76.05,76.83,77.42,78.03,78.53,79.762,null,69.39,70.26,71.24,71.52,71.89,72.22,73.84,74.32,76.33,77.55,79.11,80.204,null,42.314,45.432,48.632,51.884,55.151,57.47,59.298,62.008,65.843,68.426,70.836,72.899,null,37.444,38.598,39.487,40.118,40.546,41.291,42.598,44.555,47.391,51.313,54.496,56.867,null,36.324,37.802,39.36,41.04,42.821,44.514,45.826,46.886,47.472,47.464,46.608,46.859,null,72.67,73.44,73.47,74.08,74.34,75.37,75.97,75.89,77.32,78.32,79.05,80.196,null,37.578,40.08,43.165,46.988,52.143,57.367,62.728,67.734,71.197,72.499,74.193,75.64,null,43.436,45.557,47.67,49.8,51.929,54.043,56.158,58.245,60.838,61.818,63.61,65.483,null,55.191,59.201,61.817,64.071,66.216,68.681,70.472,71.523,72.462,73.738,74.712,75.537,null,62.649,63.196,64.361,64.951,65.815,66.353,66.874,67.378,68.225,69.4,70.755,71.752,null,43.902,46.263,49.096,51.445,55.448,58.447,61.406,64.134,66.458,68.386,69.906,71.421,null,47.752,51.334,54.757,56.393,58.065,60.06,62.082,64.151,66.458,68.564,70.303,71.688,null,61.31,65.77,67.64,69.61,70.85,70.67,71.32,70.98,70.99,72.75,74.67,75.563,null,59.82,61.51,64.39,66.6,69.26,70.41,72.77,74.06,74.86,75.97,77.29,78.098,null,64.28,68.54,69.62,71.1,72.16,73.44,73.75,74.63,73.911,74.917,77.778,78.746,null,52.724,55.09,57.666,60.542,64.274,67.064,69.885,71.913,73.615,74.772,75.744,76.442,null,61.05,64.1,66.8,66.8,69.21,69.46,69.66,69.53,69.36,69.72,71.322,72.476,null,40,41.5,43,44.1,44.6,45,46.218,44.02,23.599,36.087,43.413,46.242,null,46.471,48.945,51.893,54.425,56.48,58.55,60.351,61.728,62.742,63.306,64.337,65.528,null,39.875,42.868,45.914,49.901,53.886,58.69,63.012,66.295,68.768,70.533,71.626,72.777,null,37.278,39.329,41.454,43.563,45.815,48.879,52.379,55.769,58.196,60.187,61.6,63.062,null,57.996,61.685,64.531,66.914,68.7,70.3,70.162,71.218,71.659,72.232,73.213,74.002,null,30.331,31.57,32.767,34.113,35.4,36.788,38.445,40.006,38.333,39.897,41.012,42.568,null,60.396,63.179,65.798,67.946,69.521,70.795,71.76,73.56,75.788,77.158,78.77,79.972,null,64.36,67.45,70.33,70.98,70.35,70.45,70.8,71.08,71.38,72.71,73.8,74.663,null,65.57,67.85,69.15,69.18,69.82,70.97,71.063,72.25,73.64,75.13,76.66,77.926,null,32.978,34.977,36.981,38.977,40.973,41.974,42.955,44.501,39.658,43.795,45.936,48.159,null,45.009,47.985,49.951,51.927,53.696,55.527,58.161,60.834,61.888,60.236,53.365,49.339,null,64.94,66.66,69.69,71.44,73.06,74.39,76.3,76.9,77.57,78.77,79.78,80.941,null,57.593,61.456,62.192,64.266,65.042,65.949,68.757,69.011,70.379,70.457,70.815,72.396,null,38.635,39.624,40.87,42.858,45.083,47.8,50.338,51.744,53.556,55.373,56.369,58.556,null,41.407,43.424,44.992,46.633,49.552,52.537,55.561,57.678,58.474,54.289,43.869,39.613,null,71.86,72.49,73.37,74.16,74.72,75.44,76.42,77.19,78.16,79.39,80.04,80.884,null,69.62,70.56,71.32,72.77,73.78,75.39,76.21,77.41,78.03,79.37,80.62,81.701,null,45.883,48.284,50.305,53.655,57.296,61.195,64.59,66.974,69.249,71.527,73.053,74.143,null,58.5,62.4,65.2,67.5,69.39,70.59,72.16,73.4,74.26,75.25,76.99,78.4,null,41.215,42.974,44.246,45.757,47.62,49.919,50.608,51.535,50.44,48.466,49.651,52.517,null,50.848,53.63,56.061,58.285,60.405,62.494,64.597,66.084,67.298,67.521,68.564,70.616,null,38.596,41.208,43.922,46.769,49.759,52.887,55.471,56.941,58.061,58.39,57.561,58.42,null,59.1,61.8,64.9,65.4,65.9,68.3,68.832,69.582,69.862,69.465,68.976,69.819,null,44.6,47.1,49.579,52.053,55.602,59.837,64.048,66.894,70.001,71.973,73.042,73.923,null,43.585,48.079,52.098,54.336,57.005,59.507,61.036,63.108,66.146,68.835,70.845,71.777,null,39.978,42.571,45.344,48.051,51.016,50.35,49.849,51.509,48.825,44.578,47.813,51.542,null,69.18,70.42,70.76,71.36,72.01,72.76,74.04,75.007,76.42,77.218,78.471,79.425,null,68.44,69.49,70.21,70.76,71.34,73.38,74.65,75.02,76.09,76.81,77.31,78.242,null,66.071,67.044,68.253,68.468,68.673,69.481,70.805,71.918,72.752,74.223,75.307,76.384,null,55.088,57.907,60.77,63.479,65.712,67.456,68.557,70.19,71.15,72.146,72.766,73.747,null,40.412,42.887,45.363,47.838,50.254,55.764,58.816,62.82,67.662,70.672,73.017,74.249,null,43.16,45.671,48.127,51.631,56.532,60.765,64.406,67.046,69.718,71.096,72.37,73.422,null,32.548,33.97,35.18,36.984,39.848,44.175,49.113,52.922,55.599,58.02,60.308,62.698,null,42.038,44.077,46.023,47.768,50.107,51.386,51.821,50.821,46.1,40.238,39.193,42.384,null,48.451,50.469,52.358,53.995,55.635,57.674,60.363,62.351,60.377,46.809,39.989,43.487],\"text\":[\"year: 1952<br />lifeExp: 28.80100<br />country: Afghanistan\",\"year: 1957<br />lifeExp: 30.33200<br />country: Afghanistan\",\"year: 1962<br />lifeExp: 31.99700<br />country: Afghanistan\",\"year: 1967<br />lifeExp: 34.02000<br />country: Afghanistan\",\"year: 1972<br />lifeExp: 36.08800<br />country: Afghanistan\",\"year: 1977<br />lifeExp: 38.43800<br />country: Afghanistan\",\"year: 1982<br />lifeExp: 39.85400<br />country: Afghanistan\",\"year: 1987<br />lifeExp: 40.82200<br />country: Afghanistan\",\"year: 1992<br />lifeExp: 41.67400<br />country: Afghanistan\",\"year: 1997<br />lifeExp: 41.76300<br />country: Afghanistan\",\"year: 2002<br />lifeExp: 42.12900<br />country: Afghanistan\",\"year: 2007<br />lifeExp: 43.82800<br />country: Afghanistan\",null,\"year: 1952<br />lifeExp: 55.23000<br />country: Albania\",\"year: 1957<br />lifeExp: 59.28000<br />country: Albania\",\"year: 1962<br />lifeExp: 64.82000<br />country: Albania\",\"year: 1967<br />lifeExp: 66.22000<br />country: Albania\",\"year: 1972<br />lifeExp: 67.69000<br />country: Albania\",\"year: 1977<br />lifeExp: 68.93000<br />country: Albania\",\"year: 1982<br />lifeExp: 70.42000<br />country: Albania\",\"year: 1987<br />lifeExp: 72.00000<br />country: Albania\",\"year: 1992<br />lifeExp: 71.58100<br />country: Albania\",\"year: 1997<br />lifeExp: 72.95000<br />country: Albania\",\"year: 2002<br />lifeExp: 75.65100<br />country: Albania\",\"year: 2007<br />lifeExp: 76.42300<br />country: Albania\",null,\"year: 1952<br />lifeExp: 43.07700<br />country: Algeria\",\"year: 1957<br />lifeExp: 45.68500<br />country: Algeria\",\"year: 1962<br />lifeExp: 48.30300<br />country: Algeria\",\"year: 1967<br />lifeExp: 51.40700<br />country: Algeria\",\"year: 1972<br />lifeExp: 54.51800<br />country: Algeria\",\"year: 1977<br />lifeExp: 58.01400<br />country: Algeria\",\"year: 1982<br />lifeExp: 61.36800<br />country: Algeria\",\"year: 1987<br />lifeExp: 65.79900<br />country: Algeria\",\"year: 1992<br />lifeExp: 67.74400<br />country: Algeria\",\"year: 1997<br />lifeExp: 69.15200<br />country: Algeria\",\"year: 2002<br />lifeExp: 70.99400<br />country: Algeria\",\"year: 2007<br />lifeExp: 72.30100<br />country: Algeria\",null,\"year: 1952<br />lifeExp: 30.01500<br />country: Angola\",\"year: 1957<br />lifeExp: 31.99900<br />country: Angola\",\"year: 1962<br />lifeExp: 34.00000<br />country: Angola\",\"year: 1967<br />lifeExp: 35.98500<br />country: Angola\",\"year: 1972<br />lifeExp: 37.92800<br />country: Angola\",\"year: 1977<br />lifeExp: 39.48300<br />country: Angola\",\"year: 1982<br />lifeExp: 39.94200<br />country: Angola\",\"year: 1987<br />lifeExp: 39.90600<br />country: Angola\",\"year: 1992<br />lifeExp: 40.64700<br />country: Angola\",\"year: 1997<br />lifeExp: 40.96300<br />country: Angola\",\"year: 2002<br />lifeExp: 41.00300<br />country: Angola\",\"year: 2007<br />lifeExp: 42.73100<br />country: Angola\",null,\"year: 1952<br />lifeExp: 62.48500<br />country: Argentina\",\"year: 1957<br />lifeExp: 64.39900<br />country: Argentina\",\"year: 1962<br />lifeExp: 65.14200<br />country: Argentina\",\"year: 1967<br />lifeExp: 65.63400<br />country: Argentina\",\"year: 1972<br />lifeExp: 67.06500<br />country: Argentina\",\"year: 1977<br />lifeExp: 68.48100<br />country: Argentina\",\"year: 1982<br />lifeExp: 69.94200<br />country: Argentina\",\"year: 1987<br />lifeExp: 70.77400<br />country: Argentina\",\"year: 1992<br />lifeExp: 71.86800<br />country: Argentina\",\"year: 1997<br />lifeExp: 73.27500<br />country: Argentina\",\"year: 2002<br />lifeExp: 74.34000<br />country: Argentina\",\"year: 2007<br />lifeExp: 75.32000<br />country: Argentina\",null,\"year: 1952<br />lifeExp: 69.12000<br />country: Australia\",\"year: 1957<br />lifeExp: 70.33000<br />country: Australia\",\"year: 1962<br />lifeExp: 70.93000<br />country: Australia\",\"year: 1967<br />lifeExp: 71.10000<br />country: Australia\",\"year: 1972<br />lifeExp: 71.93000<br />country: Australia\",\"year: 1977<br />lifeExp: 73.49000<br />country: Australia\",\"year: 1982<br />lifeExp: 74.74000<br />country: Australia\",\"year: 1987<br />lifeExp: 76.32000<br />country: Australia\",\"year: 1992<br />lifeExp: 77.56000<br />country: Australia\",\"year: 1997<br />lifeExp: 78.83000<br />country: Australia\",\"year: 2002<br />lifeExp: 80.37000<br />country: Australia\",\"year: 2007<br />lifeExp: 81.23500<br />country: Australia\",null,\"year: 1952<br />lifeExp: 66.80000<br />country: Austria\",\"year: 1957<br />lifeExp: 67.48000<br />country: Austria\",\"year: 1962<br />lifeExp: 69.54000<br />country: Austria\",\"year: 1967<br />lifeExp: 70.14000<br />country: Austria\",\"year: 1972<br />lifeExp: 70.63000<br />country: Austria\",\"year: 1977<br />lifeExp: 72.17000<br />country: Austria\",\"year: 1982<br />lifeExp: 73.18000<br />country: Austria\",\"year: 1987<br />lifeExp: 74.94000<br />country: Austria\",\"year: 1992<br />lifeExp: 76.04000<br />country: Austria\",\"year: 1997<br />lifeExp: 77.51000<br />country: Austria\",\"year: 2002<br />lifeExp: 78.98000<br />country: Austria\",\"year: 2007<br />lifeExp: 79.82900<br />country: Austria\",null,\"year: 1952<br />lifeExp: 50.93900<br />country: Bahrain\",\"year: 1957<br />lifeExp: 53.83200<br />country: Bahrain\",\"year: 1962<br />lifeExp: 56.92300<br />country: Bahrain\",\"year: 1967<br />lifeExp: 59.92300<br />country: Bahrain\",\"year: 1972<br />lifeExp: 63.30000<br />country: Bahrain\",\"year: 1977<br />lifeExp: 65.59300<br />country: Bahrain\",\"year: 1982<br />lifeExp: 69.05200<br />country: Bahrain\",\"year: 1987<br />lifeExp: 70.75000<br />country: Bahrain\",\"year: 1992<br />lifeExp: 72.60100<br />country: Bahrain\",\"year: 1997<br />lifeExp: 73.92500<br />country: Bahrain\",\"year: 2002<br />lifeExp: 74.79500<br />country: Bahrain\",\"year: 2007<br />lifeExp: 75.63500<br />country: Bahrain\",null,\"year: 1952<br />lifeExp: 37.48400<br />country: Bangladesh\",\"year: 1957<br />lifeExp: 39.34800<br />country: Bangladesh\",\"year: 1962<br />lifeExp: 41.21600<br />country: Bangladesh\",\"year: 1967<br />lifeExp: 43.45300<br />country: Bangladesh\",\"year: 1972<br />lifeExp: 45.25200<br />country: Bangladesh\",\"year: 1977<br />lifeExp: 46.92300<br />country: Bangladesh\",\"year: 1982<br />lifeExp: 50.00900<br />country: Bangladesh\",\"year: 1987<br />lifeExp: 52.81900<br />country: Bangladesh\",\"year: 1992<br />lifeExp: 56.01800<br />country: Bangladesh\",\"year: 1997<br />lifeExp: 59.41200<br />country: Bangladesh\",\"year: 2002<br />lifeExp: 62.01300<br />country: Bangladesh\",\"year: 2007<br />lifeExp: 64.06200<br />country: Bangladesh\",null,\"year: 1952<br />lifeExp: 68.00000<br />country: Belgium\",\"year: 1957<br />lifeExp: 69.24000<br />country: Belgium\",\"year: 1962<br />lifeExp: 70.25000<br />country: Belgium\",\"year: 1967<br />lifeExp: 70.94000<br />country: Belgium\",\"year: 1972<br />lifeExp: 71.44000<br />country: Belgium\",\"year: 1977<br />lifeExp: 72.80000<br />country: Belgium\",\"year: 1982<br />lifeExp: 73.93000<br />country: Belgium\",\"year: 1987<br />lifeExp: 75.35000<br />country: Belgium\",\"year: 1992<br />lifeExp: 76.46000<br />country: Belgium\",\"year: 1997<br />lifeExp: 77.53000<br />country: Belgium\",\"year: 2002<br />lifeExp: 78.32000<br />country: Belgium\",\"year: 2007<br />lifeExp: 79.44100<br />country: Belgium\",null,\"year: 1952<br />lifeExp: 38.22300<br />country: Benin\",\"year: 1957<br />lifeExp: 40.35800<br />country: Benin\",\"year: 1962<br />lifeExp: 42.61800<br />country: Benin\",\"year: 1967<br />lifeExp: 44.88500<br />country: Benin\",\"year: 1972<br />lifeExp: 47.01400<br />country: Benin\",\"year: 1977<br />lifeExp: 49.19000<br />country: Benin\",\"year: 1982<br />lifeExp: 50.90400<br />country: Benin\",\"year: 1987<br />lifeExp: 52.33700<br />country: Benin\",\"year: 1992<br />lifeExp: 53.91900<br />country: Benin\",\"year: 1997<br />lifeExp: 54.77700<br />country: Benin\",\"year: 2002<br />lifeExp: 54.40600<br />country: Benin\",\"year: 2007<br />lifeExp: 56.72800<br />country: Benin\",null,\"year: 1952<br />lifeExp: 40.41400<br />country: Bolivia\",\"year: 1957<br />lifeExp: 41.89000<br />country: Bolivia\",\"year: 1962<br />lifeExp: 43.42800<br />country: Bolivia\",\"year: 1967<br />lifeExp: 45.03200<br />country: Bolivia\",\"year: 1972<br />lifeExp: 46.71400<br />country: Bolivia\",\"year: 1977<br />lifeExp: 50.02300<br />country: Bolivia\",\"year: 1982<br />lifeExp: 53.85900<br />country: Bolivia\",\"year: 1987<br />lifeExp: 57.25100<br />country: Bolivia\",\"year: 1992<br />lifeExp: 59.95700<br />country: Bolivia\",\"year: 1997<br />lifeExp: 62.05000<br />country: Bolivia\",\"year: 2002<br />lifeExp: 63.88300<br />country: Bolivia\",\"year: 2007<br />lifeExp: 65.55400<br />country: Bolivia\",null,\"year: 1952<br />lifeExp: 53.82000<br />country: Bosnia and Herzegovina\",\"year: 1957<br />lifeExp: 58.45000<br />country: Bosnia and Herzegovina\",\"year: 1962<br />lifeExp: 61.93000<br />country: Bosnia and Herzegovina\",\"year: 1967<br />lifeExp: 64.79000<br />country: Bosnia and Herzegovina\",\"year: 1972<br />lifeExp: 67.45000<br />country: Bosnia and Herzegovina\",\"year: 1977<br />lifeExp: 69.86000<br />country: Bosnia and Herzegovina\",\"year: 1982<br />lifeExp: 70.69000<br />country: Bosnia and Herzegovina\",\"year: 1987<br />lifeExp: 71.14000<br />country: Bosnia and Herzegovina\",\"year: 1992<br />lifeExp: 72.17800<br />country: Bosnia and Herzegovina\",\"year: 1997<br />lifeExp: 73.24400<br />country: Bosnia and Herzegovina\",\"year: 2002<br />lifeExp: 74.09000<br />country: Bosnia and Herzegovina\",\"year: 2007<br />lifeExp: 74.85200<br />country: Bosnia and Herzegovina\",null,\"year: 1952<br />lifeExp: 47.62200<br />country: Botswana\",\"year: 1957<br />lifeExp: 49.61800<br />country: Botswana\",\"year: 1962<br />lifeExp: 51.52000<br />country: Botswana\",\"year: 1967<br />lifeExp: 53.29800<br />country: Botswana\",\"year: 1972<br />lifeExp: 56.02400<br />country: Botswana\",\"year: 1977<br />lifeExp: 59.31900<br />country: Botswana\",\"year: 1982<br />lifeExp: 61.48400<br />country: Botswana\",\"year: 1987<br />lifeExp: 63.62200<br />country: Botswana\",\"year: 1992<br />lifeExp: 62.74500<br />country: Botswana\",\"year: 1997<br />lifeExp: 52.55600<br />country: Botswana\",\"year: 2002<br />lifeExp: 46.63400<br />country: Botswana\",\"year: 2007<br />lifeExp: 50.72800<br />country: Botswana\",null,\"year: 1952<br />lifeExp: 50.91700<br />country: Brazil\",\"year: 1957<br />lifeExp: 53.28500<br />country: Brazil\",\"year: 1962<br />lifeExp: 55.66500<br />country: Brazil\",\"year: 1967<br />lifeExp: 57.63200<br />country: Brazil\",\"year: 1972<br />lifeExp: 59.50400<br />country: Brazil\",\"year: 1977<br />lifeExp: 61.48900<br />country: Brazil\",\"year: 1982<br />lifeExp: 63.33600<br />country: Brazil\",\"year: 1987<br />lifeExp: 65.20500<br />country: Brazil\",\"year: 1992<br />lifeExp: 67.05700<br />country: Brazil\",\"year: 1997<br />lifeExp: 69.38800<br />country: Brazil\",\"year: 2002<br />lifeExp: 71.00600<br />country: Brazil\",\"year: 2007<br />lifeExp: 72.39000<br />country: Brazil\",null,\"year: 1952<br />lifeExp: 59.60000<br />country: Bulgaria\",\"year: 1957<br />lifeExp: 66.61000<br />country: Bulgaria\",\"year: 1962<br />lifeExp: 69.51000<br />country: Bulgaria\",\"year: 1967<br />lifeExp: 70.42000<br />country: Bulgaria\",\"year: 1972<br />lifeExp: 70.90000<br />country: Bulgaria\",\"year: 1977<br />lifeExp: 70.81000<br />country: Bulgaria\",\"year: 1982<br />lifeExp: 71.08000<br />country: Bulgaria\",\"year: 1987<br />lifeExp: 71.34000<br />country: Bulgaria\",\"year: 1992<br />lifeExp: 71.19000<br />country: Bulgaria\",\"year: 1997<br />lifeExp: 70.32000<br />country: Bulgaria\",\"year: 2002<br />lifeExp: 72.14000<br />country: Bulgaria\",\"year: 2007<br />lifeExp: 73.00500<br />country: Bulgaria\",null,\"year: 1952<br />lifeExp: 31.97500<br />country: Burkina Faso\",\"year: 1957<br />lifeExp: 34.90600<br />country: Burkina Faso\",\"year: 1962<br />lifeExp: 37.81400<br />country: Burkina Faso\",\"year: 1967<br />lifeExp: 40.69700<br />country: Burkina Faso\",\"year: 1972<br />lifeExp: 43.59100<br />country: Burkina Faso\",\"year: 1977<br />lifeExp: 46.13700<br />country: Burkina Faso\",\"year: 1982<br />lifeExp: 48.12200<br />country: Burkina Faso\",\"year: 1987<br />lifeExp: 49.55700<br />country: Burkina Faso\",\"year: 1992<br />lifeExp: 50.26000<br />country: Burkina Faso\",\"year: 1997<br />lifeExp: 50.32400<br />country: Burkina Faso\",\"year: 2002<br />lifeExp: 50.65000<br />country: Burkina Faso\",\"year: 2007<br />lifeExp: 52.29500<br />country: Burkina Faso\",null,\"year: 1952<br />lifeExp: 39.03100<br />country: Burundi\",\"year: 1957<br />lifeExp: 40.53300<br />country: Burundi\",\"year: 1962<br />lifeExp: 42.04500<br />country: Burundi\",\"year: 1967<br />lifeExp: 43.54800<br />country: Burundi\",\"year: 1972<br />lifeExp: 44.05700<br />country: Burundi\",\"year: 1977<br />lifeExp: 45.91000<br />country: Burundi\",\"year: 1982<br />lifeExp: 47.47100<br />country: Burundi\",\"year: 1987<br />lifeExp: 48.21100<br />country: Burundi\",\"year: 1992<br />lifeExp: 44.73600<br />country: Burundi\",\"year: 1997<br />lifeExp: 45.32600<br />country: Burundi\",\"year: 2002<br />lifeExp: 47.36000<br />country: Burundi\",\"year: 2007<br />lifeExp: 49.58000<br />country: Burundi\",null,\"year: 1952<br />lifeExp: 39.41700<br />country: Cambodia\",\"year: 1957<br />lifeExp: 41.36600<br />country: Cambodia\",\"year: 1962<br />lifeExp: 43.41500<br />country: Cambodia\",\"year: 1967<br />lifeExp: 45.41500<br />country: Cambodia\",\"year: 1972<br />lifeExp: 40.31700<br />country: Cambodia\",\"year: 1977<br />lifeExp: 31.22000<br />country: Cambodia\",\"year: 1982<br />lifeExp: 50.95700<br />country: Cambodia\",\"year: 1987<br />lifeExp: 53.91400<br />country: Cambodia\",\"year: 1992<br />lifeExp: 55.80300<br />country: Cambodia\",\"year: 1997<br />lifeExp: 56.53400<br />country: Cambodia\",\"year: 2002<br />lifeExp: 56.75200<br />country: Cambodia\",\"year: 2007<br />lifeExp: 59.72300<br />country: Cambodia\",null,\"year: 1952<br />lifeExp: 38.52300<br />country: Cameroon\",\"year: 1957<br />lifeExp: 40.42800<br />country: Cameroon\",\"year: 1962<br />lifeExp: 42.64300<br />country: Cameroon\",\"year: 1967<br />lifeExp: 44.79900<br />country: Cameroon\",\"year: 1972<br />lifeExp: 47.04900<br />country: Cameroon\",\"year: 1977<br />lifeExp: 49.35500<br />country: Cameroon\",\"year: 1982<br />lifeExp: 52.96100<br />country: Cameroon\",\"year: 1987<br />lifeExp: 54.98500<br />country: Cameroon\",\"year: 1992<br />lifeExp: 54.31400<br />country: Cameroon\",\"year: 1997<br />lifeExp: 52.19900<br />country: Cameroon\",\"year: 2002<br />lifeExp: 49.85600<br />country: Cameroon\",\"year: 2007<br />lifeExp: 50.43000<br />country: Cameroon\",null,\"year: 1952<br />lifeExp: 68.75000<br />country: Canada\",\"year: 1957<br />lifeExp: 69.96000<br />country: Canada\",\"year: 1962<br />lifeExp: 71.30000<br />country: Canada\",\"year: 1967<br />lifeExp: 72.13000<br />country: Canada\",\"year: 1972<br />lifeExp: 72.88000<br />country: Canada\",\"year: 1977<br />lifeExp: 74.21000<br />country: Canada\",\"year: 1982<br />lifeExp: 75.76000<br />country: Canada\",\"year: 1987<br />lifeExp: 76.86000<br />country: Canada\",\"year: 1992<br />lifeExp: 77.95000<br />country: Canada\",\"year: 1997<br />lifeExp: 78.61000<br />country: Canada\",\"year: 2002<br />lifeExp: 79.77000<br />country: Canada\",\"year: 2007<br />lifeExp: 80.65300<br />country: Canada\",null,\"year: 1952<br />lifeExp: 35.46300<br />country: Central African Republic\",\"year: 1957<br />lifeExp: 37.46400<br />country: Central African Republic\",\"year: 1962<br />lifeExp: 39.47500<br />country: Central African Republic\",\"year: 1967<br />lifeExp: 41.47800<br />country: Central African Republic\",\"year: 1972<br />lifeExp: 43.45700<br />country: Central African Republic\",\"year: 1977<br />lifeExp: 46.77500<br />country: Central African Republic\",\"year: 1982<br />lifeExp: 48.29500<br />country: Central African Republic\",\"year: 1987<br />lifeExp: 50.48500<br />country: Central African Republic\",\"year: 1992<br />lifeExp: 49.39600<br />country: Central African Republic\",\"year: 1997<br />lifeExp: 46.06600<br />country: Central African Republic\",\"year: 2002<br />lifeExp: 43.30800<br />country: Central African Republic\",\"year: 2007<br />lifeExp: 44.74100<br />country: Central African Republic\",null,\"year: 1952<br />lifeExp: 38.09200<br />country: Chad\",\"year: 1957<br />lifeExp: 39.88100<br />country: Chad\",\"year: 1962<br />lifeExp: 41.71600<br />country: Chad\",\"year: 1967<br />lifeExp: 43.60100<br />country: Chad\",\"year: 1972<br />lifeExp: 45.56900<br />country: Chad\",\"year: 1977<br />lifeExp: 47.38300<br />country: Chad\",\"year: 1982<br />lifeExp: 49.51700<br />country: Chad\",\"year: 1987<br />lifeExp: 51.05100<br />country: Chad\",\"year: 1992<br />lifeExp: 51.72400<br />country: Chad\",\"year: 1997<br />lifeExp: 51.57300<br />country: Chad\",\"year: 2002<br />lifeExp: 50.52500<br />country: Chad\",\"year: 2007<br />lifeExp: 50.65100<br />country: Chad\",null,\"year: 1952<br />lifeExp: 54.74500<br />country: Chile\",\"year: 1957<br />lifeExp: 56.07400<br />country: Chile\",\"year: 1962<br />lifeExp: 57.92400<br />country: Chile\",\"year: 1967<br />lifeExp: 60.52300<br />country: Chile\",\"year: 1972<br />lifeExp: 63.44100<br />country: Chile\",\"year: 1977<br />lifeExp: 67.05200<br />country: Chile\",\"year: 1982<br />lifeExp: 70.56500<br />country: Chile\",\"year: 1987<br />lifeExp: 72.49200<br />country: Chile\",\"year: 1992<br />lifeExp: 74.12600<br />country: Chile\",\"year: 1997<br />lifeExp: 75.81600<br />country: Chile\",\"year: 2002<br />lifeExp: 77.86000<br />country: Chile\",\"year: 2007<br />lifeExp: 78.55300<br />country: Chile\",null,\"year: 1952<br />lifeExp: 44.00000<br />country: China\",\"year: 1957<br />lifeExp: 50.54896<br />country: China\",\"year: 1962<br />lifeExp: 44.50136<br />country: China\",\"year: 1967<br />lifeExp: 58.38112<br />country: China\",\"year: 1972<br />lifeExp: 63.11888<br />country: China\",\"year: 1977<br />lifeExp: 63.96736<br />country: China\",\"year: 1982<br />lifeExp: 65.52500<br />country: China\",\"year: 1987<br />lifeExp: 67.27400<br />country: China\",\"year: 1992<br />lifeExp: 68.69000<br />country: China\",\"year: 1997<br />lifeExp: 70.42600<br />country: China\",\"year: 2002<br />lifeExp: 72.02800<br />country: China\",\"year: 2007<br />lifeExp: 72.96100<br />country: China\",null,\"year: 1952<br />lifeExp: 50.64300<br />country: Colombia\",\"year: 1957<br />lifeExp: 55.11800<br />country: Colombia\",\"year: 1962<br />lifeExp: 57.86300<br />country: Colombia\",\"year: 1967<br />lifeExp: 59.96300<br />country: Colombia\",\"year: 1972<br />lifeExp: 61.62300<br />country: Colombia\",\"year: 1977<br />lifeExp: 63.83700<br />country: Colombia\",\"year: 1982<br />lifeExp: 66.65300<br />country: Colombia\",\"year: 1987<br />lifeExp: 67.76800<br />country: Colombia\",\"year: 1992<br />lifeExp: 68.42100<br />country: Colombia\",\"year: 1997<br />lifeExp: 70.31300<br />country: Colombia\",\"year: 2002<br />lifeExp: 71.68200<br />country: Colombia\",\"year: 2007<br />lifeExp: 72.88900<br />country: Colombia\",null,\"year: 1952<br />lifeExp: 40.71500<br />country: Comoros\",\"year: 1957<br />lifeExp: 42.46000<br />country: Comoros\",\"year: 1962<br />lifeExp: 44.46700<br />country: Comoros\",\"year: 1967<br />lifeExp: 46.47200<br />country: Comoros\",\"year: 1972<br />lifeExp: 48.94400<br />country: Comoros\",\"year: 1977<br />lifeExp: 50.93900<br />country: Comoros\",\"year: 1982<br />lifeExp: 52.93300<br />country: Comoros\",\"year: 1987<br />lifeExp: 54.92600<br />country: Comoros\",\"year: 1992<br />lifeExp: 57.93900<br />country: Comoros\",\"year: 1997<br />lifeExp: 60.66000<br />country: Comoros\",\"year: 2002<br />lifeExp: 62.97400<br />country: Comoros\",\"year: 2007<br />lifeExp: 65.15200<br />country: Comoros\",null,\"year: 1952<br />lifeExp: 39.14300<br />country: Congo, Dem. Rep.\",\"year: 1957<br />lifeExp: 40.65200<br />country: Congo, Dem. Rep.\",\"year: 1962<br />lifeExp: 42.12200<br />country: Congo, Dem. Rep.\",\"year: 1967<br />lifeExp: 44.05600<br />country: Congo, Dem. Rep.\",\"year: 1972<br />lifeExp: 45.98900<br />country: Congo, Dem. Rep.\",\"year: 1977<br />lifeExp: 47.80400<br />country: Congo, Dem. Rep.\",\"year: 1982<br />lifeExp: 47.78400<br />country: Congo, Dem. Rep.\",\"year: 1987<br />lifeExp: 47.41200<br />country: Congo, Dem. Rep.\",\"year: 1992<br />lifeExp: 45.54800<br />country: Congo, Dem. Rep.\",\"year: 1997<br />lifeExp: 42.58700<br />country: Congo, Dem. Rep.\",\"year: 2002<br />lifeExp: 44.96600<br />country: Congo, Dem. Rep.\",\"year: 2007<br />lifeExp: 46.46200<br />country: Congo, Dem. Rep.\",null,\"year: 1952<br />lifeExp: 42.11100<br />country: Congo, Rep.\",\"year: 1957<br />lifeExp: 45.05300<br />country: Congo, Rep.\",\"year: 1962<br />lifeExp: 48.43500<br />country: Congo, Rep.\",\"year: 1967<br />lifeExp: 52.04000<br />country: Congo, Rep.\",\"year: 1972<br />lifeExp: 54.90700<br />country: Congo, Rep.\",\"year: 1977<br />lifeExp: 55.62500<br />country: Congo, Rep.\",\"year: 1982<br />lifeExp: 56.69500<br />country: Congo, Rep.\",\"year: 1987<br />lifeExp: 57.47000<br />country: Congo, Rep.\",\"year: 1992<br />lifeExp: 56.43300<br />country: Congo, Rep.\",\"year: 1997<br />lifeExp: 52.96200<br />country: Congo, Rep.\",\"year: 2002<br />lifeExp: 52.97000<br />country: Congo, Rep.\",\"year: 2007<br />lifeExp: 55.32200<br />country: Congo, Rep.\",null,\"year: 1952<br />lifeExp: 57.20600<br />country: Costa Rica\",\"year: 1957<br />lifeExp: 60.02600<br />country: Costa Rica\",\"year: 1962<br />lifeExp: 62.84200<br />country: Costa Rica\",\"year: 1967<br />lifeExp: 65.42400<br />country: Costa Rica\",\"year: 1972<br />lifeExp: 67.84900<br />country: Costa Rica\",\"year: 1977<br />lifeExp: 70.75000<br />country: Costa Rica\",\"year: 1982<br />lifeExp: 73.45000<br />country: Costa Rica\",\"year: 1987<br />lifeExp: 74.75200<br />country: Costa Rica\",\"year: 1992<br />lifeExp: 75.71300<br />country: Costa Rica\",\"year: 1997<br />lifeExp: 77.26000<br />country: Costa Rica\",\"year: 2002<br />lifeExp: 78.12300<br />country: Costa Rica\",\"year: 2007<br />lifeExp: 78.78200<br />country: Costa Rica\",null,\"year: 1952<br />lifeExp: 40.47700<br />country: Cote d'Ivoire\",\"year: 1957<br />lifeExp: 42.46900<br />country: Cote d'Ivoire\",\"year: 1962<br />lifeExp: 44.93000<br />country: Cote d'Ivoire\",\"year: 1967<br />lifeExp: 47.35000<br />country: Cote d'Ivoire\",\"year: 1972<br />lifeExp: 49.80100<br />country: Cote d'Ivoire\",\"year: 1977<br />lifeExp: 52.37400<br />country: Cote d'Ivoire\",\"year: 1982<br />lifeExp: 53.98300<br />country: Cote d'Ivoire\",\"year: 1987<br />lifeExp: 54.65500<br />country: Cote d'Ivoire\",\"year: 1992<br />lifeExp: 52.04400<br />country: Cote d'Ivoire\",\"year: 1997<br />lifeExp: 47.99100<br />country: Cote d'Ivoire\",\"year: 2002<br />lifeExp: 46.83200<br />country: Cote d'Ivoire\",\"year: 2007<br />lifeExp: 48.32800<br />country: Cote d'Ivoire\",null,\"year: 1952<br />lifeExp: 61.21000<br />country: Croatia\",\"year: 1957<br />lifeExp: 64.77000<br />country: Croatia\",\"year: 1962<br />lifeExp: 67.13000<br />country: Croatia\",\"year: 1967<br />lifeExp: 68.50000<br />country: Croatia\",\"year: 1972<br />lifeExp: 69.61000<br />country: Croatia\",\"year: 1977<br />lifeExp: 70.64000<br />country: Croatia\",\"year: 1982<br />lifeExp: 70.46000<br />country: Croatia\",\"year: 1987<br />lifeExp: 71.52000<br />country: Croatia\",\"year: 1992<br />lifeExp: 72.52700<br />country: Croatia\",\"year: 1997<br />lifeExp: 73.68000<br />country: Croatia\",\"year: 2002<br />lifeExp: 74.87600<br />country: Croatia\",\"year: 2007<br />lifeExp: 75.74800<br />country: Croatia\",null,\"year: 1952<br />lifeExp: 59.42100<br />country: Cuba\",\"year: 1957<br />lifeExp: 62.32500<br />country: Cuba\",\"year: 1962<br />lifeExp: 65.24600<br />country: Cuba\",\"year: 1967<br />lifeExp: 68.29000<br />country: Cuba\",\"year: 1972<br />lifeExp: 70.72300<br />country: Cuba\",\"year: 1977<br />lifeExp: 72.64900<br />country: Cuba\",\"year: 1982<br />lifeExp: 73.71700<br />country: Cuba\",\"year: 1987<br />lifeExp: 74.17400<br />country: Cuba\",\"year: 1992<br />lifeExp: 74.41400<br />country: Cuba\",\"year: 1997<br />lifeExp: 76.15100<br />country: Cuba\",\"year: 2002<br />lifeExp: 77.15800<br />country: Cuba\",\"year: 2007<br />lifeExp: 78.27300<br />country: Cuba\",null,\"year: 1952<br />lifeExp: 66.87000<br />country: Czech Republic\",\"year: 1957<br />lifeExp: 69.03000<br />country: Czech Republic\",\"year: 1962<br />lifeExp: 69.90000<br />country: Czech Republic\",\"year: 1967<br />lifeExp: 70.38000<br />country: Czech Republic\",\"year: 1972<br />lifeExp: 70.29000<br />country: Czech Republic\",\"year: 1977<br />lifeExp: 70.71000<br />country: Czech Republic\",\"year: 1982<br />lifeExp: 70.96000<br />country: Czech Republic\",\"year: 1987<br />lifeExp: 71.58000<br />country: Czech Republic\",\"year: 1992<br />lifeExp: 72.40000<br />country: Czech Republic\",\"year: 1997<br />lifeExp: 74.01000<br />country: Czech Republic\",\"year: 2002<br />lifeExp: 75.51000<br />country: Czech Republic\",\"year: 2007<br />lifeExp: 76.48600<br />country: Czech Republic\",null,\"year: 1952<br />lifeExp: 70.78000<br />country: Denmark\",\"year: 1957<br />lifeExp: 71.81000<br />country: Denmark\",\"year: 1962<br />lifeExp: 72.35000<br />country: Denmark\",\"year: 1967<br />lifeExp: 72.96000<br />country: Denmark\",\"year: 1972<br />lifeExp: 73.47000<br />country: Denmark\",\"year: 1977<br />lifeExp: 74.69000<br />country: Denmark\",\"year: 1982<br />lifeExp: 74.63000<br />country: Denmark\",\"year: 1987<br />lifeExp: 74.80000<br />country: Denmark\",\"year: 1992<br />lifeExp: 75.33000<br />country: Denmark\",\"year: 1997<br />lifeExp: 76.11000<br />country: Denmark\",\"year: 2002<br />lifeExp: 77.18000<br />country: Denmark\",\"year: 2007<br />lifeExp: 78.33200<br />country: Denmark\",null,\"year: 1952<br />lifeExp: 34.81200<br />country: Djibouti\",\"year: 1957<br />lifeExp: 37.32800<br />country: Djibouti\",\"year: 1962<br />lifeExp: 39.69300<br />country: Djibouti\",\"year: 1967<br />lifeExp: 42.07400<br />country: Djibouti\",\"year: 1972<br />lifeExp: 44.36600<br />country: Djibouti\",\"year: 1977<br />lifeExp: 46.51900<br />country: Djibouti\",\"year: 1982<br />lifeExp: 48.81200<br />country: Djibouti\",\"year: 1987<br />lifeExp: 50.04000<br />country: Djibouti\",\"year: 1992<br />lifeExp: 51.60400<br />country: Djibouti\",\"year: 1997<br />lifeExp: 53.15700<br />country: Djibouti\",\"year: 2002<br />lifeExp: 53.37300<br />country: Djibouti\",\"year: 2007<br />lifeExp: 54.79100<br />country: Djibouti\",null,\"year: 1952<br />lifeExp: 45.92800<br />country: Dominican Republic\",\"year: 1957<br />lifeExp: 49.82800<br />country: Dominican Republic\",\"year: 1962<br />lifeExp: 53.45900<br />country: Dominican Republic\",\"year: 1967<br />lifeExp: 56.75100<br />country: Dominican Republic\",\"year: 1972<br />lifeExp: 59.63100<br />country: Dominican Republic\",\"year: 1977<br />lifeExp: 61.78800<br />country: Dominican Republic\",\"year: 1982<br />lifeExp: 63.72700<br />country: Dominican Republic\",\"year: 1987<br />lifeExp: 66.04600<br />country: Dominican Republic\",\"year: 1992<br />lifeExp: 68.45700<br />country: Dominican Republic\",\"year: 1997<br />lifeExp: 69.95700<br />country: Dominican Republic\",\"year: 2002<br />lifeExp: 70.84700<br />country: Dominican Republic\",\"year: 2007<br />lifeExp: 72.23500<br />country: Dominican Republic\",null,\"year: 1952<br />lifeExp: 48.35700<br />country: Ecuador\",\"year: 1957<br />lifeExp: 51.35600<br />country: Ecuador\",\"year: 1962<br />lifeExp: 54.64000<br />country: Ecuador\",\"year: 1967<br />lifeExp: 56.67800<br />country: Ecuador\",\"year: 1972<br />lifeExp: 58.79600<br />country: Ecuador\",\"year: 1977<br />lifeExp: 61.31000<br />country: Ecuador\",\"year: 1982<br />lifeExp: 64.34200<br />country: Ecuador\",\"year: 1987<br />lifeExp: 67.23100<br />country: Ecuador\",\"year: 1992<br />lifeExp: 69.61300<br />country: Ecuador\",\"year: 1997<br />lifeExp: 72.31200<br />country: Ecuador\",\"year: 2002<br />lifeExp: 74.17300<br />country: Ecuador\",\"year: 2007<br />lifeExp: 74.99400<br />country: Ecuador\",null,\"year: 1952<br />lifeExp: 41.89300<br />country: Egypt\",\"year: 1957<br />lifeExp: 44.44400<br />country: Egypt\",\"year: 1962<br />lifeExp: 46.99200<br />country: Egypt\",\"year: 1967<br />lifeExp: 49.29300<br />country: Egypt\",\"year: 1972<br />lifeExp: 51.13700<br />country: Egypt\",\"year: 1977<br />lifeExp: 53.31900<br />country: Egypt\",\"year: 1982<br />lifeExp: 56.00600<br />country: Egypt\",\"year: 1987<br />lifeExp: 59.79700<br />country: Egypt\",\"year: 1992<br />lifeExp: 63.67400<br />country: Egypt\",\"year: 1997<br />lifeExp: 67.21700<br />country: Egypt\",\"year: 2002<br />lifeExp: 69.80600<br />country: Egypt\",\"year: 2007<br />lifeExp: 71.33800<br />country: Egypt\",null,\"year: 1952<br />lifeExp: 45.26200<br />country: El Salvador\",\"year: 1957<br />lifeExp: 48.57000<br />country: El Salvador\",\"year: 1962<br />lifeExp: 52.30700<br />country: El Salvador\",\"year: 1967<br />lifeExp: 55.85500<br />country: El Salvador\",\"year: 1972<br />lifeExp: 58.20700<br />country: El Salvador\",\"year: 1977<br />lifeExp: 56.69600<br />country: El Salvador\",\"year: 1982<br />lifeExp: 56.60400<br />country: El Salvador\",\"year: 1987<br />lifeExp: 63.15400<br />country: El Salvador\",\"year: 1992<br />lifeExp: 66.79800<br />country: El Salvador\",\"year: 1997<br />lifeExp: 69.53500<br />country: El Salvador\",\"year: 2002<br />lifeExp: 70.73400<br />country: El Salvador\",\"year: 2007<br />lifeExp: 71.87800<br />country: El Salvador\",null,\"year: 1952<br />lifeExp: 34.48200<br />country: Equatorial Guinea\",\"year: 1957<br />lifeExp: 35.98300<br />country: Equatorial Guinea\",\"year: 1962<br />lifeExp: 37.48500<br />country: Equatorial Guinea\",\"year: 1967<br />lifeExp: 38.98700<br />country: Equatorial Guinea\",\"year: 1972<br />lifeExp: 40.51600<br />country: Equatorial Guinea\",\"year: 1977<br />lifeExp: 42.02400<br />country: Equatorial Guinea\",\"year: 1982<br />lifeExp: 43.66200<br />country: Equatorial Guinea\",\"year: 1987<br />lifeExp: 45.66400<br />country: Equatorial Guinea\",\"year: 1992<br />lifeExp: 47.54500<br />country: Equatorial Guinea\",\"year: 1997<br />lifeExp: 48.24500<br />country: Equatorial Guinea\",\"year: 2002<br />lifeExp: 49.34800<br />country: Equatorial Guinea\",\"year: 2007<br />lifeExp: 51.57900<br />country: Equatorial Guinea\",null,\"year: 1952<br />lifeExp: 35.92800<br />country: Eritrea\",\"year: 1957<br />lifeExp: 38.04700<br />country: Eritrea\",\"year: 1962<br />lifeExp: 40.15800<br />country: Eritrea\",\"year: 1967<br />lifeExp: 42.18900<br />country: Eritrea\",\"year: 1972<br />lifeExp: 44.14200<br />country: Eritrea\",\"year: 1977<br />lifeExp: 44.53500<br />country: Eritrea\",\"year: 1982<br />lifeExp: 43.89000<br />country: Eritrea\",\"year: 1987<br />lifeExp: 46.45300<br />country: Eritrea\",\"year: 1992<br />lifeExp: 49.99100<br />country: Eritrea\",\"year: 1997<br />lifeExp: 53.37800<br />country: Eritrea\",\"year: 2002<br />lifeExp: 55.24000<br />country: Eritrea\",\"year: 2007<br />lifeExp: 58.04000<br />country: Eritrea\",null,\"year: 1952<br />lifeExp: 34.07800<br />country: Ethiopia\",\"year: 1957<br />lifeExp: 36.66700<br />country: Ethiopia\",\"year: 1962<br />lifeExp: 40.05900<br />country: Ethiopia\",\"year: 1967<br />lifeExp: 42.11500<br />country: Ethiopia\",\"year: 1972<br />lifeExp: 43.51500<br />country: Ethiopia\",\"year: 1977<br />lifeExp: 44.51000<br />country: Ethiopia\",\"year: 1982<br />lifeExp: 44.91600<br />country: Ethiopia\",\"year: 1987<br />lifeExp: 46.68400<br />country: Ethiopia\",\"year: 1992<br />lifeExp: 48.09100<br />country: Ethiopia\",\"year: 1997<br />lifeExp: 49.40200<br />country: Ethiopia\",\"year: 2002<br />lifeExp: 50.72500<br />country: Ethiopia\",\"year: 2007<br />lifeExp: 52.94700<br />country: Ethiopia\",null,\"year: 1952<br />lifeExp: 66.55000<br />country: Finland\",\"year: 1957<br />lifeExp: 67.49000<br />country: Finland\",\"year: 1962<br />lifeExp: 68.75000<br />country: Finland\",\"year: 1967<br />lifeExp: 69.83000<br />country: Finland\",\"year: 1972<br />lifeExp: 70.87000<br />country: Finland\",\"year: 1977<br />lifeExp: 72.52000<br />country: Finland\",\"year: 1982<br />lifeExp: 74.55000<br />country: Finland\",\"year: 1987<br />lifeExp: 74.83000<br />country: Finland\",\"year: 1992<br />lifeExp: 75.70000<br />country: Finland\",\"year: 1997<br />lifeExp: 77.13000<br />country: Finland\",\"year: 2002<br />lifeExp: 78.37000<br />country: Finland\",\"year: 2007<br />lifeExp: 79.31300<br />country: Finland\",null,\"year: 1952<br />lifeExp: 67.41000<br />country: France\",\"year: 1957<br />lifeExp: 68.93000<br />country: France\",\"year: 1962<br />lifeExp: 70.51000<br />country: France\",\"year: 1967<br />lifeExp: 71.55000<br />country: France\",\"year: 1972<br />lifeExp: 72.38000<br />country: France\",\"year: 1977<br />lifeExp: 73.83000<br />country: France\",\"year: 1982<br />lifeExp: 74.89000<br />country: France\",\"year: 1987<br />lifeExp: 76.34000<br />country: France\",\"year: 1992<br />lifeExp: 77.46000<br />country: France\",\"year: 1997<br />lifeExp: 78.64000<br />country: France\",\"year: 2002<br />lifeExp: 79.59000<br />country: France\",\"year: 2007<br />lifeExp: 80.65700<br />country: France\",null,\"year: 1952<br />lifeExp: 37.00300<br />country: Gabon\",\"year: 1957<br />lifeExp: 38.99900<br />country: Gabon\",\"year: 1962<br />lifeExp: 40.48900<br />country: Gabon\",\"year: 1967<br />lifeExp: 44.59800<br />country: Gabon\",\"year: 1972<br />lifeExp: 48.69000<br />country: Gabon\",\"year: 1977<br />lifeExp: 52.79000<br />country: Gabon\",\"year: 1982<br />lifeExp: 56.56400<br />country: Gabon\",\"year: 1987<br />lifeExp: 60.19000<br />country: Gabon\",\"year: 1992<br />lifeExp: 61.36600<br />country: Gabon\",\"year: 1997<br />lifeExp: 60.46100<br />country: Gabon\",\"year: 2002<br />lifeExp: 56.76100<br />country: Gabon\",\"year: 2007<br />lifeExp: 56.73500<br />country: Gabon\",null,\"year: 1952<br />lifeExp: 30.00000<br />country: Gambia\",\"year: 1957<br />lifeExp: 32.06500<br />country: Gambia\",\"year: 1962<br />lifeExp: 33.89600<br />country: Gambia\",\"year: 1967<br />lifeExp: 35.85700<br />country: Gambia\",\"year: 1972<br />lifeExp: 38.30800<br />country: Gambia\",\"year: 1977<br />lifeExp: 41.84200<br />country: Gambia\",\"year: 1982<br />lifeExp: 45.58000<br />country: Gambia\",\"year: 1987<br />lifeExp: 49.26500<br />country: Gambia\",\"year: 1992<br />lifeExp: 52.64400<br />country: Gambia\",\"year: 1997<br />lifeExp: 55.86100<br />country: Gambia\",\"year: 2002<br />lifeExp: 58.04100<br />country: Gambia\",\"year: 2007<br />lifeExp: 59.44800<br />country: Gambia\",null,\"year: 1952<br />lifeExp: 67.50000<br />country: Germany\",\"year: 1957<br />lifeExp: 69.10000<br />country: Germany\",\"year: 1962<br />lifeExp: 70.30000<br />country: Germany\",\"year: 1967<br />lifeExp: 70.80000<br />country: Germany\",\"year: 1972<br />lifeExp: 71.00000<br />country: Germany\",\"year: 1977<br />lifeExp: 72.50000<br />country: Germany\",\"year: 1982<br />lifeExp: 73.80000<br />country: Germany\",\"year: 1987<br />lifeExp: 74.84700<br />country: Germany\",\"year: 1992<br />lifeExp: 76.07000<br />country: Germany\",\"year: 1997<br />lifeExp: 77.34000<br />country: Germany\",\"year: 2002<br />lifeExp: 78.67000<br />country: Germany\",\"year: 2007<br />lifeExp: 79.40600<br />country: Germany\",null,\"year: 1952<br />lifeExp: 43.14900<br />country: Ghana\",\"year: 1957<br />lifeExp: 44.77900<br />country: Ghana\",\"year: 1962<br />lifeExp: 46.45200<br />country: Ghana\",\"year: 1967<br />lifeExp: 48.07200<br />country: Ghana\",\"year: 1972<br />lifeExp: 49.87500<br />country: Ghana\",\"year: 1977<br />lifeExp: 51.75600<br />country: Ghana\",\"year: 1982<br />lifeExp: 53.74400<br />country: Ghana\",\"year: 1987<br />lifeExp: 55.72900<br />country: Ghana\",\"year: 1992<br />lifeExp: 57.50100<br />country: Ghana\",\"year: 1997<br />lifeExp: 58.55600<br />country: Ghana\",\"year: 2002<br />lifeExp: 58.45300<br />country: Ghana\",\"year: 2007<br />lifeExp: 60.02200<br />country: Ghana\",null,\"year: 1952<br />lifeExp: 65.86000<br />country: Greece\",\"year: 1957<br />lifeExp: 67.86000<br />country: Greece\",\"year: 1962<br />lifeExp: 69.51000<br />country: Greece\",\"year: 1967<br />lifeExp: 71.00000<br />country: Greece\",\"year: 1972<br />lifeExp: 72.34000<br />country: Greece\",\"year: 1977<br />lifeExp: 73.68000<br />country: Greece\",\"year: 1982<br />lifeExp: 75.24000<br />country: Greece\",\"year: 1987<br />lifeExp: 76.67000<br />country: Greece\",\"year: 1992<br />lifeExp: 77.03000<br />country: Greece\",\"year: 1997<br />lifeExp: 77.86900<br />country: Greece\",\"year: 2002<br />lifeExp: 78.25600<br />country: Greece\",\"year: 2007<br />lifeExp: 79.48300<br />country: Greece\",null,\"year: 1952<br />lifeExp: 42.02300<br />country: Guatemala\",\"year: 1957<br />lifeExp: 44.14200<br />country: Guatemala\",\"year: 1962<br />lifeExp: 46.95400<br />country: Guatemala\",\"year: 1967<br />lifeExp: 50.01600<br />country: Guatemala\",\"year: 1972<br />lifeExp: 53.73800<br />country: Guatemala\",\"year: 1977<br />lifeExp: 56.02900<br />country: Guatemala\",\"year: 1982<br />lifeExp: 58.13700<br />country: Guatemala\",\"year: 1987<br />lifeExp: 60.78200<br />country: Guatemala\",\"year: 1992<br />lifeExp: 63.37300<br />country: Guatemala\",\"year: 1997<br />lifeExp: 66.32200<br />country: Guatemala\",\"year: 2002<br />lifeExp: 68.97800<br />country: Guatemala\",\"year: 2007<br />lifeExp: 70.25900<br />country: Guatemala\",null,\"year: 1952<br />lifeExp: 33.60900<br />country: Guinea\",\"year: 1957<br />lifeExp: 34.55800<br />country: Guinea\",\"year: 1962<br />lifeExp: 35.75300<br />country: Guinea\",\"year: 1967<br />lifeExp: 37.19700<br />country: Guinea\",\"year: 1972<br />lifeExp: 38.84200<br />country: Guinea\",\"year: 1977<br />lifeExp: 40.76200<br />country: Guinea\",\"year: 1982<br />lifeExp: 42.89100<br />country: Guinea\",\"year: 1987<br />lifeExp: 45.55200<br />country: Guinea\",\"year: 1992<br />lifeExp: 48.57600<br />country: Guinea\",\"year: 1997<br />lifeExp: 51.45500<br />country: Guinea\",\"year: 2002<br />lifeExp: 53.67600<br />country: Guinea\",\"year: 2007<br />lifeExp: 56.00700<br />country: Guinea\",null,\"year: 1952<br />lifeExp: 32.50000<br />country: Guinea-Bissau\",\"year: 1957<br />lifeExp: 33.48900<br />country: Guinea-Bissau\",\"year: 1962<br />lifeExp: 34.48800<br />country: Guinea-Bissau\",\"year: 1967<br />lifeExp: 35.49200<br />country: Guinea-Bissau\",\"year: 1972<br />lifeExp: 36.48600<br />country: Guinea-Bissau\",\"year: 1977<br />lifeExp: 37.46500<br />country: Guinea-Bissau\",\"year: 1982<br />lifeExp: 39.32700<br />country: Guinea-Bissau\",\"year: 1987<br />lifeExp: 41.24500<br />country: Guinea-Bissau\",\"year: 1992<br />lifeExp: 43.26600<br />country: Guinea-Bissau\",\"year: 1997<br />lifeExp: 44.87300<br />country: Guinea-Bissau\",\"year: 2002<br />lifeExp: 45.50400<br />country: Guinea-Bissau\",\"year: 2007<br />lifeExp: 46.38800<br />country: Guinea-Bissau\",null,\"year: 1952<br />lifeExp: 37.57900<br />country: Haiti\",\"year: 1957<br />lifeExp: 40.69600<br />country: Haiti\",\"year: 1962<br />lifeExp: 43.59000<br />country: Haiti\",\"year: 1967<br />lifeExp: 46.24300<br />country: Haiti\",\"year: 1972<br />lifeExp: 48.04200<br />country: Haiti\",\"year: 1977<br />lifeExp: 49.92300<br />country: Haiti\",\"year: 1982<br />lifeExp: 51.46100<br />country: Haiti\",\"year: 1987<br />lifeExp: 53.63600<br />country: Haiti\",\"year: 1992<br />lifeExp: 55.08900<br />country: Haiti\",\"year: 1997<br />lifeExp: 56.67100<br />country: Haiti\",\"year: 2002<br />lifeExp: 58.13700<br />country: Haiti\",\"year: 2007<br />lifeExp: 60.91600<br />country: Haiti\",null,\"year: 1952<br />lifeExp: 41.91200<br />country: Honduras\",\"year: 1957<br />lifeExp: 44.66500<br />country: Honduras\",\"year: 1962<br />lifeExp: 48.04100<br />country: Honduras\",\"year: 1967<br />lifeExp: 50.92400<br />country: Honduras\",\"year: 1972<br />lifeExp: 53.88400<br />country: Honduras\",\"year: 1977<br />lifeExp: 57.40200<br />country: Honduras\",\"year: 1982<br />lifeExp: 60.90900<br />country: Honduras\",\"year: 1987<br />lifeExp: 64.49200<br />country: Honduras\",\"year: 1992<br />lifeExp: 66.39900<br />country: Honduras\",\"year: 1997<br />lifeExp: 67.65900<br />country: Honduras\",\"year: 2002<br />lifeExp: 68.56500<br />country: Honduras\",\"year: 2007<br />lifeExp: 70.19800<br />country: Honduras\",null,\"year: 1952<br />lifeExp: 60.96000<br />country: Hong Kong, China\",\"year: 1957<br />lifeExp: 64.75000<br />country: Hong Kong, China\",\"year: 1962<br />lifeExp: 67.65000<br />country: Hong Kong, China\",\"year: 1967<br />lifeExp: 70.00000<br />country: Hong Kong, China\",\"year: 1972<br />lifeExp: 72.00000<br />country: Hong Kong, China\",\"year: 1977<br />lifeExp: 73.60000<br />country: Hong Kong, China\",\"year: 1982<br />lifeExp: 75.45000<br />country: Hong Kong, China\",\"year: 1987<br />lifeExp: 76.20000<br />country: Hong Kong, China\",\"year: 1992<br />lifeExp: 77.60100<br />country: Hong Kong, China\",\"year: 1997<br />lifeExp: 80.00000<br />country: Hong Kong, China\",\"year: 2002<br />lifeExp: 81.49500<br />country: Hong Kong, China\",\"year: 2007<br />lifeExp: 82.20800<br />country: Hong Kong, China\",null,\"year: 1952<br />lifeExp: 64.03000<br />country: Hungary\",\"year: 1957<br />lifeExp: 66.41000<br />country: Hungary\",\"year: 1962<br />lifeExp: 67.96000<br />country: Hungary\",\"year: 1967<br />lifeExp: 69.50000<br />country: Hungary\",\"year: 1972<br />lifeExp: 69.76000<br />country: Hungary\",\"year: 1977<br />lifeExp: 69.95000<br />country: Hungary\",\"year: 1982<br />lifeExp: 69.39000<br />country: Hungary\",\"year: 1987<br />lifeExp: 69.58000<br />country: Hungary\",\"year: 1992<br />lifeExp: 69.17000<br />country: Hungary\",\"year: 1997<br />lifeExp: 71.04000<br />country: Hungary\",\"year: 2002<br />lifeExp: 72.59000<br />country: Hungary\",\"year: 2007<br />lifeExp: 73.33800<br />country: Hungary\",null,\"year: 1952<br />lifeExp: 72.49000<br />country: Iceland\",\"year: 1957<br />lifeExp: 73.47000<br />country: Iceland\",\"year: 1962<br />lifeExp: 73.68000<br />country: Iceland\",\"year: 1967<br />lifeExp: 73.73000<br />country: Iceland\",\"year: 1972<br />lifeExp: 74.46000<br />country: Iceland\",\"year: 1977<br />lifeExp: 76.11000<br />country: Iceland\",\"year: 1982<br />lifeExp: 76.99000<br />country: Iceland\",\"year: 1987<br />lifeExp: 77.23000<br />country: Iceland\",\"year: 1992<br />lifeExp: 78.77000<br />country: Iceland\",\"year: 1997<br />lifeExp: 78.95000<br />country: Iceland\",\"year: 2002<br />lifeExp: 80.50000<br />country: Iceland\",\"year: 2007<br />lifeExp: 81.75700<br />country: Iceland\",null,\"year: 1952<br />lifeExp: 37.37300<br />country: India\",\"year: 1957<br />lifeExp: 40.24900<br />country: India\",\"year: 1962<br />lifeExp: 43.60500<br />country: India\",\"year: 1967<br />lifeExp: 47.19300<br />country: India\",\"year: 1972<br />lifeExp: 50.65100<br />country: India\",\"year: 1977<br />lifeExp: 54.20800<br />country: India\",\"year: 1982<br />lifeExp: 56.59600<br />country: India\",\"year: 1987<br />lifeExp: 58.55300<br />country: India\",\"year: 1992<br />lifeExp: 60.22300<br />country: India\",\"year: 1997<br />lifeExp: 61.76500<br />country: India\",\"year: 2002<br />lifeExp: 62.87900<br />country: India\",\"year: 2007<br />lifeExp: 64.69800<br />country: India\",null,\"year: 1952<br />lifeExp: 37.46800<br />country: Indonesia\",\"year: 1957<br />lifeExp: 39.91800<br />country: Indonesia\",\"year: 1962<br />lifeExp: 42.51800<br />country: Indonesia\",\"year: 1967<br />lifeExp: 45.96400<br />country: Indonesia\",\"year: 1972<br />lifeExp: 49.20300<br />country: Indonesia\",\"year: 1977<br />lifeExp: 52.70200<br />country: Indonesia\",\"year: 1982<br />lifeExp: 56.15900<br />country: Indonesia\",\"year: 1987<br />lifeExp: 60.13700<br />country: Indonesia\",\"year: 1992<br />lifeExp: 62.68100<br />country: Indonesia\",\"year: 1997<br />lifeExp: 66.04100<br />country: Indonesia\",\"year: 2002<br />lifeExp: 68.58800<br />country: Indonesia\",\"year: 2007<br />lifeExp: 70.65000<br />country: Indonesia\",null,\"year: 1952<br />lifeExp: 44.86900<br />country: Iran\",\"year: 1957<br />lifeExp: 47.18100<br />country: Iran\",\"year: 1962<br />lifeExp: 49.32500<br />country: Iran\",\"year: 1967<br />lifeExp: 52.46900<br />country: Iran\",\"year: 1972<br />lifeExp: 55.23400<br />country: Iran\",\"year: 1977<br />lifeExp: 57.70200<br />country: Iran\",\"year: 1982<br />lifeExp: 59.62000<br />country: Iran\",\"year: 1987<br />lifeExp: 63.04000<br />country: Iran\",\"year: 1992<br />lifeExp: 65.74200<br />country: Iran\",\"year: 1997<br />lifeExp: 68.04200<br />country: Iran\",\"year: 2002<br />lifeExp: 69.45100<br />country: Iran\",\"year: 2007<br />lifeExp: 70.96400<br />country: Iran\",null,\"year: 1952<br />lifeExp: 45.32000<br />country: Iraq\",\"year: 1957<br />lifeExp: 48.43700<br />country: Iraq\",\"year: 1962<br />lifeExp: 51.45700<br />country: Iraq\",\"year: 1967<br />lifeExp: 54.45900<br />country: Iraq\",\"year: 1972<br />lifeExp: 56.95000<br />country: Iraq\",\"year: 1977<br />lifeExp: 60.41300<br />country: Iraq\",\"year: 1982<br />lifeExp: 62.03800<br />country: Iraq\",\"year: 1987<br />lifeExp: 65.04400<br />country: Iraq\",\"year: 1992<br />lifeExp: 59.46100<br />country: Iraq\",\"year: 1997<br />lifeExp: 58.81100<br />country: Iraq\",\"year: 2002<br />lifeExp: 57.04600<br />country: Iraq\",\"year: 2007<br />lifeExp: 59.54500<br />country: Iraq\",null,\"year: 1952<br />lifeExp: 66.91000<br />country: Ireland\",\"year: 1957<br />lifeExp: 68.90000<br />country: Ireland\",\"year: 1962<br />lifeExp: 70.29000<br />country: Ireland\",\"year: 1967<br />lifeExp: 71.08000<br />country: Ireland\",\"year: 1972<br />lifeExp: 71.28000<br />country: Ireland\",\"year: 1977<br />lifeExp: 72.03000<br />country: Ireland\",\"year: 1982<br />lifeExp: 73.10000<br />country: Ireland\",\"year: 1987<br />lifeExp: 74.36000<br />country: Ireland\",\"year: 1992<br />lifeExp: 75.46700<br />country: Ireland\",\"year: 1997<br />lifeExp: 76.12200<br />country: Ireland\",\"year: 2002<br />lifeExp: 77.78300<br />country: Ireland\",\"year: 2007<br />lifeExp: 78.88500<br />country: Ireland\",null,\"year: 1952<br />lifeExp: 65.39000<br />country: Israel\",\"year: 1957<br />lifeExp: 67.84000<br />country: Israel\",\"year: 1962<br />lifeExp: 69.39000<br />country: Israel\",\"year: 1967<br />lifeExp: 70.75000<br />country: Israel\",\"year: 1972<br />lifeExp: 71.63000<br />country: Israel\",\"year: 1977<br />lifeExp: 73.06000<br />country: Israel\",\"year: 1982<br />lifeExp: 74.45000<br />country: Israel\",\"year: 1987<br />lifeExp: 75.60000<br />country: Israel\",\"year: 1992<br />lifeExp: 76.93000<br />country: Israel\",\"year: 1997<br />lifeExp: 78.26900<br />country: Israel\",\"year: 2002<br />lifeExp: 79.69600<br />country: Israel\",\"year: 2007<br />lifeExp: 80.74500<br />country: Israel\",null,\"year: 1952<br />lifeExp: 65.94000<br />country: Italy\",\"year: 1957<br />lifeExp: 67.81000<br />country: Italy\",\"year: 1962<br />lifeExp: 69.24000<br />country: Italy\",\"year: 1967<br />lifeExp: 71.06000<br />country: Italy\",\"year: 1972<br />lifeExp: 72.19000<br />country: Italy\",\"year: 1977<br />lifeExp: 73.48000<br />country: Italy\",\"year: 1982<br />lifeExp: 74.98000<br />country: Italy\",\"year: 1987<br />lifeExp: 76.42000<br />country: Italy\",\"year: 1992<br />lifeExp: 77.44000<br />country: Italy\",\"year: 1997<br />lifeExp: 78.82000<br />country: Italy\",\"year: 2002<br />lifeExp: 80.24000<br />country: Italy\",\"year: 2007<br />lifeExp: 80.54600<br />country: Italy\",null,\"year: 1952<br />lifeExp: 58.53000<br />country: Jamaica\",\"year: 1957<br />lifeExp: 62.61000<br />country: Jamaica\",\"year: 1962<br />lifeExp: 65.61000<br />country: Jamaica\",\"year: 1967<br />lifeExp: 67.51000<br />country: Jamaica\",\"year: 1972<br />lifeExp: 69.00000<br />country: Jamaica\",\"year: 1977<br />lifeExp: 70.11000<br />country: Jamaica\",\"year: 1982<br />lifeExp: 71.21000<br />country: Jamaica\",\"year: 1987<br />lifeExp: 71.77000<br />country: Jamaica\",\"year: 1992<br />lifeExp: 71.76600<br />country: Jamaica\",\"year: 1997<br />lifeExp: 72.26200<br />country: Jamaica\",\"year: 2002<br />lifeExp: 72.04700<br />country: Jamaica\",\"year: 2007<br />lifeExp: 72.56700<br />country: Jamaica\",null,\"year: 1952<br />lifeExp: 63.03000<br />country: Japan\",\"year: 1957<br />lifeExp: 65.50000<br />country: Japan\",\"year: 1962<br />lifeExp: 68.73000<br />country: Japan\",\"year: 1967<br />lifeExp: 71.43000<br />country: Japan\",\"year: 1972<br />lifeExp: 73.42000<br />country: Japan\",\"year: 1977<br />lifeExp: 75.38000<br />country: Japan\",\"year: 1982<br />lifeExp: 77.11000<br />country: Japan\",\"year: 1987<br />lifeExp: 78.67000<br />country: Japan\",\"year: 1992<br />lifeExp: 79.36000<br />country: Japan\",\"year: 1997<br />lifeExp: 80.69000<br />country: Japan\",\"year: 2002<br />lifeExp: 82.00000<br />country: Japan\",\"year: 2007<br />lifeExp: 82.60300<br />country: Japan\",null,\"year: 1952<br />lifeExp: 43.15800<br />country: Jordan\",\"year: 1957<br />lifeExp: 45.66900<br />country: Jordan\",\"year: 1962<br />lifeExp: 48.12600<br />country: Jordan\",\"year: 1967<br />lifeExp: 51.62900<br />country: Jordan\",\"year: 1972<br />lifeExp: 56.52800<br />country: Jordan\",\"year: 1977<br />lifeExp: 61.13400<br />country: Jordan\",\"year: 1982<br />lifeExp: 63.73900<br />country: Jordan\",\"year: 1987<br />lifeExp: 65.86900<br />country: Jordan\",\"year: 1992<br />lifeExp: 68.01500<br />country: Jordan\",\"year: 1997<br />lifeExp: 69.77200<br />country: Jordan\",\"year: 2002<br />lifeExp: 71.26300<br />country: Jordan\",\"year: 2007<br />lifeExp: 72.53500<br />country: Jordan\",null,\"year: 1952<br />lifeExp: 42.27000<br />country: Kenya\",\"year: 1957<br />lifeExp: 44.68600<br />country: Kenya\",\"year: 1962<br />lifeExp: 47.94900<br />country: Kenya\",\"year: 1967<br />lifeExp: 50.65400<br />country: Kenya\",\"year: 1972<br />lifeExp: 53.55900<br />country: Kenya\",\"year: 1977<br />lifeExp: 56.15500<br />country: Kenya\",\"year: 1982<br />lifeExp: 58.76600<br />country: Kenya\",\"year: 1987<br />lifeExp: 59.33900<br />country: Kenya\",\"year: 1992<br />lifeExp: 59.28500<br />country: Kenya\",\"year: 1997<br />lifeExp: 54.40700<br />country: Kenya\",\"year: 2002<br />lifeExp: 50.99200<br />country: Kenya\",\"year: 2007<br />lifeExp: 54.11000<br />country: Kenya\",null,\"year: 1952<br />lifeExp: 50.05600<br />country: Korea, Dem. Rep.\",\"year: 1957<br />lifeExp: 54.08100<br />country: Korea, Dem. Rep.\",\"year: 1962<br />lifeExp: 56.65600<br />country: Korea, Dem. Rep.\",\"year: 1967<br />lifeExp: 59.94200<br />country: Korea, Dem. Rep.\",\"year: 1972<br />lifeExp: 63.98300<br />country: Korea, Dem. Rep.\",\"year: 1977<br />lifeExp: 67.15900<br />country: Korea, Dem. Rep.\",\"year: 1982<br />lifeExp: 69.10000<br />country: Korea, Dem. Rep.\",\"year: 1987<br />lifeExp: 70.64700<br />country: Korea, Dem. Rep.\",\"year: 1992<br />lifeExp: 69.97800<br />country: Korea, Dem. Rep.\",\"year: 1997<br />lifeExp: 67.72700<br />country: Korea, Dem. Rep.\",\"year: 2002<br />lifeExp: 66.66200<br />country: Korea, Dem. Rep.\",\"year: 2007<br />lifeExp: 67.29700<br />country: Korea, Dem. Rep.\",null,\"year: 1952<br />lifeExp: 47.45300<br />country: Korea, Rep.\",\"year: 1957<br />lifeExp: 52.68100<br />country: Korea, Rep.\",\"year: 1962<br />lifeExp: 55.29200<br />country: Korea, Rep.\",\"year: 1967<br />lifeExp: 57.71600<br />country: Korea, Rep.\",\"year: 1972<br />lifeExp: 62.61200<br />country: Korea, Rep.\",\"year: 1977<br />lifeExp: 64.76600<br />country: Korea, Rep.\",\"year: 1982<br />lifeExp: 67.12300<br />country: Korea, Rep.\",\"year: 1987<br />lifeExp: 69.81000<br />country: Korea, Rep.\",\"year: 1992<br />lifeExp: 72.24400<br />country: Korea, Rep.\",\"year: 1997<br />lifeExp: 74.64700<br />country: Korea, Rep.\",\"year: 2002<br />lifeExp: 77.04500<br />country: Korea, Rep.\",\"year: 2007<br />lifeExp: 78.62300<br />country: Korea, Rep.\",null,\"year: 1952<br />lifeExp: 55.56500<br />country: Kuwait\",\"year: 1957<br />lifeExp: 58.03300<br />country: Kuwait\",\"year: 1962<br />lifeExp: 60.47000<br />country: Kuwait\",\"year: 1967<br />lifeExp: 64.62400<br />country: Kuwait\",\"year: 1972<br />lifeExp: 67.71200<br />country: Kuwait\",\"year: 1977<br />lifeExp: 69.34300<br />country: Kuwait\",\"year: 1982<br />lifeExp: 71.30900<br />country: Kuwait\",\"year: 1987<br />lifeExp: 74.17400<br />country: Kuwait\",\"year: 1992<br />lifeExp: 75.19000<br />country: Kuwait\",\"year: 1997<br />lifeExp: 76.15600<br />country: Kuwait\",\"year: 2002<br />lifeExp: 76.90400<br />country: Kuwait\",\"year: 2007<br />lifeExp: 77.58800<br />country: Kuwait\",null,\"year: 1952<br />lifeExp: 55.92800<br />country: Lebanon\",\"year: 1957<br />lifeExp: 59.48900<br />country: Lebanon\",\"year: 1962<br />lifeExp: 62.09400<br />country: Lebanon\",\"year: 1967<br />lifeExp: 63.87000<br />country: Lebanon\",\"year: 1972<br />lifeExp: 65.42100<br />country: Lebanon\",\"year: 1977<br />lifeExp: 66.09900<br />country: Lebanon\",\"year: 1982<br />lifeExp: 66.98300<br />country: Lebanon\",\"year: 1987<br />lifeExp: 67.92600<br />country: Lebanon\",\"year: 1992<br />lifeExp: 69.29200<br />country: Lebanon\",\"year: 1997<br />lifeExp: 70.26500<br />country: Lebanon\",\"year: 2002<br />lifeExp: 71.02800<br />country: Lebanon\",\"year: 2007<br />lifeExp: 71.99300<br />country: Lebanon\",null,\"year: 1952<br />lifeExp: 42.13800<br />country: Lesotho\",\"year: 1957<br />lifeExp: 45.04700<br />country: Lesotho\",\"year: 1962<br />lifeExp: 47.74700<br />country: Lesotho\",\"year: 1967<br />lifeExp: 48.49200<br />country: Lesotho\",\"year: 1972<br />lifeExp: 49.76700<br />country: Lesotho\",\"year: 1977<br />lifeExp: 52.20800<br />country: Lesotho\",\"year: 1982<br />lifeExp: 55.07800<br />country: Lesotho\",\"year: 1987<br />lifeExp: 57.18000<br />country: Lesotho\",\"year: 1992<br />lifeExp: 59.68500<br />country: Lesotho\",\"year: 1997<br />lifeExp: 55.55800<br />country: Lesotho\",\"year: 2002<br />lifeExp: 44.59300<br />country: Lesotho\",\"year: 2007<br />lifeExp: 42.59200<br />country: Lesotho\",null,\"year: 1952<br />lifeExp: 38.48000<br />country: Liberia\",\"year: 1957<br />lifeExp: 39.48600<br />country: Liberia\",\"year: 1962<br />lifeExp: 40.50200<br />country: Liberia\",\"year: 1967<br />lifeExp: 41.53600<br />country: Liberia\",\"year: 1972<br />lifeExp: 42.61400<br />country: Liberia\",\"year: 1977<br />lifeExp: 43.76400<br />country: Liberia\",\"year: 1982<br />lifeExp: 44.85200<br />country: Liberia\",\"year: 1987<br />lifeExp: 46.02700<br />country: Liberia\",\"year: 1992<br />lifeExp: 40.80200<br />country: Liberia\",\"year: 1997<br />lifeExp: 42.22100<br />country: Liberia\",\"year: 2002<br />lifeExp: 43.75300<br />country: Liberia\",\"year: 2007<br />lifeExp: 45.67800<br />country: Liberia\",null,\"year: 1952<br />lifeExp: 42.72300<br />country: Libya\",\"year: 1957<br />lifeExp: 45.28900<br />country: Libya\",\"year: 1962<br />lifeExp: 47.80800<br />country: Libya\",\"year: 1967<br />lifeExp: 50.22700<br />country: Libya\",\"year: 1972<br />lifeExp: 52.77300<br />country: Libya\",\"year: 1977<br />lifeExp: 57.44200<br />country: Libya\",\"year: 1982<br />lifeExp: 62.15500<br />country: Libya\",\"year: 1987<br />lifeExp: 66.23400<br />country: Libya\",\"year: 1992<br />lifeExp: 68.75500<br />country: Libya\",\"year: 1997<br />lifeExp: 71.55500<br />country: Libya\",\"year: 2002<br />lifeExp: 72.73700<br />country: Libya\",\"year: 2007<br />lifeExp: 73.95200<br />country: Libya\",null,\"year: 1952<br />lifeExp: 36.68100<br />country: Madagascar\",\"year: 1957<br />lifeExp: 38.86500<br />country: Madagascar\",\"year: 1962<br />lifeExp: 40.84800<br />country: Madagascar\",\"year: 1967<br />lifeExp: 42.88100<br />country: Madagascar\",\"year: 1972<br />lifeExp: 44.85100<br />country: Madagascar\",\"year: 1977<br />lifeExp: 46.88100<br />country: Madagascar\",\"year: 1982<br />lifeExp: 48.96900<br />country: Madagascar\",\"year: 1987<br />lifeExp: 49.35000<br />country: Madagascar\",\"year: 1992<br />lifeExp: 52.21400<br />country: Madagascar\",\"year: 1997<br />lifeExp: 54.97800<br />country: Madagascar\",\"year: 2002<br />lifeExp: 57.28600<br />country: Madagascar\",\"year: 2007<br />lifeExp: 59.44300<br />country: Madagascar\",null,\"year: 1952<br />lifeExp: 36.25600<br />country: Malawi\",\"year: 1957<br />lifeExp: 37.20700<br />country: Malawi\",\"year: 1962<br />lifeExp: 38.41000<br />country: Malawi\",\"year: 1967<br />lifeExp: 39.48700<br />country: Malawi\",\"year: 1972<br />lifeExp: 41.76600<br />country: Malawi\",\"year: 1977<br />lifeExp: 43.76700<br />country: Malawi\",\"year: 1982<br />lifeExp: 45.64200<br />country: Malawi\",\"year: 1987<br />lifeExp: 47.45700<br />country: Malawi\",\"year: 1992<br />lifeExp: 49.42000<br />country: Malawi\",\"year: 1997<br />lifeExp: 47.49500<br />country: Malawi\",\"year: 2002<br />lifeExp: 45.00900<br />country: Malawi\",\"year: 2007<br />lifeExp: 48.30300<br />country: Malawi\",null,\"year: 1952<br />lifeExp: 48.46300<br />country: Malaysia\",\"year: 1957<br />lifeExp: 52.10200<br />country: Malaysia\",\"year: 1962<br />lifeExp: 55.73700<br />country: Malaysia\",\"year: 1967<br />lifeExp: 59.37100<br />country: Malaysia\",\"year: 1972<br />lifeExp: 63.01000<br />country: Malaysia\",\"year: 1977<br />lifeExp: 65.25600<br />country: Malaysia\",\"year: 1982<br />lifeExp: 68.00000<br />country: Malaysia\",\"year: 1987<br />lifeExp: 69.50000<br />country: Malaysia\",\"year: 1992<br />lifeExp: 70.69300<br />country: Malaysia\",\"year: 1997<br />lifeExp: 71.93800<br />country: Malaysia\",\"year: 2002<br />lifeExp: 73.04400<br />country: Malaysia\",\"year: 2007<br />lifeExp: 74.24100<br />country: Malaysia\",null,\"year: 1952<br />lifeExp: 33.68500<br />country: Mali\",\"year: 1957<br />lifeExp: 35.30700<br />country: Mali\",\"year: 1962<br />lifeExp: 36.93600<br />country: Mali\",\"year: 1967<br />lifeExp: 38.48700<br />country: Mali\",\"year: 1972<br />lifeExp: 39.97700<br />country: Mali\",\"year: 1977<br />lifeExp: 41.71400<br />country: Mali\",\"year: 1982<br />lifeExp: 43.91600<br />country: Mali\",\"year: 1987<br />lifeExp: 46.36400<br />country: Mali\",\"year: 1992<br />lifeExp: 48.38800<br />country: Mali\",\"year: 1997<br />lifeExp: 49.90300<br />country: Mali\",\"year: 2002<br />lifeExp: 51.81800<br />country: Mali\",\"year: 2007<br />lifeExp: 54.46700<br />country: Mali\",null,\"year: 1952<br />lifeExp: 40.54300<br />country: Mauritania\",\"year: 1957<br />lifeExp: 42.33800<br />country: Mauritania\",\"year: 1962<br />lifeExp: 44.24800<br />country: Mauritania\",\"year: 1967<br />lifeExp: 46.28900<br />country: Mauritania\",\"year: 1972<br />lifeExp: 48.43700<br />country: Mauritania\",\"year: 1977<br />lifeExp: 50.85200<br />country: Mauritania\",\"year: 1982<br />lifeExp: 53.59900<br />country: Mauritania\",\"year: 1987<br />lifeExp: 56.14500<br />country: Mauritania\",\"year: 1992<br />lifeExp: 58.33300<br />country: Mauritania\",\"year: 1997<br />lifeExp: 60.43000<br />country: Mauritania\",\"year: 2002<br />lifeExp: 62.24700<br />country: Mauritania\",\"year: 2007<br />lifeExp: 64.16400<br />country: Mauritania\",null,\"year: 1952<br />lifeExp: 50.98600<br />country: Mauritius\",\"year: 1957<br />lifeExp: 58.08900<br />country: Mauritius\",\"year: 1962<br />lifeExp: 60.24600<br />country: Mauritius\",\"year: 1967<br />lifeExp: 61.55700<br />country: Mauritius\",\"year: 1972<br />lifeExp: 62.94400<br />country: Mauritius\",\"year: 1977<br />lifeExp: 64.93000<br />country: Mauritius\",\"year: 1982<br />lifeExp: 66.71100<br />country: Mauritius\",\"year: 1987<br />lifeExp: 68.74000<br />country: Mauritius\",\"year: 1992<br />lifeExp: 69.74500<br />country: Mauritius\",\"year: 1997<br />lifeExp: 70.73600<br />country: Mauritius\",\"year: 2002<br />lifeExp: 71.95400<br />country: Mauritius\",\"year: 2007<br />lifeExp: 72.80100<br />country: Mauritius\",null,\"year: 1952<br />lifeExp: 50.78900<br />country: Mexico\",\"year: 1957<br />lifeExp: 55.19000<br />country: Mexico\",\"year: 1962<br />lifeExp: 58.29900<br />country: Mexico\",\"year: 1967<br />lifeExp: 60.11000<br />country: Mexico\",\"year: 1972<br />lifeExp: 62.36100<br />country: Mexico\",\"year: 1977<br />lifeExp: 65.03200<br />country: Mexico\",\"year: 1982<br />lifeExp: 67.40500<br />country: Mexico\",\"year: 1987<br />lifeExp: 69.49800<br />country: Mexico\",\"year: 1992<br />lifeExp: 71.45500<br />country: Mexico\",\"year: 1997<br />lifeExp: 73.67000<br />country: Mexico\",\"year: 2002<br />lifeExp: 74.90200<br />country: Mexico\",\"year: 2007<br />lifeExp: 76.19500<br />country: Mexico\",null,\"year: 1952<br />lifeExp: 42.24400<br />country: Mongolia\",\"year: 1957<br />lifeExp: 45.24800<br />country: Mongolia\",\"year: 1962<br />lifeExp: 48.25100<br />country: Mongolia\",\"year: 1967<br />lifeExp: 51.25300<br />country: Mongolia\",\"year: 1972<br />lifeExp: 53.75400<br />country: Mongolia\",\"year: 1977<br />lifeExp: 55.49100<br />country: Mongolia\",\"year: 1982<br />lifeExp: 57.48900<br />country: Mongolia\",\"year: 1987<br />lifeExp: 60.22200<br />country: Mongolia\",\"year: 1992<br />lifeExp: 61.27100<br />country: Mongolia\",\"year: 1997<br />lifeExp: 63.62500<br />country: Mongolia\",\"year: 2002<br />lifeExp: 65.03300<br />country: Mongolia\",\"year: 2007<br />lifeExp: 66.80300<br />country: Mongolia\",null,\"year: 1952<br />lifeExp: 59.16400<br />country: Montenegro\",\"year: 1957<br />lifeExp: 61.44800<br />country: Montenegro\",\"year: 1962<br />lifeExp: 63.72800<br />country: Montenegro\",\"year: 1967<br />lifeExp: 67.17800<br />country: Montenegro\",\"year: 1972<br />lifeExp: 70.63600<br />country: Montenegro\",\"year: 1977<br />lifeExp: 73.06600<br />country: Montenegro\",\"year: 1982<br />lifeExp: 74.10100<br />country: Montenegro\",\"year: 1987<br />lifeExp: 74.86500<br />country: Montenegro\",\"year: 1992<br />lifeExp: 75.43500<br />country: Montenegro\",\"year: 1997<br />lifeExp: 75.44500<br />country: Montenegro\",\"year: 2002<br />lifeExp: 73.98100<br />country: Montenegro\",\"year: 2007<br />lifeExp: 74.54300<br />country: Montenegro\",null,\"year: 1952<br />lifeExp: 42.87300<br />country: Morocco\",\"year: 1957<br />lifeExp: 45.42300<br />country: Morocco\",\"year: 1962<br />lifeExp: 47.92400<br />country: Morocco\",\"year: 1967<br />lifeExp: 50.33500<br />country: Morocco\",\"year: 1972<br />lifeExp: 52.86200<br />country: Morocco\",\"year: 1977<br />lifeExp: 55.73000<br />country: Morocco\",\"year: 1982<br />lifeExp: 59.65000<br />country: Morocco\",\"year: 1987<br />lifeExp: 62.67700<br />country: Morocco\",\"year: 1992<br />lifeExp: 65.39300<br />country: Morocco\",\"year: 1997<br />lifeExp: 67.66000<br />country: Morocco\",\"year: 2002<br />lifeExp: 69.61500<br />country: Morocco\",\"year: 2007<br />lifeExp: 71.16400<br />country: Morocco\",null,\"year: 1952<br />lifeExp: 31.28600<br />country: Mozambique\",\"year: 1957<br />lifeExp: 33.77900<br />country: Mozambique\",\"year: 1962<br />lifeExp: 36.16100<br />country: Mozambique\",\"year: 1967<br />lifeExp: 38.11300<br />country: Mozambique\",\"year: 1972<br />lifeExp: 40.32800<br />country: Mozambique\",\"year: 1977<br />lifeExp: 42.49500<br />country: Mozambique\",\"year: 1982<br />lifeExp: 42.79500<br />country: Mozambique\",\"year: 1987<br />lifeExp: 42.86100<br />country: Mozambique\",\"year: 1992<br />lifeExp: 44.28400<br />country: Mozambique\",\"year: 1997<br />lifeExp: 46.34400<br />country: Mozambique\",\"year: 2002<br />lifeExp: 44.02600<br />country: Mozambique\",\"year: 2007<br />lifeExp: 42.08200<br />country: Mozambique\",null,\"year: 1952<br />lifeExp: 36.31900<br />country: Myanmar\",\"year: 1957<br />lifeExp: 41.90500<br />country: Myanmar\",\"year: 1962<br />lifeExp: 45.10800<br />country: Myanmar\",\"year: 1967<br />lifeExp: 49.37900<br />country: Myanmar\",\"year: 1972<br />lifeExp: 53.07000<br />country: Myanmar\",\"year: 1977<br />lifeExp: 56.05900<br />country: Myanmar\",\"year: 1982<br />lifeExp: 58.05600<br />country: Myanmar\",\"year: 1987<br />lifeExp: 58.33900<br />country: Myanmar\",\"year: 1992<br />lifeExp: 59.32000<br />country: Myanmar\",\"year: 1997<br />lifeExp: 60.32800<br />country: Myanmar\",\"year: 2002<br />lifeExp: 59.90800<br />country: Myanmar\",\"year: 2007<br />lifeExp: 62.06900<br />country: Myanmar\",null,\"year: 1952<br />lifeExp: 41.72500<br />country: Namibia\",\"year: 1957<br />lifeExp: 45.22600<br />country: Namibia\",\"year: 1962<br />lifeExp: 48.38600<br />country: Namibia\",\"year: 1967<br />lifeExp: 51.15900<br />country: Namibia\",\"year: 1972<br />lifeExp: 53.86700<br />country: Namibia\",\"year: 1977<br />lifeExp: 56.43700<br />country: Namibia\",\"year: 1982<br />lifeExp: 58.96800<br />country: Namibia\",\"year: 1987<br />lifeExp: 60.83500<br />country: Namibia\",\"year: 1992<br />lifeExp: 61.99900<br />country: Namibia\",\"year: 1997<br />lifeExp: 58.90900<br />country: Namibia\",\"year: 2002<br />lifeExp: 51.47900<br />country: Namibia\",\"year: 2007<br />lifeExp: 52.90600<br />country: Namibia\",null,\"year: 1952<br />lifeExp: 36.15700<br />country: Nepal\",\"year: 1957<br />lifeExp: 37.68600<br />country: Nepal\",\"year: 1962<br />lifeExp: 39.39300<br />country: Nepal\",\"year: 1967<br />lifeExp: 41.47200<br />country: Nepal\",\"year: 1972<br />lifeExp: 43.97100<br />country: Nepal\",\"year: 1977<br />lifeExp: 46.74800<br />country: Nepal\",\"year: 1982<br />lifeExp: 49.59400<br />country: Nepal\",\"year: 1987<br />lifeExp: 52.53700<br />country: Nepal\",\"year: 1992<br />lifeExp: 55.72700<br />country: Nepal\",\"year: 1997<br />lifeExp: 59.42600<br />country: Nepal\",\"year: 2002<br />lifeExp: 61.34000<br />country: Nepal\",\"year: 2007<br />lifeExp: 63.78500<br />country: Nepal\",null,\"year: 1952<br />lifeExp: 72.13000<br />country: Netherlands\",\"year: 1957<br />lifeExp: 72.99000<br />country: Netherlands\",\"year: 1962<br />lifeExp: 73.23000<br />country: Netherlands\",\"year: 1967<br />lifeExp: 73.82000<br />country: Netherlands\",\"year: 1972<br />lifeExp: 73.75000<br />country: Netherlands\",\"year: 1977<br />lifeExp: 75.24000<br />country: Netherlands\",\"year: 1982<br />lifeExp: 76.05000<br />country: Netherlands\",\"year: 1987<br />lifeExp: 76.83000<br />country: Netherlands\",\"year: 1992<br />lifeExp: 77.42000<br />country: Netherlands\",\"year: 1997<br />lifeExp: 78.03000<br />country: Netherlands\",\"year: 2002<br />lifeExp: 78.53000<br />country: Netherlands\",\"year: 2007<br />lifeExp: 79.76200<br />country: Netherlands\",null,\"year: 1952<br />lifeExp: 69.39000<br />country: New Zealand\",\"year: 1957<br />lifeExp: 70.26000<br />country: New Zealand\",\"year: 1962<br />lifeExp: 71.24000<br />country: New Zealand\",\"year: 1967<br />lifeExp: 71.52000<br />country: New Zealand\",\"year: 1972<br />lifeExp: 71.89000<br />country: New Zealand\",\"year: 1977<br />lifeExp: 72.22000<br />country: New Zealand\",\"year: 1982<br />lifeExp: 73.84000<br />country: New Zealand\",\"year: 1987<br />lifeExp: 74.32000<br />country: New Zealand\",\"year: 1992<br />lifeExp: 76.33000<br />country: New Zealand\",\"year: 1997<br />lifeExp: 77.55000<br />country: New Zealand\",\"year: 2002<br />lifeExp: 79.11000<br />country: New Zealand\",\"year: 2007<br />lifeExp: 80.20400<br />country: New Zealand\",null,\"year: 1952<br />lifeExp: 42.31400<br />country: Nicaragua\",\"year: 1957<br />lifeExp: 45.43200<br />country: Nicaragua\",\"year: 1962<br />lifeExp: 48.63200<br />country: Nicaragua\",\"year: 1967<br />lifeExp: 51.88400<br />country: Nicaragua\",\"year: 1972<br />lifeExp: 55.15100<br />country: Nicaragua\",\"year: 1977<br />lifeExp: 57.47000<br />country: Nicaragua\",\"year: 1982<br />lifeExp: 59.29800<br />country: Nicaragua\",\"year: 1987<br />lifeExp: 62.00800<br />country: Nicaragua\",\"year: 1992<br />lifeExp: 65.84300<br />country: Nicaragua\",\"year: 1997<br />lifeExp: 68.42600<br />country: Nicaragua\",\"year: 2002<br />lifeExp: 70.83600<br />country: Nicaragua\",\"year: 2007<br />lifeExp: 72.89900<br />country: Nicaragua\",null,\"year: 1952<br />lifeExp: 37.44400<br />country: Niger\",\"year: 1957<br />lifeExp: 38.59800<br />country: Niger\",\"year: 1962<br />lifeExp: 39.48700<br />country: Niger\",\"year: 1967<br />lifeExp: 40.11800<br />country: Niger\",\"year: 1972<br />lifeExp: 40.54600<br />country: Niger\",\"year: 1977<br />lifeExp: 41.29100<br />country: Niger\",\"year: 1982<br />lifeExp: 42.59800<br />country: Niger\",\"year: 1987<br />lifeExp: 44.55500<br />country: Niger\",\"year: 1992<br />lifeExp: 47.39100<br />country: Niger\",\"year: 1997<br />lifeExp: 51.31300<br />country: Niger\",\"year: 2002<br />lifeExp: 54.49600<br />country: Niger\",\"year: 2007<br />lifeExp: 56.86700<br />country: Niger\",null,\"year: 1952<br />lifeExp: 36.32400<br />country: Nigeria\",\"year: 1957<br />lifeExp: 37.80200<br />country: Nigeria\",\"year: 1962<br />lifeExp: 39.36000<br />country: Nigeria\",\"year: 1967<br />lifeExp: 41.04000<br />country: Nigeria\",\"year: 1972<br />lifeExp: 42.82100<br />country: Nigeria\",\"year: 1977<br />lifeExp: 44.51400<br />country: Nigeria\",\"year: 1982<br />lifeExp: 45.82600<br />country: Nigeria\",\"year: 1987<br />lifeExp: 46.88600<br />country: Nigeria\",\"year: 1992<br />lifeExp: 47.47200<br />country: Nigeria\",\"year: 1997<br />lifeExp: 47.46400<br />country: Nigeria\",\"year: 2002<br />lifeExp: 46.60800<br />country: Nigeria\",\"year: 2007<br />lifeExp: 46.85900<br />country: Nigeria\",null,\"year: 1952<br />lifeExp: 72.67000<br />country: Norway\",\"year: 1957<br />lifeExp: 73.44000<br />country: Norway\",\"year: 1962<br />lifeExp: 73.47000<br />country: Norway\",\"year: 1967<br />lifeExp: 74.08000<br />country: Norway\",\"year: 1972<br />lifeExp: 74.34000<br />country: Norway\",\"year: 1977<br />lifeExp: 75.37000<br />country: Norway\",\"year: 1982<br />lifeExp: 75.97000<br />country: Norway\",\"year: 1987<br />lifeExp: 75.89000<br />country: Norway\",\"year: 1992<br />lifeExp: 77.32000<br />country: Norway\",\"year: 1997<br />lifeExp: 78.32000<br />country: Norway\",\"year: 2002<br />lifeExp: 79.05000<br />country: Norway\",\"year: 2007<br />lifeExp: 80.19600<br />country: Norway\",null,\"year: 1952<br />lifeExp: 37.57800<br />country: Oman\",\"year: 1957<br />lifeExp: 40.08000<br />country: Oman\",\"year: 1962<br />lifeExp: 43.16500<br />country: Oman\",\"year: 1967<br />lifeExp: 46.98800<br />country: Oman\",\"year: 1972<br />lifeExp: 52.14300<br />country: Oman\",\"year: 1977<br />lifeExp: 57.36700<br />country: Oman\",\"year: 1982<br />lifeExp: 62.72800<br />country: Oman\",\"year: 1987<br />lifeExp: 67.73400<br />country: Oman\",\"year: 1992<br />lifeExp: 71.19700<br />country: Oman\",\"year: 1997<br />lifeExp: 72.49900<br />country: Oman\",\"year: 2002<br />lifeExp: 74.19300<br />country: Oman\",\"year: 2007<br />lifeExp: 75.64000<br />country: Oman\",null,\"year: 1952<br />lifeExp: 43.43600<br />country: Pakistan\",\"year: 1957<br />lifeExp: 45.55700<br />country: Pakistan\",\"year: 1962<br />lifeExp: 47.67000<br />country: Pakistan\",\"year: 1967<br />lifeExp: 49.80000<br />country: Pakistan\",\"year: 1972<br />lifeExp: 51.92900<br />country: Pakistan\",\"year: 1977<br />lifeExp: 54.04300<br />country: Pakistan\",\"year: 1982<br />lifeExp: 56.15800<br />country: Pakistan\",\"year: 1987<br />lifeExp: 58.24500<br />country: Pakistan\",\"year: 1992<br />lifeExp: 60.83800<br />country: Pakistan\",\"year: 1997<br />lifeExp: 61.81800<br />country: Pakistan\",\"year: 2002<br />lifeExp: 63.61000<br />country: Pakistan\",\"year: 2007<br />lifeExp: 65.48300<br />country: Pakistan\",null,\"year: 1952<br />lifeExp: 55.19100<br />country: Panama\",\"year: 1957<br />lifeExp: 59.20100<br />country: Panama\",\"year: 1962<br />lifeExp: 61.81700<br />country: Panama\",\"year: 1967<br />lifeExp: 64.07100<br />country: Panama\",\"year: 1972<br />lifeExp: 66.21600<br />country: Panama\",\"year: 1977<br />lifeExp: 68.68100<br />country: Panama\",\"year: 1982<br />lifeExp: 70.47200<br />country: Panama\",\"year: 1987<br />lifeExp: 71.52300<br />country: Panama\",\"year: 1992<br />lifeExp: 72.46200<br />country: Panama\",\"year: 1997<br />lifeExp: 73.73800<br />country: Panama\",\"year: 2002<br />lifeExp: 74.71200<br />country: Panama\",\"year: 2007<br />lifeExp: 75.53700<br />country: Panama\",null,\"year: 1952<br />lifeExp: 62.64900<br />country: Paraguay\",\"year: 1957<br />lifeExp: 63.19600<br />country: Paraguay\",\"year: 1962<br />lifeExp: 64.36100<br />country: Paraguay\",\"year: 1967<br />lifeExp: 64.95100<br />country: Paraguay\",\"year: 1972<br />lifeExp: 65.81500<br />country: Paraguay\",\"year: 1977<br />lifeExp: 66.35300<br />country: Paraguay\",\"year: 1982<br />lifeExp: 66.87400<br />country: Paraguay\",\"year: 1987<br />lifeExp: 67.37800<br />country: Paraguay\",\"year: 1992<br />lifeExp: 68.22500<br />country: Paraguay\",\"year: 1997<br />lifeExp: 69.40000<br />country: Paraguay\",\"year: 2002<br />lifeExp: 70.75500<br />country: Paraguay\",\"year: 2007<br />lifeExp: 71.75200<br />country: Paraguay\",null,\"year: 1952<br />lifeExp: 43.90200<br />country: Peru\",\"year: 1957<br />lifeExp: 46.26300<br />country: Peru\",\"year: 1962<br />lifeExp: 49.09600<br />country: Peru\",\"year: 1967<br />lifeExp: 51.44500<br />country: Peru\",\"year: 1972<br />lifeExp: 55.44800<br />country: Peru\",\"year: 1977<br />lifeExp: 58.44700<br />country: Peru\",\"year: 1982<br />lifeExp: 61.40600<br />country: Peru\",\"year: 1987<br />lifeExp: 64.13400<br />country: Peru\",\"year: 1992<br />lifeExp: 66.45800<br />country: Peru\",\"year: 1997<br />lifeExp: 68.38600<br />country: Peru\",\"year: 2002<br />lifeExp: 69.90600<br />country: Peru\",\"year: 2007<br />lifeExp: 71.42100<br />country: Peru\",null,\"year: 1952<br />lifeExp: 47.75200<br />country: Philippines\",\"year: 1957<br />lifeExp: 51.33400<br />country: Philippines\",\"year: 1962<br />lifeExp: 54.75700<br />country: Philippines\",\"year: 1967<br />lifeExp: 56.39300<br />country: Philippines\",\"year: 1972<br />lifeExp: 58.06500<br />country: Philippines\",\"year: 1977<br />lifeExp: 60.06000<br />country: Philippines\",\"year: 1982<br />lifeExp: 62.08200<br />country: Philippines\",\"year: 1987<br />lifeExp: 64.15100<br />country: Philippines\",\"year: 1992<br />lifeExp: 66.45800<br />country: Philippines\",\"year: 1997<br />lifeExp: 68.56400<br />country: Philippines\",\"year: 2002<br />lifeExp: 70.30300<br />country: Philippines\",\"year: 2007<br />lifeExp: 71.68800<br />country: Philippines\",null,\"year: 1952<br />lifeExp: 61.31000<br />country: Poland\",\"year: 1957<br />lifeExp: 65.77000<br />country: Poland\",\"year: 1962<br />lifeExp: 67.64000<br />country: Poland\",\"year: 1967<br />lifeExp: 69.61000<br />country: Poland\",\"year: 1972<br />lifeExp: 70.85000<br />country: Poland\",\"year: 1977<br />lifeExp: 70.67000<br />country: Poland\",\"year: 1982<br />lifeExp: 71.32000<br />country: Poland\",\"year: 1987<br />lifeExp: 70.98000<br />country: Poland\",\"year: 1992<br />lifeExp: 70.99000<br />country: Poland\",\"year: 1997<br />lifeExp: 72.75000<br />country: Poland\",\"year: 2002<br />lifeExp: 74.67000<br />country: Poland\",\"year: 2007<br />lifeExp: 75.56300<br />country: Poland\",null,\"year: 1952<br />lifeExp: 59.82000<br />country: Portugal\",\"year: 1957<br />lifeExp: 61.51000<br />country: Portugal\",\"year: 1962<br />lifeExp: 64.39000<br />country: Portugal\",\"year: 1967<br />lifeExp: 66.60000<br />country: Portugal\",\"year: 1972<br />lifeExp: 69.26000<br />country: Portugal\",\"year: 1977<br />lifeExp: 70.41000<br />country: Portugal\",\"year: 1982<br />lifeExp: 72.77000<br />country: Portugal\",\"year: 1987<br />lifeExp: 74.06000<br />country: Portugal\",\"year: 1992<br />lifeExp: 74.86000<br />country: Portugal\",\"year: 1997<br />lifeExp: 75.97000<br />country: Portugal\",\"year: 2002<br />lifeExp: 77.29000<br />country: Portugal\",\"year: 2007<br />lifeExp: 78.09800<br />country: Portugal\",null,\"year: 1952<br />lifeExp: 64.28000<br />country: Puerto Rico\",\"year: 1957<br />lifeExp: 68.54000<br />country: Puerto Rico\",\"year: 1962<br />lifeExp: 69.62000<br />country: Puerto Rico\",\"year: 1967<br />lifeExp: 71.10000<br />country: Puerto Rico\",\"year: 1972<br />lifeExp: 72.16000<br />country: Puerto Rico\",\"year: 1977<br />lifeExp: 73.44000<br />country: Puerto Rico\",\"year: 1982<br />lifeExp: 73.75000<br />country: Puerto Rico\",\"year: 1987<br />lifeExp: 74.63000<br />country: Puerto Rico\",\"year: 1992<br />lifeExp: 73.91100<br />country: Puerto Rico\",\"year: 1997<br />lifeExp: 74.91700<br />country: Puerto Rico\",\"year: 2002<br />lifeExp: 77.77800<br />country: Puerto Rico\",\"year: 2007<br />lifeExp: 78.74600<br />country: Puerto Rico\",null,\"year: 1952<br />lifeExp: 52.72400<br />country: Reunion\",\"year: 1957<br />lifeExp: 55.09000<br />country: Reunion\",\"year: 1962<br />lifeExp: 57.66600<br />country: Reunion\",\"year: 1967<br />lifeExp: 60.54200<br />country: Reunion\",\"year: 1972<br />lifeExp: 64.27400<br />country: Reunion\",\"year: 1977<br />lifeExp: 67.06400<br />country: Reunion\",\"year: 1982<br />lifeExp: 69.88500<br />country: Reunion\",\"year: 1987<br />lifeExp: 71.91300<br />country: Reunion\",\"year: 1992<br />lifeExp: 73.61500<br />country: Reunion\",\"year: 1997<br />lifeExp: 74.77200<br />country: Reunion\",\"year: 2002<br />lifeExp: 75.74400<br />country: Reunion\",\"year: 2007<br />lifeExp: 76.44200<br />country: Reunion\",null,\"year: 1952<br />lifeExp: 61.05000<br />country: Romania\",\"year: 1957<br />lifeExp: 64.10000<br />country: Romania\",\"year: 1962<br />lifeExp: 66.80000<br />country: Romania\",\"year: 1967<br />lifeExp: 66.80000<br />country: Romania\",\"year: 1972<br />lifeExp: 69.21000<br />country: Romania\",\"year: 1977<br />lifeExp: 69.46000<br />country: Romania\",\"year: 1982<br />lifeExp: 69.66000<br />country: Romania\",\"year: 1987<br />lifeExp: 69.53000<br />country: Romania\",\"year: 1992<br />lifeExp: 69.36000<br />country: Romania\",\"year: 1997<br />lifeExp: 69.72000<br />country: Romania\",\"year: 2002<br />lifeExp: 71.32200<br />country: Romania\",\"year: 2007<br />lifeExp: 72.47600<br />country: Romania\",null,\"year: 1952<br />lifeExp: 40.00000<br />country: Rwanda\",\"year: 1957<br />lifeExp: 41.50000<br />country: Rwanda\",\"year: 1962<br />lifeExp: 43.00000<br />country: Rwanda\",\"year: 1967<br />lifeExp: 44.10000<br />country: Rwanda\",\"year: 1972<br />lifeExp: 44.60000<br />country: Rwanda\",\"year: 1977<br />lifeExp: 45.00000<br />country: Rwanda\",\"year: 1982<br />lifeExp: 46.21800<br />country: Rwanda\",\"year: 1987<br />lifeExp: 44.02000<br />country: Rwanda\",\"year: 1992<br />lifeExp: 23.59900<br />country: Rwanda\",\"year: 1997<br />lifeExp: 36.08700<br />country: Rwanda\",\"year: 2002<br />lifeExp: 43.41300<br />country: Rwanda\",\"year: 2007<br />lifeExp: 46.24200<br />country: Rwanda\",null,\"year: 1952<br />lifeExp: 46.47100<br />country: Sao Tome and Principe\",\"year: 1957<br />lifeExp: 48.94500<br />country: Sao Tome and Principe\",\"year: 1962<br />lifeExp: 51.89300<br />country: Sao Tome and Principe\",\"year: 1967<br />lifeExp: 54.42500<br />country: Sao Tome and Principe\",\"year: 1972<br />lifeExp: 56.48000<br />country: Sao Tome and Principe\",\"year: 1977<br />lifeExp: 58.55000<br />country: Sao Tome and Principe\",\"year: 1982<br />lifeExp: 60.35100<br />country: Sao Tome and Principe\",\"year: 1987<br />lifeExp: 61.72800<br />country: Sao Tome and Principe\",\"year: 1992<br />lifeExp: 62.74200<br />country: Sao Tome and Principe\",\"year: 1997<br />lifeExp: 63.30600<br />country: Sao Tome and Principe\",\"year: 2002<br />lifeExp: 64.33700<br />country: Sao Tome and Principe\",\"year: 2007<br />lifeExp: 65.52800<br />country: Sao Tome and Principe\",null,\"year: 1952<br />lifeExp: 39.87500<br />country: Saudi Arabia\",\"year: 1957<br />lifeExp: 42.86800<br />country: Saudi Arabia\",\"year: 1962<br />lifeExp: 45.91400<br />country: Saudi Arabia\",\"year: 1967<br />lifeExp: 49.90100<br />country: Saudi Arabia\",\"year: 1972<br />lifeExp: 53.88600<br />country: Saudi Arabia\",\"year: 1977<br />lifeExp: 58.69000<br />country: Saudi Arabia\",\"year: 1982<br />lifeExp: 63.01200<br />country: Saudi Arabia\",\"year: 1987<br />lifeExp: 66.29500<br />country: Saudi Arabia\",\"year: 1992<br />lifeExp: 68.76800<br />country: Saudi Arabia\",\"year: 1997<br />lifeExp: 70.53300<br />country: Saudi Arabia\",\"year: 2002<br />lifeExp: 71.62600<br />country: Saudi Arabia\",\"year: 2007<br />lifeExp: 72.77700<br />country: Saudi Arabia\",null,\"year: 1952<br />lifeExp: 37.27800<br />country: Senegal\",\"year: 1957<br />lifeExp: 39.32900<br />country: Senegal\",\"year: 1962<br />lifeExp: 41.45400<br />country: Senegal\",\"year: 1967<br />lifeExp: 43.56300<br />country: Senegal\",\"year: 1972<br />lifeExp: 45.81500<br />country: Senegal\",\"year: 1977<br />lifeExp: 48.87900<br />country: Senegal\",\"year: 1982<br />lifeExp: 52.37900<br />country: Senegal\",\"year: 1987<br />lifeExp: 55.76900<br />country: Senegal\",\"year: 1992<br />lifeExp: 58.19600<br />country: Senegal\",\"year: 1997<br />lifeExp: 60.18700<br />country: Senegal\",\"year: 2002<br />lifeExp: 61.60000<br />country: Senegal\",\"year: 2007<br />lifeExp: 63.06200<br />country: Senegal\",null,\"year: 1952<br />lifeExp: 57.99600<br />country: Serbia\",\"year: 1957<br />lifeExp: 61.68500<br />country: Serbia\",\"year: 1962<br />lifeExp: 64.53100<br />country: Serbia\",\"year: 1967<br />lifeExp: 66.91400<br />country: Serbia\",\"year: 1972<br />lifeExp: 68.70000<br />country: Serbia\",\"year: 1977<br />lifeExp: 70.30000<br />country: Serbia\",\"year: 1982<br />lifeExp: 70.16200<br />country: Serbia\",\"year: 1987<br />lifeExp: 71.21800<br />country: Serbia\",\"year: 1992<br />lifeExp: 71.65900<br />country: Serbia\",\"year: 1997<br />lifeExp: 72.23200<br />country: Serbia\",\"year: 2002<br />lifeExp: 73.21300<br />country: Serbia\",\"year: 2007<br />lifeExp: 74.00200<br />country: Serbia\",null,\"year: 1952<br />lifeExp: 30.33100<br />country: Sierra Leone\",\"year: 1957<br />lifeExp: 31.57000<br />country: Sierra Leone\",\"year: 1962<br />lifeExp: 32.76700<br />country: Sierra Leone\",\"year: 1967<br />lifeExp: 34.11300<br />country: Sierra Leone\",\"year: 1972<br />lifeExp: 35.40000<br />country: Sierra Leone\",\"year: 1977<br />lifeExp: 36.78800<br />country: Sierra Leone\",\"year: 1982<br />lifeExp: 38.44500<br />country: Sierra Leone\",\"year: 1987<br />lifeExp: 40.00600<br />country: Sierra Leone\",\"year: 1992<br />lifeExp: 38.33300<br />country: Sierra Leone\",\"year: 1997<br />lifeExp: 39.89700<br />country: Sierra Leone\",\"year: 2002<br />lifeExp: 41.01200<br />country: Sierra Leone\",\"year: 2007<br />lifeExp: 42.56800<br />country: Sierra Leone\",null,\"year: 1952<br />lifeExp: 60.39600<br />country: Singapore\",\"year: 1957<br />lifeExp: 63.17900<br />country: Singapore\",\"year: 1962<br />lifeExp: 65.79800<br />country: Singapore\",\"year: 1967<br />lifeExp: 67.94600<br />country: Singapore\",\"year: 1972<br />lifeExp: 69.52100<br />country: Singapore\",\"year: 1977<br />lifeExp: 70.79500<br />country: Singapore\",\"year: 1982<br />lifeExp: 71.76000<br />country: Singapore\",\"year: 1987<br />lifeExp: 73.56000<br />country: Singapore\",\"year: 1992<br />lifeExp: 75.78800<br />country: Singapore\",\"year: 1997<br />lifeExp: 77.15800<br />country: Singapore\",\"year: 2002<br />lifeExp: 78.77000<br />country: Singapore\",\"year: 2007<br />lifeExp: 79.97200<br />country: Singapore\",null,\"year: 1952<br />lifeExp: 64.36000<br />country: Slovak Republic\",\"year: 1957<br />lifeExp: 67.45000<br />country: Slovak Republic\",\"year: 1962<br />lifeExp: 70.33000<br />country: Slovak Republic\",\"year: 1967<br />lifeExp: 70.98000<br />country: Slovak Republic\",\"year: 1972<br />lifeExp: 70.35000<br />country: Slovak Republic\",\"year: 1977<br />lifeExp: 70.45000<br />country: Slovak Republic\",\"year: 1982<br />lifeExp: 70.80000<br />country: Slovak Republic\",\"year: 1987<br />lifeExp: 71.08000<br />country: Slovak Republic\",\"year: 1992<br />lifeExp: 71.38000<br />country: Slovak Republic\",\"year: 1997<br />lifeExp: 72.71000<br />country: Slovak Republic\",\"year: 2002<br />lifeExp: 73.80000<br />country: Slovak Republic\",\"year: 2007<br />lifeExp: 74.66300<br />country: Slovak Republic\",null,\"year: 1952<br />lifeExp: 65.57000<br />country: Slovenia\",\"year: 1957<br />lifeExp: 67.85000<br />country: Slovenia\",\"year: 1962<br />lifeExp: 69.15000<br />country: Slovenia\",\"year: 1967<br />lifeExp: 69.18000<br />country: Slovenia\",\"year: 1972<br />lifeExp: 69.82000<br />country: Slovenia\",\"year: 1977<br />lifeExp: 70.97000<br />country: Slovenia\",\"year: 1982<br />lifeExp: 71.06300<br />country: Slovenia\",\"year: 1987<br />lifeExp: 72.25000<br />country: Slovenia\",\"year: 1992<br />lifeExp: 73.64000<br />country: Slovenia\",\"year: 1997<br />lifeExp: 75.13000<br />country: Slovenia\",\"year: 2002<br />lifeExp: 76.66000<br />country: Slovenia\",\"year: 2007<br />lifeExp: 77.92600<br />country: Slovenia\",null,\"year: 1952<br />lifeExp: 32.97800<br />country: Somalia\",\"year: 1957<br />lifeExp: 34.97700<br />country: Somalia\",\"year: 1962<br />lifeExp: 36.98100<br />country: Somalia\",\"year: 1967<br />lifeExp: 38.97700<br />country: Somalia\",\"year: 1972<br />lifeExp: 40.97300<br />country: Somalia\",\"year: 1977<br />lifeExp: 41.97400<br />country: Somalia\",\"year: 1982<br />lifeExp: 42.95500<br />country: Somalia\",\"year: 1987<br />lifeExp: 44.50100<br />country: Somalia\",\"year: 1992<br />lifeExp: 39.65800<br />country: Somalia\",\"year: 1997<br />lifeExp: 43.79500<br />country: Somalia\",\"year: 2002<br />lifeExp: 45.93600<br />country: Somalia\",\"year: 2007<br />lifeExp: 48.15900<br />country: Somalia\",null,\"year: 1952<br />lifeExp: 45.00900<br />country: South Africa\",\"year: 1957<br />lifeExp: 47.98500<br />country: South Africa\",\"year: 1962<br />lifeExp: 49.95100<br />country: South Africa\",\"year: 1967<br />lifeExp: 51.92700<br />country: South Africa\",\"year: 1972<br />lifeExp: 53.69600<br />country: South Africa\",\"year: 1977<br />lifeExp: 55.52700<br />country: South Africa\",\"year: 1982<br />lifeExp: 58.16100<br />country: South Africa\",\"year: 1987<br />lifeExp: 60.83400<br />country: South Africa\",\"year: 1992<br />lifeExp: 61.88800<br />country: South Africa\",\"year: 1997<br />lifeExp: 60.23600<br />country: South Africa\",\"year: 2002<br />lifeExp: 53.36500<br />country: South Africa\",\"year: 2007<br />lifeExp: 49.33900<br />country: South Africa\",null,\"year: 1952<br />lifeExp: 64.94000<br />country: Spain\",\"year: 1957<br />lifeExp: 66.66000<br />country: Spain\",\"year: 1962<br />lifeExp: 69.69000<br />country: Spain\",\"year: 1967<br />lifeExp: 71.44000<br />country: Spain\",\"year: 1972<br />lifeExp: 73.06000<br />country: Spain\",\"year: 1977<br />lifeExp: 74.39000<br />country: Spain\",\"year: 1982<br />lifeExp: 76.30000<br />country: Spain\",\"year: 1987<br />lifeExp: 76.90000<br />country: Spain\",\"year: 1992<br />lifeExp: 77.57000<br />country: Spain\",\"year: 1997<br />lifeExp: 78.77000<br />country: Spain\",\"year: 2002<br />lifeExp: 79.78000<br />country: Spain\",\"year: 2007<br />lifeExp: 80.94100<br />country: Spain\",null,\"year: 1952<br />lifeExp: 57.59300<br />country: Sri Lanka\",\"year: 1957<br />lifeExp: 61.45600<br />country: Sri Lanka\",\"year: 1962<br />lifeExp: 62.19200<br />country: Sri Lanka\",\"year: 1967<br />lifeExp: 64.26600<br />country: Sri Lanka\",\"year: 1972<br />lifeExp: 65.04200<br />country: Sri Lanka\",\"year: 1977<br />lifeExp: 65.94900<br />country: Sri Lanka\",\"year: 1982<br />lifeExp: 68.75700<br />country: Sri Lanka\",\"year: 1987<br />lifeExp: 69.01100<br />country: Sri Lanka\",\"year: 1992<br />lifeExp: 70.37900<br />country: Sri Lanka\",\"year: 1997<br />lifeExp: 70.45700<br />country: Sri Lanka\",\"year: 2002<br />lifeExp: 70.81500<br />country: Sri Lanka\",\"year: 2007<br />lifeExp: 72.39600<br />country: Sri Lanka\",null,\"year: 1952<br />lifeExp: 38.63500<br />country: Sudan\",\"year: 1957<br />lifeExp: 39.62400<br />country: Sudan\",\"year: 1962<br />lifeExp: 40.87000<br />country: Sudan\",\"year: 1967<br />lifeExp: 42.85800<br />country: Sudan\",\"year: 1972<br />lifeExp: 45.08300<br />country: Sudan\",\"year: 1977<br />lifeExp: 47.80000<br />country: Sudan\",\"year: 1982<br />lifeExp: 50.33800<br />country: Sudan\",\"year: 1987<br />lifeExp: 51.74400<br />country: Sudan\",\"year: 1992<br />lifeExp: 53.55600<br />country: Sudan\",\"year: 1997<br />lifeExp: 55.37300<br />country: Sudan\",\"year: 2002<br />lifeExp: 56.36900<br />country: Sudan\",\"year: 2007<br />lifeExp: 58.55600<br />country: Sudan\",null,\"year: 1952<br />lifeExp: 41.40700<br />country: Swaziland\",\"year: 1957<br />lifeExp: 43.42400<br />country: Swaziland\",\"year: 1962<br />lifeExp: 44.99200<br />country: Swaziland\",\"year: 1967<br />lifeExp: 46.63300<br />country: Swaziland\",\"year: 1972<br />lifeExp: 49.55200<br />country: Swaziland\",\"year: 1977<br />lifeExp: 52.53700<br />country: Swaziland\",\"year: 1982<br />lifeExp: 55.56100<br />country: Swaziland\",\"year: 1987<br />lifeExp: 57.67800<br />country: Swaziland\",\"year: 1992<br />lifeExp: 58.47400<br />country: Swaziland\",\"year: 1997<br />lifeExp: 54.28900<br />country: Swaziland\",\"year: 2002<br />lifeExp: 43.86900<br />country: Swaziland\",\"year: 2007<br />lifeExp: 39.61300<br />country: Swaziland\",null,\"year: 1952<br />lifeExp: 71.86000<br />country: Sweden\",\"year: 1957<br />lifeExp: 72.49000<br />country: Sweden\",\"year: 1962<br />lifeExp: 73.37000<br />country: Sweden\",\"year: 1967<br />lifeExp: 74.16000<br />country: Sweden\",\"year: 1972<br />lifeExp: 74.72000<br />country: Sweden\",\"year: 1977<br />lifeExp: 75.44000<br />country: Sweden\",\"year: 1982<br />lifeExp: 76.42000<br />country: Sweden\",\"year: 1987<br />lifeExp: 77.19000<br />country: Sweden\",\"year: 1992<br />lifeExp: 78.16000<br />country: Sweden\",\"year: 1997<br />lifeExp: 79.39000<br />country: Sweden\",\"year: 2002<br />lifeExp: 80.04000<br />country: Sweden\",\"year: 2007<br />lifeExp: 80.88400<br />country: Sweden\",null,\"year: 1952<br />lifeExp: 69.62000<br />country: Switzerland\",\"year: 1957<br />lifeExp: 70.56000<br />country: Switzerland\",\"year: 1962<br />lifeExp: 71.32000<br />country: Switzerland\",\"year: 1967<br />lifeExp: 72.77000<br />country: Switzerland\",\"year: 1972<br />lifeExp: 73.78000<br />country: Switzerland\",\"year: 1977<br />lifeExp: 75.39000<br />country: Switzerland\",\"year: 1982<br />lifeExp: 76.21000<br />country: Switzerland\",\"year: 1987<br />lifeExp: 77.41000<br />country: Switzerland\",\"year: 1992<br />lifeExp: 78.03000<br />country: Switzerland\",\"year: 1997<br />lifeExp: 79.37000<br />country: Switzerland\",\"year: 2002<br />lifeExp: 80.62000<br />country: Switzerland\",\"year: 2007<br />lifeExp: 81.70100<br />country: Switzerland\",null,\"year: 1952<br />lifeExp: 45.88300<br />country: Syria\",\"year: 1957<br />lifeExp: 48.28400<br />country: Syria\",\"year: 1962<br />lifeExp: 50.30500<br />country: Syria\",\"year: 1967<br />lifeExp: 53.65500<br />country: Syria\",\"year: 1972<br />lifeExp: 57.29600<br />country: Syria\",\"year: 1977<br />lifeExp: 61.19500<br />country: Syria\",\"year: 1982<br />lifeExp: 64.59000<br />country: Syria\",\"year: 1987<br />lifeExp: 66.97400<br />country: Syria\",\"year: 1992<br />lifeExp: 69.24900<br />country: Syria\",\"year: 1997<br />lifeExp: 71.52700<br />country: Syria\",\"year: 2002<br />lifeExp: 73.05300<br />country: Syria\",\"year: 2007<br />lifeExp: 74.14300<br />country: Syria\",null,\"year: 1952<br />lifeExp: 58.50000<br />country: Taiwan\",\"year: 1957<br />lifeExp: 62.40000<br />country: Taiwan\",\"year: 1962<br />lifeExp: 65.20000<br />country: Taiwan\",\"year: 1967<br />lifeExp: 67.50000<br />country: Taiwan\",\"year: 1972<br />lifeExp: 69.39000<br />country: Taiwan\",\"year: 1977<br />lifeExp: 70.59000<br />country: Taiwan\",\"year: 1982<br />lifeExp: 72.16000<br />country: Taiwan\",\"year: 1987<br />lifeExp: 73.40000<br />country: Taiwan\",\"year: 1992<br />lifeExp: 74.26000<br />country: Taiwan\",\"year: 1997<br />lifeExp: 75.25000<br />country: Taiwan\",\"year: 2002<br />lifeExp: 76.99000<br />country: Taiwan\",\"year: 2007<br />lifeExp: 78.40000<br />country: Taiwan\",null,\"year: 1952<br />lifeExp: 41.21500<br />country: Tanzania\",\"year: 1957<br />lifeExp: 42.97400<br />country: Tanzania\",\"year: 1962<br />lifeExp: 44.24600<br />country: Tanzania\",\"year: 1967<br />lifeExp: 45.75700<br />country: Tanzania\",\"year: 1972<br />lifeExp: 47.62000<br />country: Tanzania\",\"year: 1977<br />lifeExp: 49.91900<br />country: Tanzania\",\"year: 1982<br />lifeExp: 50.60800<br />country: Tanzania\",\"year: 1987<br />lifeExp: 51.53500<br />country: Tanzania\",\"year: 1992<br />lifeExp: 50.44000<br />country: Tanzania\",\"year: 1997<br />lifeExp: 48.46600<br />country: Tanzania\",\"year: 2002<br />lifeExp: 49.65100<br />country: Tanzania\",\"year: 2007<br />lifeExp: 52.51700<br />country: Tanzania\",null,\"year: 1952<br />lifeExp: 50.84800<br />country: Thailand\",\"year: 1957<br />lifeExp: 53.63000<br />country: Thailand\",\"year: 1962<br />lifeExp: 56.06100<br />country: Thailand\",\"year: 1967<br />lifeExp: 58.28500<br />country: Thailand\",\"year: 1972<br />lifeExp: 60.40500<br />country: Thailand\",\"year: 1977<br />lifeExp: 62.49400<br />country: Thailand\",\"year: 1982<br />lifeExp: 64.59700<br />country: Thailand\",\"year: 1987<br />lifeExp: 66.08400<br />country: Thailand\",\"year: 1992<br />lifeExp: 67.29800<br />country: Thailand\",\"year: 1997<br />lifeExp: 67.52100<br />country: Thailand\",\"year: 2002<br />lifeExp: 68.56400<br />country: Thailand\",\"year: 2007<br />lifeExp: 70.61600<br />country: Thailand\",null,\"year: 1952<br />lifeExp: 38.59600<br />country: Togo\",\"year: 1957<br />lifeExp: 41.20800<br />country: Togo\",\"year: 1962<br />lifeExp: 43.92200<br />country: Togo\",\"year: 1967<br />lifeExp: 46.76900<br />country: Togo\",\"year: 1972<br />lifeExp: 49.75900<br />country: Togo\",\"year: 1977<br />lifeExp: 52.88700<br />country: Togo\",\"year: 1982<br />lifeExp: 55.47100<br />country: Togo\",\"year: 1987<br />lifeExp: 56.94100<br />country: Togo\",\"year: 1992<br />lifeExp: 58.06100<br />country: Togo\",\"year: 1997<br />lifeExp: 58.39000<br />country: Togo\",\"year: 2002<br />lifeExp: 57.56100<br />country: Togo\",\"year: 2007<br />lifeExp: 58.42000<br />country: Togo\",null,\"year: 1952<br />lifeExp: 59.10000<br />country: Trinidad and Tobago\",\"year: 1957<br />lifeExp: 61.80000<br />country: Trinidad and Tobago\",\"year: 1962<br />lifeExp: 64.90000<br />country: Trinidad and Tobago\",\"year: 1967<br />lifeExp: 65.40000<br />country: Trinidad and Tobago\",\"year: 1972<br />lifeExp: 65.90000<br />country: Trinidad and Tobago\",\"year: 1977<br />lifeExp: 68.30000<br />country: Trinidad and Tobago\",\"year: 1982<br />lifeExp: 68.83200<br />country: Trinidad and Tobago\",\"year: 1987<br />lifeExp: 69.58200<br />country: Trinidad and Tobago\",\"year: 1992<br />lifeExp: 69.86200<br />country: Trinidad and Tobago\",\"year: 1997<br />lifeExp: 69.46500<br />country: Trinidad and Tobago\",\"year: 2002<br />lifeExp: 68.97600<br />country: Trinidad and Tobago\",\"year: 2007<br />lifeExp: 69.81900<br />country: Trinidad and Tobago\",null,\"year: 1952<br />lifeExp: 44.60000<br />country: Tunisia\",\"year: 1957<br />lifeExp: 47.10000<br />country: Tunisia\",\"year: 1962<br />lifeExp: 49.57900<br />country: Tunisia\",\"year: 1967<br />lifeExp: 52.05300<br />country: Tunisia\",\"year: 1972<br />lifeExp: 55.60200<br />country: Tunisia\",\"year: 1977<br />lifeExp: 59.83700<br />country: Tunisia\",\"year: 1982<br />lifeExp: 64.04800<br />country: Tunisia\",\"year: 1987<br />lifeExp: 66.89400<br />country: Tunisia\",\"year: 1992<br />lifeExp: 70.00100<br />country: Tunisia\",\"year: 1997<br />lifeExp: 71.97300<br />country: Tunisia\",\"year: 2002<br />lifeExp: 73.04200<br />country: Tunisia\",\"year: 2007<br />lifeExp: 73.92300<br />country: Tunisia\",null,\"year: 1952<br />lifeExp: 43.58500<br />country: Turkey\",\"year: 1957<br />lifeExp: 48.07900<br />country: Turkey\",\"year: 1962<br />lifeExp: 52.09800<br />country: Turkey\",\"year: 1967<br />lifeExp: 54.33600<br />country: Turkey\",\"year: 1972<br />lifeExp: 57.00500<br />country: Turkey\",\"year: 1977<br />lifeExp: 59.50700<br />country: Turkey\",\"year: 1982<br />lifeExp: 61.03600<br />country: Turkey\",\"year: 1987<br />lifeExp: 63.10800<br />country: Turkey\",\"year: 1992<br />lifeExp: 66.14600<br />country: Turkey\",\"year: 1997<br />lifeExp: 68.83500<br />country: Turkey\",\"year: 2002<br />lifeExp: 70.84500<br />country: Turkey\",\"year: 2007<br />lifeExp: 71.77700<br />country: Turkey\",null,\"year: 1952<br />lifeExp: 39.97800<br />country: Uganda\",\"year: 1957<br />lifeExp: 42.57100<br />country: Uganda\",\"year: 1962<br />lifeExp: 45.34400<br />country: Uganda\",\"year: 1967<br />lifeExp: 48.05100<br />country: Uganda\",\"year: 1972<br />lifeExp: 51.01600<br />country: Uganda\",\"year: 1977<br />lifeExp: 50.35000<br />country: Uganda\",\"year: 1982<br />lifeExp: 49.84900<br />country: Uganda\",\"year: 1987<br />lifeExp: 51.50900<br />country: Uganda\",\"year: 1992<br />lifeExp: 48.82500<br />country: Uganda\",\"year: 1997<br />lifeExp: 44.57800<br />country: Uganda\",\"year: 2002<br />lifeExp: 47.81300<br />country: Uganda\",\"year: 2007<br />lifeExp: 51.54200<br />country: Uganda\",null,\"year: 1952<br />lifeExp: 69.18000<br />country: United Kingdom\",\"year: 1957<br />lifeExp: 70.42000<br />country: United Kingdom\",\"year: 1962<br />lifeExp: 70.76000<br />country: United Kingdom\",\"year: 1967<br />lifeExp: 71.36000<br />country: United Kingdom\",\"year: 1972<br />lifeExp: 72.01000<br />country: United Kingdom\",\"year: 1977<br />lifeExp: 72.76000<br />country: United Kingdom\",\"year: 1982<br />lifeExp: 74.04000<br />country: United Kingdom\",\"year: 1987<br />lifeExp: 75.00700<br />country: United Kingdom\",\"year: 1992<br />lifeExp: 76.42000<br />country: United Kingdom\",\"year: 1997<br />lifeExp: 77.21800<br />country: United Kingdom\",\"year: 2002<br />lifeExp: 78.47100<br />country: United Kingdom\",\"year: 2007<br />lifeExp: 79.42500<br />country: United Kingdom\",null,\"year: 1952<br />lifeExp: 68.44000<br />country: United States\",\"year: 1957<br />lifeExp: 69.49000<br />country: United States\",\"year: 1962<br />lifeExp: 70.21000<br />country: United States\",\"year: 1967<br />lifeExp: 70.76000<br />country: United States\",\"year: 1972<br />lifeExp: 71.34000<br />country: United States\",\"year: 1977<br />lifeExp: 73.38000<br />country: United States\",\"year: 1982<br />lifeExp: 74.65000<br />country: United States\",\"year: 1987<br />lifeExp: 75.02000<br />country: United States\",\"year: 1992<br />lifeExp: 76.09000<br />country: United States\",\"year: 1997<br />lifeExp: 76.81000<br />country: United States\",\"year: 2002<br />lifeExp: 77.31000<br />country: United States\",\"year: 2007<br />lifeExp: 78.24200<br />country: United States\",null,\"year: 1952<br />lifeExp: 66.07100<br />country: Uruguay\",\"year: 1957<br />lifeExp: 67.04400<br />country: Uruguay\",\"year: 1962<br />lifeExp: 68.25300<br />country: Uruguay\",\"year: 1967<br />lifeExp: 68.46800<br />country: Uruguay\",\"year: 1972<br />lifeExp: 68.67300<br />country: Uruguay\",\"year: 1977<br />lifeExp: 69.48100<br />country: Uruguay\",\"year: 1982<br />lifeExp: 70.80500<br />country: Uruguay\",\"year: 1987<br />lifeExp: 71.91800<br />country: Uruguay\",\"year: 1992<br />lifeExp: 72.75200<br />country: Uruguay\",\"year: 1997<br />lifeExp: 74.22300<br />country: Uruguay\",\"year: 2002<br />lifeExp: 75.30700<br />country: Uruguay\",\"year: 2007<br />lifeExp: 76.38400<br />country: Uruguay\",null,\"year: 1952<br />lifeExp: 55.08800<br />country: Venezuela\",\"year: 1957<br />lifeExp: 57.90700<br />country: Venezuela\",\"year: 1962<br />lifeExp: 60.77000<br />country: Venezuela\",\"year: 1967<br />lifeExp: 63.47900<br />country: Venezuela\",\"year: 1972<br />lifeExp: 65.71200<br />country: Venezuela\",\"year: 1977<br />lifeExp: 67.45600<br />country: Venezuela\",\"year: 1982<br />lifeExp: 68.55700<br />country: Venezuela\",\"year: 1987<br />lifeExp: 70.19000<br />country: Venezuela\",\"year: 1992<br />lifeExp: 71.15000<br />country: Venezuela\",\"year: 1997<br />lifeExp: 72.14600<br />country: Venezuela\",\"year: 2002<br />lifeExp: 72.76600<br />country: Venezuela\",\"year: 2007<br />lifeExp: 73.74700<br />country: Venezuela\",null,\"year: 1952<br />lifeExp: 40.41200<br />country: Vietnam\",\"year: 1957<br />lifeExp: 42.88700<br />country: Vietnam\",\"year: 1962<br />lifeExp: 45.36300<br />country: Vietnam\",\"year: 1967<br />lifeExp: 47.83800<br />country: Vietnam\",\"year: 1972<br />lifeExp: 50.25400<br />country: Vietnam\",\"year: 1977<br />lifeExp: 55.76400<br />country: Vietnam\",\"year: 1982<br />lifeExp: 58.81600<br />country: Vietnam\",\"year: 1987<br />lifeExp: 62.82000<br />country: Vietnam\",\"year: 1992<br />lifeExp: 67.66200<br />country: Vietnam\",\"year: 1997<br />lifeExp: 70.67200<br />country: Vietnam\",\"year: 2002<br />lifeExp: 73.01700<br />country: Vietnam\",\"year: 2007<br />lifeExp: 74.24900<br />country: Vietnam\",null,\"year: 1952<br />lifeExp: 43.16000<br />country: West Bank and Gaza\",\"year: 1957<br />lifeExp: 45.67100<br />country: West Bank and Gaza\",\"year: 1962<br />lifeExp: 48.12700<br />country: West Bank and Gaza\",\"year: 1967<br />lifeExp: 51.63100<br />country: West Bank and Gaza\",\"year: 1972<br />lifeExp: 56.53200<br />country: West Bank and Gaza\",\"year: 1977<br />lifeExp: 60.76500<br />country: West Bank and Gaza\",\"year: 1982<br />lifeExp: 64.40600<br />country: West Bank and Gaza\",\"year: 1987<br />lifeExp: 67.04600<br />country: West Bank and Gaza\",\"year: 1992<br />lifeExp: 69.71800<br />country: West Bank and Gaza\",\"year: 1997<br />lifeExp: 71.09600<br />country: West Bank and Gaza\",\"year: 2002<br />lifeExp: 72.37000<br />country: West Bank and Gaza\",\"year: 2007<br />lifeExp: 73.42200<br />country: West Bank and Gaza\",null,\"year: 1952<br />lifeExp: 32.54800<br />country: Yemen, Rep.\",\"year: 1957<br />lifeExp: 33.97000<br />country: Yemen, Rep.\",\"year: 1962<br />lifeExp: 35.18000<br />country: Yemen, Rep.\",\"year: 1967<br />lifeExp: 36.98400<br />country: Yemen, Rep.\",\"year: 1972<br />lifeExp: 39.84800<br />country: Yemen, Rep.\",\"year: 1977<br />lifeExp: 44.17500<br />country: Yemen, Rep.\",\"year: 1982<br />lifeExp: 49.11300<br />country: Yemen, Rep.\",\"year: 1987<br />lifeExp: 52.92200<br />country: Yemen, Rep.\",\"year: 1992<br />lifeExp: 55.59900<br />country: Yemen, Rep.\",\"year: 1997<br />lifeExp: 58.02000<br />country: Yemen, Rep.\",\"year: 2002<br />lifeExp: 60.30800<br />country: Yemen, Rep.\",\"year: 2007<br />lifeExp: 62.69800<br />country: Yemen, Rep.\",null,\"year: 1952<br />lifeExp: 42.03800<br />country: Zambia\",\"year: 1957<br />lifeExp: 44.07700<br />country: Zambia\",\"year: 1962<br />lifeExp: 46.02300<br />country: Zambia\",\"year: 1967<br />lifeExp: 47.76800<br />country: Zambia\",\"year: 1972<br />lifeExp: 50.10700<br />country: Zambia\",\"year: 1977<br />lifeExp: 51.38600<br />country: Zambia\",\"year: 1982<br />lifeExp: 51.82100<br />country: Zambia\",\"year: 1987<br />lifeExp: 50.82100<br />country: Zambia\",\"year: 1992<br />lifeExp: 46.10000<br />country: Zambia\",\"year: 1997<br />lifeExp: 40.23800<br />country: Zambia\",\"year: 2002<br />lifeExp: 39.19300<br />country: Zambia\",\"year: 2007<br />lifeExp: 42.38400<br />country: Zambia\",null,\"year: 1952<br />lifeExp: 48.45100<br />country: Zimbabwe\",\"year: 1957<br />lifeExp: 50.46900<br />country: Zimbabwe\",\"year: 1962<br />lifeExp: 52.35800<br />country: Zimbabwe\",\"year: 1967<br />lifeExp: 53.99500<br />country: Zimbabwe\",\"year: 1972<br />lifeExp: 55.63500<br />country: Zimbabwe\",\"year: 1977<br />lifeExp: 57.67400<br />country: Zimbabwe\",\"year: 1982<br />lifeExp: 60.36300<br />country: Zimbabwe\",\"year: 1987<br />lifeExp: 62.35100<br />country: Zimbabwe\",\"year: 1992<br />lifeExp: 60.37700<br />country: Zimbabwe\",\"year: 1997<br />lifeExp: 46.80900<br />country: Zimbabwe\",\"year: 2002<br />lifeExp: 39.98900<br />country: Zimbabwe\",\"year: 2007<br />lifeExp: 43.48700<br />country: Zimbabwe\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":1.88976377952756,\"color\":\"rgba(0,0,0,0.2)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[47.622,49.618,51.52,53.298,56.024,59.319,61.484,63.622,62.745,52.556,46.634,50.728],\"text\":[\"country: Botswana<br />year: 1952<br />lifeExp: 47.622<br />country: Botswana\",\"country: Botswana<br />year: 1957<br />lifeExp: 49.618<br />country: Botswana\",\"country: Botswana<br />year: 1962<br />lifeExp: 51.520<br />country: Botswana\",\"country: Botswana<br />year: 1967<br />lifeExp: 53.298<br />country: Botswana\",\"country: Botswana<br />year: 1972<br />lifeExp: 56.024<br />country: Botswana\",\"country: Botswana<br />year: 1977<br />lifeExp: 59.319<br />country: Botswana\",\"country: Botswana<br />year: 1982<br />lifeExp: 61.484<br />country: Botswana\",\"country: Botswana<br />year: 1987<br />lifeExp: 63.622<br />country: Botswana\",\"country: Botswana<br />year: 1992<br />lifeExp: 62.745<br />country: Botswana\",\"country: Botswana<br />year: 1997<br />lifeExp: 52.556<br />country: Botswana\",\"country: Botswana<br />year: 2002<br />lifeExp: 46.634<br />country: Botswana\",\"country: Botswana<br />year: 2007<br />lifeExp: 50.728<br />country: Botswana\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":6.4251968503937,\"color\":\"rgba(143,29,30,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Botswana\",\"legendgroup\":\"Botswana\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[42.138,45.047,47.747,48.492,49.767,52.208,55.078,57.18,59.685,55.558,44.593,42.592],\"text\":[\"country: Lesotho<br />year: 1952<br />lifeExp: 42.138<br />country: Lesotho\",\"country: Lesotho<br />year: 1957<br />lifeExp: 45.047<br />country: Lesotho\",\"country: Lesotho<br />year: 1962<br />lifeExp: 47.747<br />country: Lesotho\",\"country: Lesotho<br />year: 1967<br />lifeExp: 48.492<br />country: Lesotho\",\"country: Lesotho<br />year: 1972<br />lifeExp: 49.767<br />country: Lesotho\",\"country: Lesotho<br />year: 1977<br />lifeExp: 52.208<br />country: Lesotho\",\"country: Lesotho<br />year: 1982<br />lifeExp: 55.078<br />country: Lesotho\",\"country: Lesotho<br />year: 1987<br />lifeExp: 57.180<br />country: Lesotho\",\"country: Lesotho<br />year: 1992<br />lifeExp: 59.685<br />country: Lesotho\",\"country: Lesotho<br />year: 1997<br />lifeExp: 55.558<br />country: Lesotho\",\"country: Lesotho<br />year: 2002<br />lifeExp: 44.593<br />country: Lesotho\",\"country: Lesotho<br />year: 2007<br />lifeExp: 42.592<br />country: Lesotho\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":6.4251968503937,\"color\":\"rgba(214,0,43,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Lesotho\",\"legendgroup\":\"Lesotho\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[40,41.5,43,44.1,44.6,45,46.218,44.02,23.599,36.087,43.413,46.242],\"text\":[\"country: Rwanda<br />year: 1952<br />lifeExp: 40.000<br />country: Rwanda\",\"country: Rwanda<br />year: 1957<br />lifeExp: 41.500<br />country: Rwanda\",\"country: Rwanda<br />year: 1962<br />lifeExp: 43.000<br />country: Rwanda\",\"country: Rwanda<br />year: 1967<br />lifeExp: 44.100<br />country: Rwanda\",\"country: Rwanda<br />year: 1972<br />lifeExp: 44.600<br />country: Rwanda\",\"country: Rwanda<br />year: 1977<br />lifeExp: 45.000<br />country: Rwanda\",\"country: Rwanda<br />year: 1982<br />lifeExp: 46.218<br />country: Rwanda\",\"country: Rwanda<br />year: 1987<br />lifeExp: 44.020<br />country: Rwanda\",\"country: Rwanda<br />year: 1992<br />lifeExp: 23.599<br />country: Rwanda\",\"country: Rwanda<br />year: 1997<br />lifeExp: 36.087<br />country: Rwanda\",\"country: Rwanda<br />year: 2002<br />lifeExp: 43.413<br />country: Rwanda\",\"country: Rwanda<br />year: 2007<br />lifeExp: 46.242<br />country: Rwanda\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":6.4251968503937,\"color\":\"rgba(255,169,11,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Rwanda\",\"legendgroup\":\"Rwanda\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[41.407,43.424,44.992,46.633,49.552,52.537,55.561,57.678,58.474,54.289,43.869,39.613],\"text\":[\"country: Swaziland<br />year: 1952<br />lifeExp: 41.407<br />country: Swaziland\",\"country: Swaziland<br />year: 1957<br />lifeExp: 43.424<br />country: Swaziland\",\"country: Swaziland<br />year: 1962<br />lifeExp: 44.992<br />country: Swaziland\",\"country: Swaziland<br />year: 1967<br />lifeExp: 46.633<br />country: Swaziland\",\"country: Swaziland<br />year: 1972<br />lifeExp: 49.552<br />country: Swaziland\",\"country: Swaziland<br />year: 1977<br />lifeExp: 52.537<br />country: Swaziland\",\"country: Swaziland<br />year: 1982<br />lifeExp: 55.561<br />country: Swaziland\",\"country: Swaziland<br />year: 1987<br />lifeExp: 57.678<br />country: Swaziland\",\"country: Swaziland<br />year: 1992<br />lifeExp: 58.474<br />country: Swaziland\",\"country: Swaziland<br />year: 1997<br />lifeExp: 54.289<br />country: Swaziland\",\"country: Swaziland<br />year: 2002<br />lifeExp: 43.869<br />country: Swaziland\",\"country: Swaziland<br />year: 2007<br />lifeExp: 39.613<br />country: Swaziland\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":6.4251968503937,\"color\":\"rgba(204,171,116,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Swaziland\",\"legendgroup\":\"Swaziland\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[42.038,44.077,46.023,47.768,50.107,51.386,51.821,50.821,46.1,40.238,39.193,42.384],\"text\":[\"country: Zambia<br />year: 1952<br />lifeExp: 42.038<br />country: Zambia\",\"country: Zambia<br />year: 1957<br />lifeExp: 44.077<br />country: Zambia\",\"country: Zambia<br />year: 1962<br />lifeExp: 46.023<br />country: Zambia\",\"country: Zambia<br />year: 1967<br />lifeExp: 47.768<br />country: Zambia\",\"country: Zambia<br />year: 1972<br />lifeExp: 50.107<br />country: Zambia\",\"country: Zambia<br />year: 1977<br />lifeExp: 51.386<br />country: Zambia\",\"country: Zambia<br />year: 1982<br />lifeExp: 51.821<br />country: Zambia\",\"country: Zambia<br />year: 1987<br />lifeExp: 50.821<br />country: Zambia\",\"country: Zambia<br />year: 1992<br />lifeExp: 46.100<br />country: Zambia\",\"country: Zambia<br />year: 1997<br />lifeExp: 40.238<br />country: Zambia\",\"country: Zambia<br />year: 2002<br />lifeExp: 39.193<br />country: Zambia\",\"country: Zambia<br />year: 2007<br />lifeExp: 42.384<br />country: Zambia\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":6.4251968503937,\"color\":\"rgba(0,57,156,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Zambia\",\"legendgroup\":\"Zambia\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"x\":[1952,1957,1962,1967,1972,1977,1982,1987,1992,1997,2002,2007],\"y\":[48.451,50.469,52.358,53.995,55.635,57.674,60.363,62.351,60.377,46.809,39.989,43.487],\"text\":[\"country: Zimbabwe<br />year: 1952<br />lifeExp: 48.451<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1957<br />lifeExp: 50.469<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1962<br />lifeExp: 52.358<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1967<br />lifeExp: 53.995<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1972<br />lifeExp: 55.635<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1977<br />lifeExp: 57.674<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1982<br />lifeExp: 60.363<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1987<br />lifeExp: 62.351<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1992<br />lifeExp: 60.377<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 1997<br />lifeExp: 46.809<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 2002<br />lifeExp: 39.989<br />country: Zimbabwe\",\"country: Zimbabwe<br />year: 2007<br />lifeExp: 43.487<br />country: Zimbabwe\"],\"type\":\"scatter\",\"mode\":\"lines\",\"line\":{\"width\":6.4251968503937,\"color\":\"rgba(0,0,0,1)\",\"dash\":\"solid\"},\"hoveron\":\"points\",\"name\":\"Zimbabwe\",\"legendgroup\":\"Zimbabwe\",\"showlegend\":true,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"name\":\"Botswana\",\"legendgroup\":\"Botswana\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"name\":\"Lesotho\",\"legendgroup\":\"Lesotho\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"name\":\"Rwanda\",\"legendgroup\":\"Rwanda\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"name\":\"Swaziland\",\"legendgroup\":\"Swaziland\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"name\":\"Zambia\",\"legendgroup\":\"Zambia\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"name\":\"Zimbabwe\",\"legendgroup\":\"Zimbabwe\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null},{\"visible\":false,\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"hoverinfo\":\"text\",\"frame\":null}],\"layout\":{\"margin\":{\"t\":27.8721461187215,\"r\":7.30593607305936,\"b\":41.8264840182648,\"l\":37.2602739726027},\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187},\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[1948.85,2018.15],\"tickmode\":\"array\",\"ticktext\":[\"1960\",\"1980\",\"2000\"],\"tickvals\":[1960,1980,2000],\"categoryorder\":\"array\",\"categoryarray\":[\"1960\",\"1980\",\"2000\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"y\",\"title\":{\"text\":\"year\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"type\":\"linear\",\"autorange\":false,\"range\":[20.6488,85.5532],\"tickmode\":\"array\",\"ticktext\":[\"40\",\"60\",\"80\"],\"tickvals\":[40,60,80],\"categoryorder\":\"array\",\"categoryarray\":[\"40\",\"60\",\"80\"],\"nticks\":null,\"ticks\":\"\",\"tickcolor\":null,\"ticklen\":3.65296803652968,\"tickwidth\":0,\"showticklabels\":true,\"tickfont\":{\"color\":\"rgba(77,77,77,1)\",\"family\":\"\",\"size\":11.689497716895},\"tickangle\":-0,\"showline\":false,\"linecolor\":null,\"linewidth\":0,\"showgrid\":true,\"gridcolor\":\"rgba(235,235,235,1)\",\"gridwidth\":0.66417600664176,\"zeroline\":false,\"anchor\":\"x\",\"title\":{\"text\":\"Life Expectancy at Birth\",\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":14.6118721461187}},\"hoverformat\":\".2f\"},\"shapes\":[{\"type\":\"rect\",\"fillcolor\":null,\"line\":{\"color\":null,\"width\":0,\"linetype\":[]},\"yref\":\"paper\",\"xref\":\"paper\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}],\"showlegend\":true,\"legend\":{\"bgcolor\":null,\"bordercolor\":null,\"borderwidth\":0,\"font\":{\"color\":\"rgba(0,0,0,1)\",\"family\":\"\",\"size\":11.689497716895},\"y\":1},\"hovermode\":\"closest\",\"barmode\":\"relative\"},\"config\":{\"doubleClick\":\"reset\",\"showSendToCloud\":false},\"source\":\"A\",\"attrs\":{\"687061760f99\":{\"x\":{},\"y\":{},\"type\":\"scatter\"},\"68704507d645\":{\"colour\":{},\"x\":{},\"y\":{}},\"687058648f20\":{\"label\":{},\"colour\":{},\"x\":{},\"y\":{}},\"68703d281fd8\":{\"x\":{}}},\"cur_data\":\"687061760f99\",\"visdat\":{\"687061760f99\":[\"function (y) \",\"x\"],\"68704507d645\":[\"function (y) \",\"x\"],\"687058648f20\":[\"function (y) \",\"x\"],\"68703d281fd8\":[\"function (y) \",\"x\"]},\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nThe downward slope of our highlighted countries starting in the 1990s is a result of the ravaging AIDS pandemic. The prominent dips in two of the curves, orange for Rwanda and Cambodia in gray, are the direct consequences of genocides. These dire realities can in no way be summarized in just a couple of colorful lines. I am also in no way qualified to lecture on these topics. A good friend of mine, Timothy Williams, however is a researcher and teacher in the field of conflict and violence with a focus on genocides. He did field work in Cambodia and Rwanda and his book “The Complexity of Evil. Perpetration and Genocide” will be published here on December 18 (Williams, n.d.).\nAdvanced dplyr\nLast but not least, I want to mention a powerful advanced function in dplyr to make your data transformations even more efficient. It is the across function, which we can use inside of dplyr verbs such as mutate and summarise to use one or multiple functions on multiple columns. Let’s look at an example, again with the gapminder dataset. Now, this is sort of a silly example, but let’s say we want the continents and countries in UPPERCASE. We could do:\n\n\ngapminder %>% \n  mutate(\n    continent = str_to_upper(continent),\n    country = str_to_upper(country)\n  )\n\n\n# A tibble: 1,704 x 6\n   continent country  year lifeExp      pop gdpPercap\n   <chr>     <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 AFRICA    ALGERIA  1952    43.1  9279525     2449.\n 2 AFRICA    ALGERIA  1957    45.7 10270856     3014.\n 3 AFRICA    ALGERIA  1962    48.3 11000948     2551.\n 4 AFRICA    ALGERIA  1967    51.4 12760499     3247.\n 5 AFRICA    ALGERIA  1972    54.5 14760787     4183.\n 6 AFRICA    ALGERIA  1977    58.0 17152804     4910.\n 7 AFRICA    ALGERIA  1982    61.4 20033753     5745.\n 8 AFRICA    ALGERIA  1987    65.8 23254956     5681.\n 9 AFRICA    ALGERIA  1992    67.7 26298373     5023.\n10 AFRICA    ALGERIA  1997    69.2 29072015     4797.\n# … with 1,694 more rows\n\nAnd now everyone is really shouty. But we had some repetition in our code. Wouldn’t it be cool, to just say: “Apply the function str_to_upper to these columns.”\n\n\ngapminder %>% \n  mutate(\n    across(c(continent, country), str_to_upper)\n  )\n\n\n# A tibble: 1,704 x 6\n   continent country  year lifeExp      pop gdpPercap\n   <chr>     <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 AFRICA    ALGERIA  1952    43.1  9279525     2449.\n 2 AFRICA    ALGERIA  1957    45.7 10270856     3014.\n 3 AFRICA    ALGERIA  1962    48.3 11000948     2551.\n 4 AFRICA    ALGERIA  1967    51.4 12760499     3247.\n 5 AFRICA    ALGERIA  1972    54.5 14760787     4183.\n 6 AFRICA    ALGERIA  1977    58.0 17152804     4910.\n 7 AFRICA    ALGERIA  1982    61.4 20033753     5745.\n 8 AFRICA    ALGERIA  1987    65.8 23254956     5681.\n 9 AFRICA    ALGERIA  1992    67.7 26298373     5023.\n10 AFRICA    ALGERIA  1997    69.2 29072015     4797.\n# … with 1,694 more rows\n\nNot that is raw power! We can be even more general and ask R to apply the function to all columns that contain text:\n\n\ngapminder %>% \n  mutate(\n    across(where(is.character), str_to_upper)\n  )\n\n\n# A tibble: 1,704 x 6\n   continent country  year lifeExp      pop gdpPercap\n   <chr>     <chr>   <dbl>   <dbl>    <dbl>     <dbl>\n 1 AFRICA    ALGERIA  1952    43.1  9279525     2449.\n 2 AFRICA    ALGERIA  1957    45.7 10270856     3014.\n 3 AFRICA    ALGERIA  1962    48.3 11000948     2551.\n 4 AFRICA    ALGERIA  1967    51.4 12760499     3247.\n 5 AFRICA    ALGERIA  1972    54.5 14760787     4183.\n 6 AFRICA    ALGERIA  1977    58.0 17152804     4910.\n 7 AFRICA    ALGERIA  1982    61.4 20033753     5745.\n 8 AFRICA    ALGERIA  1987    65.8 23254956     5681.\n 9 AFRICA    ALGERIA  1992    67.7 26298373     5023.\n10 AFRICA    ALGERIA  1997    69.2 29072015     4797.\n# … with 1,694 more rows\n\nIt also works with summarise, for example to create summaries across a range of columns. And we can supply more than one function to calculate using a named list:\n\n\ngapminder %>% \n  summarise(\n    across(year:gdpPercap, list(mean = mean, total = sum))\n  )\n\n\n# A tibble: 1 x 8\n  year_mean year_total lifeExp_mean lifeExp_total pop_mean pop_total\n      <dbl>      <dbl>        <dbl>         <dbl>    <dbl>     <dbl>\n1     1980.    3373068         59.5       101344.   2.96e7   5.04e10\n# … with 2 more variables: gdpPercap_mean <dbl>,\n#   gdpPercap_total <dbl>\n\nYou are on you way to becoming a true data wizard! After today, you should be familiar with:\nimporting data into R\nthe concept of tidy data\nthe grammar of graphics\nthe basic dplyr verbs for data wrangling\na project-based workflow\nwriting and using functions\nWe will then use these foundations to experience statistical concepts ourselves in the next lectures.\nExercises\nThe whole Deal\nI want to get you playing around with data, so keep in mind that the solutions for this exercise are not set in stone. There is often more than one viable way of graphing the same dataset and we will use the Office Hour to talk about the advantages and disadvantages of approaches that you came up with.\nRoman emperors\nThe first exercise uses a dataset about roman emperors from the tidytuesday project (link). You can import it with:\n\n\nemperors <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-08-13/emperors.csv\")\n\n\n\nHere are a couple of questions to answer. Decide for yourselves if a particular question is best answered using a visualization, a table or a simple sentence.\nWhat was the most popular way to rise to power?\nI what are the most common causes of death among roman emperors, what (or who) killed them?\nWhich dynasty was the most successful?\nFirstly, how often did each dynasty reign?\nSecondly, how long where the reigns?\nWhich dynasty would you rather be a part of, if your goal is to live the longest?\n\nDairy Products in the US\nAnother dataset (link) concerns dairy product consumption per person in the US across a number of years. Load it with\n\n\ndairy <- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-01-29/milk_products_facts.csv\")\n\n\n\nAll masses are given in lbs (pounds), can you convert them to kg?\nWhich products lost their customer base over time, which ones won?\nAbove all, have some fun! If you make interesting findings along the way, go ahead and produce plots to highlight it.\nResources\npurrr documentation\nstringr documentation\ndplyr documentation\n\n\n\nWickham, Hadley. 2015. R Packages: Organize, Test, Document, and Share Your Code. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\nWilliams, Timothy. n.d. “The Complexity of Evil.” Rutgers University Press.\n\n\n\n\n",
    "preview": "lectures/lecture4/lecture4_files/figure-html5/unnamed-chunk-18-1.png",
    "last_modified": "2020-11-23T01:37:17+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "lectures/lecture3/",
    "title": "Lecture 3",
    "description": "... in which we explore the concept of Tidy Data, learn more\nadvanced data wrangling techniques and get a sneak peak at\niteration.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-14",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nTidy data\nWhat and Why is Tidy Data?\nMaking Data Tidy\npivot_wider\nseparate\nleft_join\npivot_longer\nunite\nAnother Example\n\nMore Shapes for Data\nNested Data\n\nA Sneak Peak at Iteration\n\nExercises\nTidy Data\nFunctions and Iteration\n\nResources\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen. Press ? for a list of keyboard shortcuts.\n\n\nknitr::include_url(\"slides3.html\")\n\n\n\n\n\nScript\nTidy data\nWhat and Why is Tidy Data?\nThere is one concept which also lends it’s name to the tidyverse that I want to talk about. Tidy Data is a way of turning your datasets into a uniform shape. This makes it easier to develop and work with tools because we get a consistent interface. Once you know how to turn any dataset into a tidy dataset, you are on home turf and can express your ideas more fluently in code. Getting there can sometimes be tricky, but I will give you the most important tools. Because…\n\n»Tidy datasets are all alike, but every messy dataset is messy in its own way.« — Hadley Wickham\n\nfreely adapted from:\n\n»Happy families are all alike; every unhappy family is unhappy in its own way.« — Leo Tolstoy\n\nSo, how can we recognize tidy data?\n\n\n\n\nFigure 1: Figure from https://r4ds.had.co.nz/tidy-data.html (Wickham and Grolemund 2017)\n\n\n\nIn tidy data, each variable (feature) forms it’s own column. Each observation forms a row. And each cell is a single value (measurement). Furthermore, information about the same things belongs in one table.\nThe tidyr package contained in the tidyverse provides small example datasets to demonstrate what this means in practice. Hadley Wickham and Garrett Grolemund use these in their book as well (https://r4ds.had.co.nz/tidy-data.html)(Wickham and Grolemund 2017).\ntable1, table2, table3, table4a, table4b, and table5 all display the number of TB cases documented by the World Health Organization in Afghanistan, Brazil, and China between 1999 and 2000. The first of these is in the tidy format, the others are not:\n\n\nlibrary(tidyverse)\n\n# The paged_table function from the rmarkdown package prints the tables\n# for the rmarkdown html document format so that it looks nice in the script.\n# Alternatively you could use\n# knitr's kable function\npaged_table(table1)\n\n\n\n\n{\"columns\":[{\"label\":[\"country\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"year\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"cases\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"population\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"1999\",\"3\":\"745\",\"4\":\"19987071\"},{\"1\":\"Afghanistan\",\"2\":\"2000\",\"3\":\"2666\",\"4\":\"20595360\"},{\"1\":\"Brazil\",\"2\":\"1999\",\"3\":\"37737\",\"4\":\"172006362\"},{\"1\":\"Brazil\",\"2\":\"2000\",\"3\":\"80488\",\"4\":\"174504898\"},{\"1\":\"China\",\"2\":\"1999\",\"3\":\"212258\",\"4\":\"1272915272\"},{\"1\":\"China\",\"2\":\"2000\",\"3\":\"213766\",\"4\":\"1280428583\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nThis nicely qualifies as tidy data. Every row is uniquely identified by the country and year, and all other columns are properties of the specific country in this specific year.\n\n\npaged_table(table2)\n\n\n\n\n{\"columns\":[{\"label\":[\"country\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"year\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"type\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"count\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"1999\",\"3\":\"cases\",\"4\":\"745\"},{\"1\":\"Afghanistan\",\"2\":\"1999\",\"3\":\"population\",\"4\":\"19987071\"},{\"1\":\"Afghanistan\",\"2\":\"2000\",\"3\":\"cases\",\"4\":\"2666\"},{\"1\":\"Afghanistan\",\"2\":\"2000\",\"3\":\"population\",\"4\":\"20595360\"},{\"1\":\"Brazil\",\"2\":\"1999\",\"3\":\"cases\",\"4\":\"37737\"},{\"1\":\"Brazil\",\"2\":\"1999\",\"3\":\"population\",\"4\":\"172006362\"},{\"1\":\"Brazil\",\"2\":\"2000\",\"3\":\"cases\",\"4\":\"80488\"},{\"1\":\"Brazil\",\"2\":\"2000\",\"3\":\"population\",\"4\":\"174504898\"},{\"1\":\"China\",\"2\":\"1999\",\"3\":\"cases\",\"4\":\"212258\"},{\"1\":\"China\",\"2\":\"1999\",\"3\":\"population\",\"4\":\"1272915272\"},{\"1\":\"China\",\"2\":\"2000\",\"3\":\"cases\",\"4\":\"213766\"},{\"1\":\"China\",\"2\":\"2000\",\"3\":\"population\",\"4\":\"1280428583\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nNow it gets interesting. table2 still looks organized, but it is not tidy (by our definition). Note, this doesn’t say the format is useless — it has it’s places — but it will not fit in as snugly with our tools. The column type is not a feature of the country, rather the actual features are hidden in that column with their values in the count column. In order to make it tidy, this dataset would need to get wider.\n\n\npaged_table(table3)\n\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"country\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"year\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"rate\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"1999\",\"3\":\"745/19987071\",\"_rn_\":\"1\"},{\"1\":\"Afghanistan\",\"2\":\"2000\",\"3\":\"2666/20595360\",\"_rn_\":\"2\"},{\"1\":\"Brazil\",\"2\":\"1999\",\"3\":\"37737/172006362\",\"_rn_\":\"3\"},{\"1\":\"Brazil\",\"2\":\"2000\",\"3\":\"80488/174504898\",\"_rn_\":\"4\"},{\"1\":\"China\",\"2\":\"1999\",\"3\":\"212258/1272915272\",\"_rn_\":\"5\"},{\"1\":\"China\",\"2\":\"2000\",\"3\":\"213766/1280428583\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nIn table3, two features are jammed into one column. This is annoying, because we can’t easily calculate with the values; they are stored as text and separated by a slash like cases/population. Ideally, we would want to separate this column into two.\n\n\npaged_table(table4a)\n\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"country\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"1999\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"2000\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"745\",\"3\":\"2666\",\"_rn_\":\"1\"},{\"1\":\"Brazil\",\"2\":\"37737\",\"3\":\"80488\",\"_rn_\":\"2\"},{\"1\":\"China\",\"2\":\"212258\",\"3\":\"213766\",\"_rn_\":\"3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\n\n\npaged_table(table4b)\n\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"country\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"1999\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"2000\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"19987071\",\"3\":\"20595360\",\"_rn_\":\"1\"},{\"1\":\"Brazil\",\"2\":\"172006362\",\"3\":\"174504898\",\"_rn_\":\"2\"},{\"1\":\"China\",\"2\":\"1272915272\",\"3\":\"1280428583\",\"_rn_\":\"3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\ntable4a and table4b split the data into two different tables, which again makes it harder to calculate with. This data is so closely related, we would want it in one table. And another principle of tidy data is violated. Notice the column names? 1999 is not a feature that Afghanistan can have. Rather, it is the value for a feature (namely the year), while the values in the 1999 column are in fact values for the feature population (in table4a) and cases (in table4b).\n\n\npaged_table(table5)\n\n\n\n\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"country\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"century\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"year\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"rate\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"Afghanistan\",\"2\":\"19\",\"3\":\"99\",\"4\":\"745/19987071\",\"_rn_\":\"1\"},{\"1\":\"Afghanistan\",\"2\":\"20\",\"3\":\"00\",\"4\":\"2666/20595360\",\"_rn_\":\"2\"},{\"1\":\"Brazil\",\"2\":\"19\",\"3\":\"99\",\"4\":\"37737/172006362\",\"_rn_\":\"3\"},{\"1\":\"Brazil\",\"2\":\"20\",\"3\":\"00\",\"4\":\"80488/174504898\",\"_rn_\":\"4\"},{\"1\":\"China\",\"2\":\"19\",\"3\":\"99\",\"4\":\"212258/1272915272\",\"_rn_\":\"5\"},{\"1\":\"China\",\"2\":\"20\",\"3\":\"00\",\"4\":\"213766/1280428583\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nIn table5, we have the same problem as in table3 and additionally the opposite problem! This time, feature that should be one column (namely year) is spread across two columns (century and year). What we want to do is unite those into one.\nMaking Data Tidy\n\n\n\n\n\nwith the tidyr package.\n\nNote: I do not go over data is better in another format in this course. Examples for this might involve matrices to benefit from matrix math or their multidimensional equivalent: arrays.\n\nLet’s make some data tidy!\npivot_wider\nStarting with table2, which wants to be wider. Accordingly, we use the function pivot_wider. It is very powerful, but the two most important arguments (well, after the data) are which column contains the names of the new columns and which column contains the values of the newly created columns as shown below.\n\n\ntable2 %>% \n  pivot_wider(names_from = type, values_from = count)\n\n\n# A tibble: 6 x 4\n  country      year  cases population\n  <chr>       <int>  <int>      <int>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\nseparate\nTo make table3 tidy, we need the separate function, followed by mutate to get the new columns into the correct datatype. Run it yourself step by step to see why the mutate afterwards is necessary.\n\n\ntable3 %>% \n  separate(rate, into = c(\"cases\", \"population\"), sep = \"/\") %>% \n  mutate(cases = parse_number(cases),\n         population = parse_number(population))\n\n\n# A tibble: 6 x 4\n  country      year  cases population\n  <chr>       <int>  <dbl>      <dbl>\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\nThe parse_ functions come from readr. Parsing is the act of turning raw text into usable data, and the parse_number function does a particularly good job at extracting numbers, where the naïve approach of as.numeric might fail e.g.\n\n\nsome_text = \"take my number: 12\"\nas.numeric(some_text)\n\n\n[1] NA\n\n\n\nparse_number(some_text)\n\n\n[1] 12\n\nleft_join\nNow is the time to join table4a and tabl4b together. For this, we need an operation known from databases as a join. In fact, this whole concept of tidy data is closely related to databases and something called Codd`s normal forms (Codd 1990; Wickham 2014) so I am throwing these references in here just in case you are interested in the theoretical foundations. But without further ado:\n\n\n# the suffix argument is necessary because the columns\n# in the two tables have the same names\ntable4 <- left_join(table4a, table4b, by = \"country\",\n                    suffix = c(\"_cases\", \"_population\"))\ntable4\n\n\n# A tibble: 3 x 5\n  country  `1999_cases` `2000_cases` `1999_populatio… `2000_populatio…\n  <chr>           <int>        <int>            <int>            <int>\n1 Afghani…          745         2666         19987071         20595360\n2 Brazil          37737        80488        172006362        174504898\n3 China          212258       213766       1272915272       1280428583\n\npivot_longer\nNow we can deal with the next problem: Making the table longer so that year, population and cases become their own columns again, because they are independent features. Consequently, we use the function pivot_longer:\n\n\n# note that cols takes what is called a tidyselect specification.\n# you know this from the selection function and it's help page.\n# here, I am selecting everything BUT the country column.\nlong_table4 <- table4 %>% \n  pivot_longer(cols = -country)\nlong_table4\n\n\n# A tibble: 12 x 3\n   country     name                 value\n   <chr>       <chr>                <int>\n 1 Afghanistan 1999_cases             745\n 2 Afghanistan 2000_cases            2666\n 3 Afghanistan 1999_population   19987071\n 4 Afghanistan 2000_population   20595360\n 5 Brazil      1999_cases           37737\n 6 Brazil      2000_cases           80488\n 7 Brazil      1999_population  172006362\n 8 Brazil      2000_population  174504898\n 9 China       1999_cases          212258\n10 China       2000_cases          213766\n11 China       1999_population 1272915272\n12 China       2000_population 1280428583\n\nBut we are not done yet, table4 is putting all our skills to the test. There is a way to do the following steps with pivot_wider straight away, but doing it step by step should be easier to follow. You can revisit this part and check out the other arguments to pivot_wider if you fancy a challenge. The next step we already know: separating a column into two. Only the separator changed.\n\n\nlong_table4_separated <- long_table4 %>% \n  separate(col = name, into = c(\"year\", \"type\"), sep = \"_\")\nlong_table4_separated\n\n\n# A tibble: 12 x 4\n   country     year  type            value\n   <chr>       <chr> <chr>           <int>\n 1 Afghanistan 1999  cases             745\n 2 Afghanistan 2000  cases            2666\n 3 Afghanistan 1999  population   19987071\n 4 Afghanistan 2000  population   20595360\n 5 Brazil      1999  cases           37737\n 6 Brazil      2000  cases           80488\n 7 Brazil      1999  population  172006362\n 8 Brazil      2000  population  174504898\n 9 China       1999  cases          212258\n10 China       2000  cases          213766\n11 China       1999  population 1272915272\n12 China       2000  population 1280428583\n\nNow we are back to the problem we had in table2, so we know how to make this table wider again:\n\n\nlong_table4_separated %>% \n  pivot_wider(names_from = type, values_from = value)\n\n\n# A tibble: 6 x 4\n  country     year   cases population\n  <chr>       <chr>  <int>      <int>\n1 Afghanistan 1999     745   19987071\n2 Afghanistan 2000    2666   20595360\n3 Brazil      1999   37737  172006362\n4 Brazil      2000   80488  174504898\n5 China       1999  212258 1272915272\n6 China       2000  213766 1280428583\n\nWe did it! Now one last look at table5, which contains a case we haven’t encountered yet: a feature is separated across two columns, so we need the opposite of separeate: unite.\nunite\n\n\ntable5 %>% \n  unite(col = year, c(century, year), sep = \"\") %>% \n  mutate(year = parse_number(year))\n\n\n# A tibble: 6 x 3\n  country      year rate             \n  <chr>       <dbl> <chr>            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\nAnother Example\nLet us look at one last example of data that needs tidying, which is also provided by the tidyr package as an example:\n\n\nhead(billboard) %>% paged_table()\n\n\n\n\n{\"columns\":[{\"label\":[\"artist\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"track\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"date.entered\"],\"name\":[3],\"type\":[\"date\"],\"align\":[\"right\"]},{\"label\":[\"wk1\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk2\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk3\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk4\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk5\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk6\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk7\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk8\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk9\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk10\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk11\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk12\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk13\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk14\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk15\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk16\"],\"name\":[19],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk17\"],\"name\":[20],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk18\"],\"name\":[21],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk19\"],\"name\":[22],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk20\"],\"name\":[23],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk21\"],\"name\":[24],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk22\"],\"name\":[25],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk23\"],\"name\":[26],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk24\"],\"name\":[27],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk25\"],\"name\":[28],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk26\"],\"name\":[29],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk27\"],\"name\":[30],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk28\"],\"name\":[31],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk29\"],\"name\":[32],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk30\"],\"name\":[33],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk31\"],\"name\":[34],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk32\"],\"name\":[35],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk33\"],\"name\":[36],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk34\"],\"name\":[37],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk35\"],\"name\":[38],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk36\"],\"name\":[39],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk37\"],\"name\":[40],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk38\"],\"name\":[41],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk39\"],\"name\":[42],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk40\"],\"name\":[43],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk41\"],\"name\":[44],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk42\"],\"name\":[45],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk43\"],\"name\":[46],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk44\"],\"name\":[47],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk45\"],\"name\":[48],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk46\"],\"name\":[49],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk47\"],\"name\":[50],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk48\"],\"name\":[51],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk49\"],\"name\":[52],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk50\"],\"name\":[53],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk51\"],\"name\":[54],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk52\"],\"name\":[55],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk53\"],\"name\":[56],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk54\"],\"name\":[57],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk55\"],\"name\":[58],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk56\"],\"name\":[59],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk57\"],\"name\":[60],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk58\"],\"name\":[61],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk59\"],\"name\":[62],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk60\"],\"name\":[63],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk61\"],\"name\":[64],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk62\"],\"name\":[65],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk63\"],\"name\":[66],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk64\"],\"name\":[67],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk65\"],\"name\":[68],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wk66\"],\"name\":[69],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk67\"],\"name\":[70],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk68\"],\"name\":[71],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk69\"],\"name\":[72],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk70\"],\"name\":[73],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk71\"],\"name\":[74],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk72\"],\"name\":[75],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk73\"],\"name\":[76],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk74\"],\"name\":[77],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk75\"],\"name\":[78],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"wk76\"],\"name\":[79],\"type\":[\"lgl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"2000-02-26\",\"4\":\"87\",\"5\":\"82\",\"6\":\"72\",\"7\":\"77\",\"8\":\"87\",\"9\":\"94\",\"10\":\"99\",\"11\":\"NA\",\"12\":\"NA\",\"13\":\"NA\",\"14\":\"NA\",\"15\":\"NA\",\"16\":\"NA\",\"17\":\"NA\",\"18\":\"NA\",\"19\":\"NA\",\"20\":\"NA\",\"21\":\"NA\",\"22\":\"NA\",\"23\":\"NA\",\"24\":\"NA\",\"25\":\"NA\",\"26\":\"NA\",\"27\":\"NA\",\"28\":\"NA\",\"29\":\"NA\",\"30\":\"NA\",\"31\":\"NA\",\"32\":\"NA\",\"33\":\"NA\",\"34\":\"NA\",\"35\":\"NA\",\"36\":\"NA\",\"37\":\"NA\",\"38\":\"NA\",\"39\":\"NA\",\"40\":\"NA\",\"41\":\"NA\",\"42\":\"NA\",\"43\":\"NA\",\"44\":\"NA\",\"45\":\"NA\",\"46\":\"NA\",\"47\":\"NA\",\"48\":\"NA\",\"49\":\"NA\",\"50\":\"NA\",\"51\":\"NA\",\"52\":\"NA\",\"53\":\"NA\",\"54\":\"NA\",\"55\":\"NA\",\"56\":\"NA\",\"57\":\"NA\",\"58\":\"NA\",\"59\":\"NA\",\"60\":\"NA\",\"61\":\"NA\",\"62\":\"NA\",\"63\":\"NA\",\"64\":\"NA\",\"65\":\"NA\",\"66\":\"NA\",\"67\":\"NA\",\"68\":\"NA\",\"69\":\"NA\",\"70\":\"NA\",\"71\":\"NA\",\"72\":\"NA\",\"73\":\"NA\",\"74\":\"NA\",\"75\":\"NA\",\"76\":\"NA\",\"77\":\"NA\",\"78\":\"NA\",\"79\":\"NA\"},{\"1\":\"2Ge+her\",\"2\":\"The Hardest Part Of ...\",\"3\":\"2000-09-02\",\"4\":\"91\",\"5\":\"87\",\"6\":\"92\",\"7\":\"NA\",\"8\":\"NA\",\"9\":\"NA\",\"10\":\"NA\",\"11\":\"NA\",\"12\":\"NA\",\"13\":\"NA\",\"14\":\"NA\",\"15\":\"NA\",\"16\":\"NA\",\"17\":\"NA\",\"18\":\"NA\",\"19\":\"NA\",\"20\":\"NA\",\"21\":\"NA\",\"22\":\"NA\",\"23\":\"NA\",\"24\":\"NA\",\"25\":\"NA\",\"26\":\"NA\",\"27\":\"NA\",\"28\":\"NA\",\"29\":\"NA\",\"30\":\"NA\",\"31\":\"NA\",\"32\":\"NA\",\"33\":\"NA\",\"34\":\"NA\",\"35\":\"NA\",\"36\":\"NA\",\"37\":\"NA\",\"38\":\"NA\",\"39\":\"NA\",\"40\":\"NA\",\"41\":\"NA\",\"42\":\"NA\",\"43\":\"NA\",\"44\":\"NA\",\"45\":\"NA\",\"46\":\"NA\",\"47\":\"NA\",\"48\":\"NA\",\"49\":\"NA\",\"50\":\"NA\",\"51\":\"NA\",\"52\":\"NA\",\"53\":\"NA\",\"54\":\"NA\",\"55\":\"NA\",\"56\":\"NA\",\"57\":\"NA\",\"58\":\"NA\",\"59\":\"NA\",\"60\":\"NA\",\"61\":\"NA\",\"62\":\"NA\",\"63\":\"NA\",\"64\":\"NA\",\"65\":\"NA\",\"66\":\"NA\",\"67\":\"NA\",\"68\":\"NA\",\"69\":\"NA\",\"70\":\"NA\",\"71\":\"NA\",\"72\":\"NA\",\"73\":\"NA\",\"74\":\"NA\",\"75\":\"NA\",\"76\":\"NA\",\"77\":\"NA\",\"78\":\"NA\",\"79\":\"NA\"},{\"1\":\"3 Doors Down\",\"2\":\"Kryptonite\",\"3\":\"2000-04-08\",\"4\":\"81\",\"5\":\"70\",\"6\":\"68\",\"7\":\"67\",\"8\":\"66\",\"9\":\"57\",\"10\":\"54\",\"11\":\"53\",\"12\":\"51\",\"13\":\"51\",\"14\":\"51\",\"15\":\"51\",\"16\":\"47\",\"17\":\"44\",\"18\":\"38\",\"19\":\"28\",\"20\":\"22\",\"21\":\"18\",\"22\":\"18\",\"23\":\"14\",\"24\":\"12\",\"25\":\"7\",\"26\":\"6\",\"27\":\"6\",\"28\":\"6\",\"29\":\"5\",\"30\":\"5\",\"31\":\"4\",\"32\":\"4\",\"33\":\"4\",\"34\":\"4\",\"35\":\"3\",\"36\":\"3\",\"37\":\"3\",\"38\":\"4\",\"39\":\"5\",\"40\":\"5\",\"41\":\"9\",\"42\":\"9\",\"43\":\"15\",\"44\":\"14\",\"45\":\"13\",\"46\":\"14\",\"47\":\"16\",\"48\":\"17\",\"49\":\"21\",\"50\":\"22\",\"51\":\"24\",\"52\":\"28\",\"53\":\"33\",\"54\":\"42\",\"55\":\"42\",\"56\":\"49\",\"57\":\"NA\",\"58\":\"NA\",\"59\":\"NA\",\"60\":\"NA\",\"61\":\"NA\",\"62\":\"NA\",\"63\":\"NA\",\"64\":\"NA\",\"65\":\"NA\",\"66\":\"NA\",\"67\":\"NA\",\"68\":\"NA\",\"69\":\"NA\",\"70\":\"NA\",\"71\":\"NA\",\"72\":\"NA\",\"73\":\"NA\",\"74\":\"NA\",\"75\":\"NA\",\"76\":\"NA\",\"77\":\"NA\",\"78\":\"NA\",\"79\":\"NA\"},{\"1\":\"3 Doors Down\",\"2\":\"Loser\",\"3\":\"2000-10-21\",\"4\":\"76\",\"5\":\"76\",\"6\":\"72\",\"7\":\"69\",\"8\":\"67\",\"9\":\"65\",\"10\":\"55\",\"11\":\"59\",\"12\":\"62\",\"13\":\"61\",\"14\":\"61\",\"15\":\"59\",\"16\":\"61\",\"17\":\"66\",\"18\":\"72\",\"19\":\"76\",\"20\":\"75\",\"21\":\"67\",\"22\":\"73\",\"23\":\"70\",\"24\":\"NA\",\"25\":\"NA\",\"26\":\"NA\",\"27\":\"NA\",\"28\":\"NA\",\"29\":\"NA\",\"30\":\"NA\",\"31\":\"NA\",\"32\":\"NA\",\"33\":\"NA\",\"34\":\"NA\",\"35\":\"NA\",\"36\":\"NA\",\"37\":\"NA\",\"38\":\"NA\",\"39\":\"NA\",\"40\":\"NA\",\"41\":\"NA\",\"42\":\"NA\",\"43\":\"NA\",\"44\":\"NA\",\"45\":\"NA\",\"46\":\"NA\",\"47\":\"NA\",\"48\":\"NA\",\"49\":\"NA\",\"50\":\"NA\",\"51\":\"NA\",\"52\":\"NA\",\"53\":\"NA\",\"54\":\"NA\",\"55\":\"NA\",\"56\":\"NA\",\"57\":\"NA\",\"58\":\"NA\",\"59\":\"NA\",\"60\":\"NA\",\"61\":\"NA\",\"62\":\"NA\",\"63\":\"NA\",\"64\":\"NA\",\"65\":\"NA\",\"66\":\"NA\",\"67\":\"NA\",\"68\":\"NA\",\"69\":\"NA\",\"70\":\"NA\",\"71\":\"NA\",\"72\":\"NA\",\"73\":\"NA\",\"74\":\"NA\",\"75\":\"NA\",\"76\":\"NA\",\"77\":\"NA\",\"78\":\"NA\",\"79\":\"NA\"},{\"1\":\"504 Boyz\",\"2\":\"Wobble Wobble\",\"3\":\"2000-04-15\",\"4\":\"57\",\"5\":\"34\",\"6\":\"25\",\"7\":\"17\",\"8\":\"17\",\"9\":\"31\",\"10\":\"36\",\"11\":\"49\",\"12\":\"53\",\"13\":\"57\",\"14\":\"64\",\"15\":\"70\",\"16\":\"75\",\"17\":\"76\",\"18\":\"78\",\"19\":\"85\",\"20\":\"92\",\"21\":\"96\",\"22\":\"NA\",\"23\":\"NA\",\"24\":\"NA\",\"25\":\"NA\",\"26\":\"NA\",\"27\":\"NA\",\"28\":\"NA\",\"29\":\"NA\",\"30\":\"NA\",\"31\":\"NA\",\"32\":\"NA\",\"33\":\"NA\",\"34\":\"NA\",\"35\":\"NA\",\"36\":\"NA\",\"37\":\"NA\",\"38\":\"NA\",\"39\":\"NA\",\"40\":\"NA\",\"41\":\"NA\",\"42\":\"NA\",\"43\":\"NA\",\"44\":\"NA\",\"45\":\"NA\",\"46\":\"NA\",\"47\":\"NA\",\"48\":\"NA\",\"49\":\"NA\",\"50\":\"NA\",\"51\":\"NA\",\"52\":\"NA\",\"53\":\"NA\",\"54\":\"NA\",\"55\":\"NA\",\"56\":\"NA\",\"57\":\"NA\",\"58\":\"NA\",\"59\":\"NA\",\"60\":\"NA\",\"61\":\"NA\",\"62\":\"NA\",\"63\":\"NA\",\"64\":\"NA\",\"65\":\"NA\",\"66\":\"NA\",\"67\":\"NA\",\"68\":\"NA\",\"69\":\"NA\",\"70\":\"NA\",\"71\":\"NA\",\"72\":\"NA\",\"73\":\"NA\",\"74\":\"NA\",\"75\":\"NA\",\"76\":\"NA\",\"77\":\"NA\",\"78\":\"NA\",\"79\":\"NA\"},{\"1\":\"98^0\",\"2\":\"Give Me Just One Nig...\",\"3\":\"2000-08-19\",\"4\":\"51\",\"5\":\"39\",\"6\":\"34\",\"7\":\"26\",\"8\":\"26\",\"9\":\"19\",\"10\":\"2\",\"11\":\"2\",\"12\":\"3\",\"13\":\"6\",\"14\":\"7\",\"15\":\"22\",\"16\":\"29\",\"17\":\"36\",\"18\":\"47\",\"19\":\"67\",\"20\":\"66\",\"21\":\"84\",\"22\":\"93\",\"23\":\"94\",\"24\":\"NA\",\"25\":\"NA\",\"26\":\"NA\",\"27\":\"NA\",\"28\":\"NA\",\"29\":\"NA\",\"30\":\"NA\",\"31\":\"NA\",\"32\":\"NA\",\"33\":\"NA\",\"34\":\"NA\",\"35\":\"NA\",\"36\":\"NA\",\"37\":\"NA\",\"38\":\"NA\",\"39\":\"NA\",\"40\":\"NA\",\"41\":\"NA\",\"42\":\"NA\",\"43\":\"NA\",\"44\":\"NA\",\"45\":\"NA\",\"46\":\"NA\",\"47\":\"NA\",\"48\":\"NA\",\"49\":\"NA\",\"50\":\"NA\",\"51\":\"NA\",\"52\":\"NA\",\"53\":\"NA\",\"54\":\"NA\",\"55\":\"NA\",\"56\":\"NA\",\"57\":\"NA\",\"58\":\"NA\",\"59\":\"NA\",\"60\":\"NA\",\"61\":\"NA\",\"62\":\"NA\",\"63\":\"NA\",\"64\":\"NA\",\"65\":\"NA\",\"66\":\"NA\",\"67\":\"NA\",\"68\":\"NA\",\"69\":\"NA\",\"70\":\"NA\",\"71\":\"NA\",\"72\":\"NA\",\"73\":\"NA\",\"74\":\"NA\",\"75\":\"NA\",\"76\":\"NA\",\"77\":\"NA\",\"78\":\"NA\",\"79\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\nThis is a lot of columns! For 76 weeks after a song entered the top 100 (I assume in the USA) it’s position is recorded. It might be in this format because it made data entry easier, or the previous person wanted to make plots in excel, where this wide format is used to denote multiple traces. In any event, for our style of visualizations with the grammar of graphics, we want a column to represent a feature, so this data needs to get longer:\n\n\nlong_billboard <- billboard %>% \n  pivot_longer(starts_with(\"w\"),\n               names_to = \"week\",\n               names_pattern = \"wk(\\\\d+)\",\n               values_to = \"placement\",\n               values_drop_na = TRUE) %>% \n  mutate(week = parse_integer(week),\n         date = as.Date(date.entered) + 7 * (week - 1)) %>% \n  select(-date.entered)\n\nlong_billboard %>% \n  head() %>% \n  paged_table()\n\n\n\n\n{\"columns\":[{\"label\":[\"artist\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"track\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"week\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"placement\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"date\"],\"name\":[5],\"type\":[\"date\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"1\",\"4\":\"87\",\"5\":\"2000-02-26\"},{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"2\",\"4\":\"82\",\"5\":\"2000-03-04\"},{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"3\",\"4\":\"72\",\"5\":\"2000-03-11\"},{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"4\",\"4\":\"77\",\"5\":\"2000-03-18\"},{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"5\",\"4\":\"87\",\"5\":\"2000-03-25\"},{\"1\":\"2 Pac\",\"2\":\"Baby Don't Cry (Keep...\",\"3\":\"6\",\"4\":\"94\",\"5\":\"2000-04-01\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  \n\n\nThis time I am leaving the visualisation up to you. This is a greate opportunity to play around with ggplot!\n\nThis whole tidy data idea might seem like just another way of moving numbers around. But once you build the mental model for it, it will truly transform the way you are able to think about data. Both for data wrangling with dplyr, as shown last week, and also for data visualization with ggplot, a journey we began in the first week and that is still well underway.\nMore Shapes for Data\nThe tidyr package provides more tools for dealing with data in various shapes. We just discovered the first set of operations called pivoting to get a feel for tidy data and to obtain it from various formats. But data is not always rectangular like we can show it in a spreadsheet. Sometimes data already comes in a nested form, sometimes we create nested data because it serves our purpose (see next week). So, what do I mean by nested?\nNested Data\nRemember that lists can contain elements of any type, even other lists? Well, if have have a list that contains more lists, we call it nested. E.g.\n\n\nlist(\n  c(1, 2),\n  list(\n    42, list(\"hi\", TRUE)\n  )\n)\n\n\n[[1]]\n[1] 1 2\n\n[[2]]\n[[2]][[1]]\n[1] 42\n\n[[2]][[2]]\n[[2]][[2]][[1]]\n[1] \"hi\"\n\n[[2]][[2]][[2]]\n[1] TRUE\n\nBut nested list are not always fun to work with, and when there is a straightforward way to represent the same data in a rectangular, flat format, we most likely want to do that. We will deal with data rectangling today was well. But first, there is another implication of nested lists: Because dataframes (and tibbles) are built on top of lists, we can nest them to! This can sometimes come in really handy. We a dataframe contains a column that is not an atomic vector but a list (so it is a list in a list), we call it a list column:\n\n\nexample <- tibble(\n  x = 1:3,\n  y = list(\"hello\", TRUE, c(1,2,3,4))\n)\nexample\n\n\n# A tibble: 3 x 2\n      x y        \n  <int> <list>   \n1     1 <chr [1]>\n2     2 <lgl [1]>\n3     3 <dbl [4]>\n\nHere, the output in our code only tells us, that the list column y contains an atomic character vector of length 1, a logical vector of length 1 and a double vector of length 4. The overall length of the column is 3, because it has to fit in the tibble.\nWe can get a better view of what is in there by either pulling the column out with the subsetting functions we already learned (like $, [[]], pull), using str to learn more about the structure or simply using RStudio’s Environment panel to inspect our variable. Click on the name to view it in a new window (the same can be done from code by using the function View or Ctrl+Clicking the variable name) or use the little blue arrow to expand the list.\n\n\ninclude_graphics(\"img/environment.png\")\n\n\n\n\nThis extends even further, we are about to go full inception on this! A list column can contain tibbles (/dataframes) as well!\n\n\nnested_tibble <- tibble(\n  id = 1:2,\n  df = list(\n    tibble(x = 1:10, y = x^2),\n    tibble(x = seq(1, 100, 3), y = sqrt(x))\n  )\n)\n\nnested_tibble\n\n\n# A tibble: 2 x 2\n     id df               \n  <int> <list>           \n1     1 <tibble [10 × 2]>\n2     2 <tibble [34 × 2]>\n\nWe can still use the data nested in there, as long as we remember how to chain our subsetting functions together.\n\n\n# take the column df, take the second element\nnested_tibble$df[[2]]\n\n\n# A tibble: 34 x 2\n       x     y\n   <dbl> <dbl>\n 1     1  1   \n 2     4  2   \n 3     7  2.65\n 4    10  3.16\n 5    13  3.61\n 6    16  4   \n 7    19  4.36\n 8    22  4.69\n 9    25  5   \n10    28  5.29\n# … with 24 more rows\n\nA handy way to subsett into nested structures is with the pluck function:\n\n\nnested_tibble %>% pluck(\"df\", 2)\n\n\n# A tibble: 34 x 2\n       x     y\n   <dbl> <dbl>\n 1     1  1   \n 2     4  2   \n 3     7  2.65\n 4    10  3.16\n 5    13  3.61\n 6    16  4   \n 7    19  4.36\n 8    22  4.69\n 9    25  5   \n10    28  5.29\n# … with 24 more rows\n\n\n\nnested_tibble$df[[2]] %>% \n  ggplot(aes(x, y)) +\n  geom_line() +\n  geom_point() + \n  theme_minimal()\n\n\n\n\nThis will be incredibly useful next week, when we talk about iteration.\nCreating a tibble by hand is unlikely going to be the way that you end up with a nested tibble. Let’s create one from an already existing tibble. We can use the long version of the billboard dataset we created above.\n\n\nnested_billboard <- long_billboard %>% \n  nest(data = c(-artist, -track))\n\nhead(nested_billboard)\n\n\n# A tibble: 6 x 3\n  artist       track                   data             \n  <chr>        <chr>                   <list>           \n1 2 Pac        Baby Don't Cry (Keep... <tibble [7 × 3]> \n2 2Ge+her      The Hardest Part Of ... <tibble [3 × 3]> \n3 3 Doors Down Kryptonite              <tibble [53 × 3]>\n4 3 Doors Down Loser                   <tibble [20 × 3]>\n5 504 Boyz     Wobble Wobble           <tibble [18 × 3]>\n6 98^0         Give Me Just One Nig... <tibble [20 × 3]>\n\nNotice, how similar this is to group_by, except it is much more explicit. The resulting groups are now separated into their own tibble in the list column I named data. Again, RStudio’s environment panel makes it easier to inspect the data.\nWe can get back to our original shape by unnesting the tibble\n\n\nnested_billboard %>% \n  unnest(data) %>% \n  head()\n\n\n# A tibble: 6 x 5\n  artist track                    week placement date      \n  <chr>  <chr>                   <int>     <dbl> <date>    \n1 2 Pac  Baby Don't Cry (Keep...     1        87 2000-02-26\n2 2 Pac  Baby Don't Cry (Keep...     2        82 2000-03-04\n3 2 Pac  Baby Don't Cry (Keep...     3        72 2000-03-11\n4 2 Pac  Baby Don't Cry (Keep...     4        77 2000-03-18\n5 2 Pac  Baby Don't Cry (Keep...     5        87 2000-03-25\n6 2 Pac  Baby Don't Cry (Keep...     6        94 2000-04-01\n\nUnnesting is one special case for the general idea of data rectangling, for which the tidyr package provides more functions. Unfortunately, we can’t all explore them all today.\nA Sneak Peak at Iteration\nNext week we are going to explore the concept of iteration, having R do one operation for multiple things. But today, I am already giving you a sneak peak at how nested data can help us in that respect. It will also make sure you get more comfortable with writing functions.\nLet us take just one dataset out of the many datasets:\n\n\none_track <- nested_billboard$data[[1]]\none_track\n\n\n# A tibble: 7 x 3\n   week placement date      \n  <int>     <dbl> <date>    \n1     1        87 2000-02-26\n2     2        82 2000-03-04\n3     3        72 2000-03-11\n4     4        77 2000-03-18\n5     5        87 2000-03-25\n6     6        94 2000-04-01\n7     7        99 2000-04-08\n\nThis contains the performance of one song. we can create a plot of it:\n\n\nggplot(one_track, aes(week, placement)) +\n  geom_line() +\n  theme_linedraw()\n\n\n\n\nMoreover, we can create a function, that takes some data and creates a plot from it:\n\n\nplot_song_performance <- function(song_data) {\n  ggplot(song_data, aes(week, placement)) +\n    geom_line() +\n    theme_linedraw()\n}\n\n\n\nWe can now pass any song data from the nested dataframe to it:\n\n\nplot_song_performance(nested_billboard$data[[1]])\n\n\n\n\nBut we are more ambitious, we want this plot for all songs! The map function from the purrr package takes a list and a function and applies the function to all elements of the list. It is really powerful (and fun). We will learn all about it next week, but here is a preview:\n\n\n\n\n\n\n\nsong_performance <- nested_billboard %>% \n   mutate(\n      plt = map(data, plot_song_performance)\n   )\n\nsong_performance %>% head()\n\n\n# A tibble: 6 x 4\n  artist       track                   data              plt   \n  <chr>        <chr>                   <list>            <list>\n1 2 Pac        Baby Don't Cry (Keep... <tibble [7 × 3]>  <gg>  \n2 2Ge+her      The Hardest Part Of ... <tibble [3 × 3]>  <gg>  \n3 3 Doors Down Kryptonite              <tibble [53 × 3]> <gg>  \n4 3 Doors Down Loser                   <tibble [20 × 3]> <gg>  \n5 504 Boyz     Wobble Wobble           <tibble [18 × 3]> <gg>  \n6 98^0         Give Me Just One Nig... <tibble [20 × 3]> <gg>  \n\nAnd now we can look at individual plots:\n\n\nsong_performance$plt[[24]]\n\n\n\n\nIt might have been handy to include a title for the plot, so let’s modify our plotting function a little bit:\n\n\nplot_song_performance <- function(song_data, title) {\n  ggplot(song_data, aes(week, placement)) +\n    geom_line() +\n    theme_linedraw() +\n    labs(title = title)\n}\n\n\n\nAnd now we use the function map2 instead of map, which iterates over two vectors at the same time to also pass the plot title:\n\n\nsong_performance <- nested_billboard %>% \n   mutate(\n      plt = map2(data, track,  plot_song_performance)\n   )\n\nsong_performance$plt[[1]]\n\n\n\n\nWhen we don’t care about the return value of a function, but rather about the side-effect it has, we use the walk function in place of map. A side-effect is anything that changes the state of your program or the world around it, as opposed to pure functions, which only depend on their arguments return some value. Writing to a file for example is a side effect:\n\n\ndir.create(\"plts\")\n\nsave_plot <- function(name, plot) {\n  ggsave(paste0(\"plts/\", name, \".png\"), plot)\n}\n\nwalk2(song_performance$track, song_performance$plt, save_plot)\n\n\n\nDo try this at home, it feels quite good to achieve so much with one key-press!\nExercises\nTidy Data\nImagine for a second this whole pandemic thing is not going on and we are planning a vacation. Of course, we want to choose the safest airline possible, so we download data about incident reports. You can find it in the data folder1.\nInstead of the type_of_event and n_events columns we would like to have one column per type of event, where the values are the count for this event.\nWhich airlines had the least fatal accidents, standardized to the distance theses airlines covered, in the two time ranges?\nEven if something where to go wrong, which airlines have the best record when it comes to fatalities per fatal accident?\nCreate an informative plot to highlight your discoveries. It might be beneficial to only plot e.g. the highest or lowest scoring Airlines. One of the slice_ functions will help you there. And to make your plot prettier, you will have to look into fct_reorder again.\nFunctions and Iteration\nYou are going strong so far! Programming can sometimes be frustrating, so I think what we need is someone to motivate us. R is up to the task. Write a function that takes a name, like “Jannik” or your name, and spits out a motivational message that includes the name. Make sure to also test it and show that it works.\nNow that you have a motivational machine, you need to make sure to motivate the greatest amount of people. Use the map function to apply your function to a whole vector of names.\nResources\ntidyr documentation\npurrr documentation\nstringr documentation for working with text and a helpful cheatsheet for the regular expressions mentioned in the video\n\n\n\nCodd, E. F. 1990. The Relational Model for Database Management: Version 2. USA: Addison-Wesley Longman Publishing Co., Inc.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (1): 1–23. https://doi.org/10.18637/jss.v059.i10.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\nsource: tidytuesday↩︎\n",
    "preview": "lectures/lecture3/img/tidy-data-wickham.png",
    "last_modified": "2020-11-15T23:31:53+01:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 600
  },
  {
    "path": "lectures/lecture2/",
    "title": "Lecture 2",
    "description": "... in which we explore the typical data analysis workflow\nwith the tidyverse, wrangle different kinds of data and\nlearn about factors.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-07",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nMaking Ourselves at Home in RStudio\nImportant Settings\nA Project-based Workflow\nWorking in Style\n\nA Data Analysis Workflow\nReading Data with readr\nCommon Hurdles when Importing Data\n\nWrangling Data with dplyr\nselect\nfilter\nmutate\nInterlude: Begind the magic, handling data with base-R\nThe pipe %>%\narrange\nsummarise\ngroup_by\n\nVisualization and our First Encounter with factors\n\nExercises\nResources\nPackage Documentation\nGetting Help\n\n\nVideo\n\n\nSlides\n\n\n\n\nScript\n\nNote:\nI try to be vocal about what the code does in plain English while I type it and learning the “translations” of symbols and keywords can help you, too. After a while, programming can feel a lot more like having a conversation with your digital assistant or a helpful friend. The boundary between human languages and computer languages is more blurry than you might think.\n\nBefore we get deeper into R, let’s talk a little bit about our Home when working with R: RStudio.\nMaking Ourselves at Home in RStudio\nImportant Settings\nI highlighted 3 settings that I consider important to change from their default values. The first two might seem odd at first glance.\n\n\n\nThe workspace that RStudio would save as .RData contains all objects created in a session, which is, what we can see in the Environment pane (by default in the top right panel, bottom right in my setup). Why would we not want to load the objects we created in the last session into our current session automatically? The reason is reproducibility. We want to make sure that everything our analysis needs is in the script. It creates our variables and plots from the raw data and should be the sole source of truth. Given the raw data and the script, everyone should be able to reproduce our results. The third setting (text encoding) is also concerned with collaboration. It makes sure that our text files and special characters in them (like German umlauts) look the same on different operating systems like Windows, iOS and Linux.\nA Project-based Workflow\nLast week we simply went ahead and created a script file and an Rmarkdown file in some folder on our computer. But how does R known, where the script is? How does it know, where to look, when we tell it to read in a file or save a plot? The main folder where R starts is called the working directory. To find out, what our current working directory is, we execute the function getwd() for get working directory:\n\n\ngetwd()\n\n\n[1] \"/home/jannik/Documents/projects/teaching/dataIntro20/_lectures/lecture2\"\n\nThis will look slightly different depending on you operating system. The next function I want you to know, but never use:\n\n\nsetwd(\"some/file/path\")\n\n\n\n“Why should I not use it?” you might ask. Let’s assume I use the function to set the working directory as seen above:\n\n\nsetwd(\"/home/jannik/Documents/projects/teaching/dataIntro20/_lectures/lecture2\")\n\n\n\nNow, when I give the file to you to test my analysis, chances are very low that it would work. Because you are likely not called Jannik and even more likely don’t have the same folder structure that I had.\nSo what we want instead of these absolute file paths, is a relative file paths that start in the folder that our scripts are in. This is what RStudio Projects are for. It is basically just a folder with a special file that ends in .Rproj, but as soon as R finds this file in the folder, the working directory will automatically be this folder. So when you share this folder, it will still just work.\nGo ahead and use the blue R button in the top right corner to create a New Project. I recommend you do this either as one project for the whole course or with one project per week. Projects are also convenient because they save what files you had open and so forth.\nThere is one thing I didn’t tell you about Rmarkdown documents, yet. Their working directory is always the folder they are in, even if they are in some subdirectory of a project. In a way this also means that you don’t necessarily need a project to work with Rmarkdown, but having one anyway makes it easier to keep track of your files and have a consistent structure.\nWorking in Style\nNow that we have a cosy project for today, let’s also make sure we are working in style and are feeling right at home in RStudio. This blogpost provides excellent gifs for the different settings in RStudio and even for Rmarkdown troubleshooting. I am also fond of the rsthemes package for additional appearances.\nA Data Analysis Workflow\nWe are getting close to importing our very first dataset from a file into R. Generally, this is the first thing that needs to happen with any data analysis and we will cover it today. The data I provided is already pretty tidy so we will start with that and build some visualizations. The communicate-part is also covered, because we are working in Rmarkdown after all, which is designed to communicate our findings. Later, we will also have a look at some less tidy data, but not before having defined what “tidy data” is.\n\n\n\n\nFigure 1: Figure from Wickham and Grolemund (2017).\n\n\n\nReading Data with readr\n\n\n\n\n\nThe package responsible for loading data in the tidyverse is called readr, so we start by loading the whole tidyverse.\nNote, that in general, we could also load just the readr package with library(readr), but we need the rest of the tidyverse later on anyways. There is also the option to not load a package at all but rather only use one function from a package by prefixing the function with the package name and two colons (::) Like so: readr::read_csv(\"...\").\n\n\nlibrary(tidyverse)\n\n\n\nWithout further ado, let’s download the data for today. In fact, there are multiple ways to go about this. We could download the whole course folder from GitHub by following the link in the top right corner of this website and then using the download button:\n\n\n\nYou will then find the data in the folder ./_lectures/lecture2/data/.\nOr we can navigate to the file on GitHub. Follow this link: files, click on one of the files and then click on raw:\n\n\n\nFrom there you can copy the link displayed in your browser address field and download the file straight from R:\n\n\ndownload.file(\"https://raw.githubusercontent.com/jmbuhr/dataIntro20/master/_lectures/lecture2/data/gapminder.csv\",\n              \"data/gapminder.csv\")\n\n\n\nThe folder to download your data to (./data) must be created in advance. This is an example for a relative path (an absolute path would start with / or a drive letter like C:).\nNow we can finally load in the data and store it in a variable. When working with file paths, RStudio’s autocompletion is especially helpful. We can trigger it with Tab or Ctrl+Space.\n\n\ngapminder <- read_csv(\"data/gapminder.csv\")\n\n\n\nreadr will also tell you the datatypes it guessed for the columns. Let’s inspect our dataset:\n\n\ngapminder\n\n\n# A tibble: 1,704 x 6\n   country     continent  year lifeExp      pop gdpPercap\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# … with 1,694 more rows\n\nThe gapminder dataset (Bryan 2017) is an excerpt from the gapminder project and contains the life expectancy at birth for 142 countries at 5 year intervals between 1952 and 2007. It also contains the population and the Gross Domestic Product (GDP) per Inhabitant. We will built a visualization later on.\nread_csv can even read data from a url straight away, without the need for us to download the file ourselves, but we usually want a copy of the data locally. For the curious run this:\n\n\nread_csv(\"https://raw.githubusercontent.com/jmbuhr/dataIntro20/master/_lectures/lecture2/data/gapminder.csv\")\n\n\n\nSo, this all went smoothly. But this will not always be the case. We will now look at common hurdles when importing data\nCommon Hurdles when Importing Data\nThe function we just used was called read_csv, because it reads a file format that consists of comma separated values. Look at the raw file in a text editor (not word) like notepad or RStudio to see why. But the file extension .csv can sometimes be lying…\nBecause in German, the comma is used to separate decimal numbers (vs. the dot in English), a lot of Software will output a different type of csv-file when configured in German. It will still call it csv, but actually it is separated by semicolons! We have a special function for this:\n\n\nread_csv2(\"data/gapminder_csv2.csv\")\n\n\n\nWhen looking through the autocompletion options that pop up when you are typing the function name, you might have noticed a similar function read.csv and read.csv2. These are the functions that come with R, without any packages like the tidyverse. You can of course use those as well, but the tidyverse functions provide a more consistent experience and have less surprising quirks. I am teaching the tidyverse first, because it allows you to do more while having to learn less edge cases.\nIf we look at yet another file data/gapminder_tsv.txt, we notice that the file extension doesn’t tell us much about the format, only that it is text (as opposed to a binary format only computers can read). If we look into the file:\n\n\nread_lines(\"data/gapminder_tsv.txt\", n_max = 3)\n\n\n[1] \"country\\tcontinent\\tyear\\tlifeExp\\tpop\\tgdpPercap\"    \n[2] \"Afghanistan\\tAsia\\t1952\\t28.801\\t8425333\\t779.4453145\"\n[3] \"Afghanistan\\tAsia\\t1957\\t30.332\\t9240934\\t820.8530296\"\n\nWe notice that the values are separated by \", a special sequence that stands for the tab character. The read_tsv function will do the job.\nIf the separator (also called delimiter) is even more obscure, we can use the general function read_delim. Say a co-worker misunderstood us and thought tsv stands for “Tilde separated values,” we can still read his file.\n\n\nread_lines(\"data/obscure_file.tsv\", n_max = 3)\n\n\n[1] \"country~continent~year~lifeExp~pop~gdpPercap\"    \n[2] \"Afghanistan~Asia~1952~28.801~8425333~779.4453145\"\n[3] \"Afghanistan~Asia~1957~30.332~9240934~820.8530296\"\n\n\n\nread_delim(\"data/obscure_file.tsv\", delim = \"~\")\n\n\n\nThere are more ways in which raw data can be messy or hard to read depending on the machine but I can’t show all of them. One common thing you will encounter though is measurement machines writing some additional information in the first couple of lines before the actual data (like the time of the measurement). In this example:\n\n\nread_lines(\"data/gapminder_messier.csv\", n_max = 4)\n\n\n[1] \"# Some comment about the data\"                   \n[2] \"And maybe a personal note\"                       \n[3] \"country,continent,year,lifeExp,pop,gdpPercap\"    \n[4] \"Afghanistan,Asia,1952,28.801,8425333,779.4453145\"\n\nThe first 2 lines are not part of the data. Reading the file normally as a csv would produce something weird: Because the first line does not contain any commata, it will assume that the file contains only one column and also report a bunch of parsing failures. Parsing is the act of turning data represented as raw text into a useful format, like a table of numbers.\n\n\nread_csv(\"data/gapminder_messier.csv\", n_max = 3)\n\n\n# A tibble: 3 x 1\n  `# Some comment about the data`\n  <chr>                          \n1 And maybe a personal note      \n2 country                        \n3 Afghanistan                    \n\nWe can fix this by telling R to skip the first 2 lines entirely:\n\n\nread_csv(\"data/gapminder_messier.csv\", skip = 2, n_max = 3)\n\n\n# A tibble: 3 x 6\n  country     continent  year lifeExp      pop gdpPercap\n  <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n\nI was using the n_max argument of the functions above to save space in this lecture script.\nIn the video I forgot to mention that I also included an excel file to practice. We can read it using a function from the readxl package. This package is automatically installed with the tidyverse, but it is not loaded along with the other packages via library(tidyverse). We can either load it with library(readxl) or refer to a single function from the package without loading the whole thing using double colons (::):\n\n\nreadxl::read_xlsx(\"./data/gapminder.xlsx\")\n\n\n\nNow, that we learned about some of the ways in which raw data can be structured, let us go back to the original data that we read in and saved in the variable gapminder.\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.4453\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.8530\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.1007\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.1971\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.9811\nAfghanistan\nAsia\n1977\n38.438\n14880372\n786.1134\n\nWrangling Data with dplyr\n\n\n\n\n\nThere a are a number of ways in which we can manipulate data. Of course I mean manipulate in it’s original sense, not the malicious one. This is sometimes referred to as data wrangling and within the tidyverse, this is a job for the dplyr package (short for data plyer, the tool you see in the logo).\ndplyr provides functions for various operations on our data. Theses functions are sometimes also called dplyr verbs. All of them take a tibble or data.frame as input (plus additional parameters) and always return a tibble.\n\n\n\nFigure 2: (“Artwork by @allison_horst” 2020)\n\n\n\nselect\nThe first verb we introduce is used to select columns. And hence, it is called select. The first argument is always the data, followed by an arbitrary number of column names. We can recognize functions the take an arbitrary number of additional arguments by the ... in the autocompletion and help page.\n\n\nselect(gapminder, country, year, pop)\n\n\n# A tibble: 1,704 x 3\n   country      year      pop\n   <chr>       <dbl>    <dbl>\n 1 Afghanistan  1952  8425333\n 2 Afghanistan  1957  9240934\n 3 Afghanistan  1962 10267083\n 4 Afghanistan  1967 11537966\n 5 Afghanistan  1972 13079460\n 6 Afghanistan  1977 14880372\n 7 Afghanistan  1982 12881816\n 8 Afghanistan  1987 13867957\n 9 Afghanistan  1992 16317921\n10 Afghanistan  1997 22227415\n# … with 1,694 more rows\n\nIt might be confusing why we don’t need quotation marks around the column names like we do when we select and element from a vector by name as in:\n\n\nc(first = 1, second = 2)[\"first\"]\n\n\nfirst \n    1 \n\nThis concept is known as quasiquotation or data masking. It is quite unique to R, but it allows functions to known about the content of the data that is passed to them and use this as the environment in which they do their computations and search for variable names. So while the variable country doesn’t exist in the global environment, it does exist as a column of the gapminder tibble. dplyr functions always look in the data first when they search for names.\nThe help page for select tells us more about the different ways in which we can select columns. Here are a couple of examples without the output, rum them in your R session to confirm that they do what you think they do. (but do have a look at the help pages yourselves, they are quite well written).\n\n\nselect(gapminder, where(is.numeric))\nselect(gapminder, country:lifeExp)\nselect(gapminder, starts_with(\"c\"))\nselect(gapminder, c(1, 3, 4))\n\n\n\nfilter\n\n\n\nFigure 3: (“Artwork by @allison_horst” 2020)\n\n\n\nAfter selecting columns it is only natural to ask how to select rows. This is achieved with the function filter. For example, we can filter for all years smaller than 2000:\n\n\nfilter(gapminder, year < 2000)\n\n\n# A tibble: 1,420 x 6\n   country     continent  year lifeExp      pop gdpPercap\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# … with 1,410 more rows\n\nOr all the rows where the country is “New Zealand”:\n\n\nfilter(gapminder, country == \"New Zealand\")\n\n\n# A tibble: 12 x 6\n   country     continent  year lifeExp     pop gdpPercap\n   <chr>       <chr>     <dbl>   <dbl>   <dbl>     <dbl>\n 1 New Zealand Oceania    1952    69.4 1994794    10557.\n 2 New Zealand Oceania    1957    70.3 2229407    12247.\n 3 New Zealand Oceania    1962    71.2 2488550    13176.\n 4 New Zealand Oceania    1967    71.5 2728150    14464.\n 5 New Zealand Oceania    1972    71.9 2929100    16046.\n 6 New Zealand Oceania    1977    72.2 3164900    16234.\n 7 New Zealand Oceania    1982    73.8 3210650    17632.\n 8 New Zealand Oceania    1987    74.3 3317166    19007.\n 9 New Zealand Oceania    1992    76.3 3437674    18363.\n10 New Zealand Oceania    1997    77.6 3676187    21050.\n11 New Zealand Oceania    2002    79.1 3908037    23190.\n12 New Zealand Oceania    2007    80.2 4115771    25185.\n\nmutate\nWe are back at manipulating columns, this time by creating new ones or changing old ones. The dplyr verb that does that is called muate. For example, we might want to calculate the total GDP from the GDP per Capita and the population:\n\n\nmutate(gapminder, gdp = pop * gdpPercap)\n\n\n# A tibble: 1,704 x 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# … with 1,694 more rows\n\nNotice, that none of the functions changed the original variable gapminder. They only take an input and return and output, which makes it easier to reason about our code and later chain pieces of code together. How do you change it then? Use the Force! … ahem, I mean, the assignment operator (<-).\n\n\ngapminder <- mutate(gapminder, gdp = pop * gdpPercap)\n\n\n\nHere, the power of dplyr shines. It knows that pop and gdpPercap are columns of the tibble and that gdp refers to the new name of the freshly created column.\nInterlude: Begind the magic, handling data with base-R\nThis section is meant to show you what happens behind the scenes. It is not strictly necessary to understand all the details of it in order to work effectively with the tidyverse, but it helps especially when things don’t go as planned.\nSo let’s look into handling data with base-R. Last week we briefly covered subsetting of vectors by their indices, their names, or a logical vector:\n\n\nx <- c(42, 1, 13, 29)\nnames(x) <- c(\"first\", \"second\", \"third\", \"fourth\")\nx\n\n\n first second  third fourth \n    42      1     13     29 \n\n\n\nx[c(1,3)]\n\n\nfirst third \n   42    13 \n\n\n\nx[c(\"first\", \"second\")]\n\n\n first second \n    42      1 \n\n\n\nx[c(TRUE, FALSE, FALSE, TRUE)]\n\n\n first fourth \n    42     29 \n\nThis subsetting with a logical vector can be used to filter the vector:\n\n\nselect_this <- x < 20\nselect_this\n\n\n first second  third fourth \n FALSE   TRUE   TRUE  FALSE \n\n\n\nx[select_this]\n\n\nsecond  third \n     1     13 \n\nWith data in 2 dimensions, rows and columns, subsetting works similarly. Let’s use the function tibble to create a tibble from vectors:\n\n\nmy_data <- tibble(\n  x = c(42, 1, 13, 29),\n  y = c(1, 2, 3, 4),\n  z = c(\"z1\", \"z2\", \"z3\", \"z4\")\n)\nmy_data\n\n\n# A tibble: 4 x 3\n      x     y z    \n  <dbl> <dbl> <chr>\n1    42     1 z1   \n2     1     2 z2   \n3    13     3 z3   \n4    29     4 z4   \n\n\nNote:\nR is not whitespace sensitive (like python). That means indentation doesn’t change the meaning of the code. We can use this to format our code to look pretty, which is why I started a new line after the opening bracket of tibble(.\n\nSubsetting a tibble like a vector selects columns:\n\n\nmy_data[c(1, 3)]\n\n\n# A tibble: 4 x 2\n      x z    \n  <dbl> <chr>\n1    42 z1   \n2     1 z2   \n3    13 z3   \n4    29 z4   \n\nBut if you pass two arguments to the square brackets, separated by commata, we can filter rows and select columns Here, we get the first row in the second and third columns:\n\n\nmy_data[1, c(2, 3)]\n\n\n# A tibble: 1 x 2\n      y z    \n  <dbl> <chr>\n1     1 z1   \n\nIf we follow the logic above, we can also filter the data. The comma without any argument afterwards selects all columns.\n\n\nmy_data[my_data$x < 20, ]\n\n\n# A tibble: 2 x 3\n      x     y z    \n  <dbl> <dbl> <chr>\n1     1     2 z2   \n2    13     3 z3   \n\nAt first glance, the tidyverse way of doing the same is only a little bit shorter. But apart from the fact that we don’t have to repeat the name of the data object my_data (because filter knows where to look for x, whereas [] doesn’t), there is another advantage.\n\n\nfilter(my_data, x < 20)\n\n\n# A tibble: 2 x 3\n      x     y z    \n  <dbl> <dbl> <chr>\n1     1     2 z2   \n2    13     3 z3   \n\nThe pipe %>%\nThe tidyverse functions are easier to compose (i.e. chain together). To facilitate this, we introduce another operator, a bit like + for numbers or the + to add ggplot components, but specially for functions. The pipe, which you can either type or insert in RStudio with Ctrl+Shift+M, takes it’s left side and passes it as the first argument to the function on the right side:\n\n\nmy_data %>% select(x, z)\n\n\n# A tibble: 4 x 2\n      x z    \n  <dbl> <chr>\n1    42 z1   \n2     1 z2   \n3    13 z3   \n4    29 z4   \n\nAnd because all main tidyverse functions take data as their first argument, we can chain them together fluently. Additionally, it enables autocompletion of column names inside of the function that gets the data. So back to the gapminder example:\n\n\ngapminder %>% \n  filter(year > 2000) %>% \n  mutate(gdp = pop * gdpPercap) %>% \n  select(country, year, gdp)\n\n\n# A tibble: 284 x 3\n   country      year           gdp\n   <chr>       <dbl>         <dbl>\n 1 Afghanistan  2002  18363410424.\n 2 Afghanistan  2007  31079291949.\n 3 Albania      2002  16153932130.\n 4 Albania      2007  21376411360.\n 5 Algeria      2002 165447670333.\n 6 Algeria      2007 207444851958.\n 7 Angola       2002  30134833901.\n 8 Angola       2007  59583895818.\n 9 Argentina    2002 337223430800.\n10 Argentina    2007 515033625357.\n# … with 274 more rows\n\nIt also reads much nicer in your head, which makes reasoning about the code easier. Without telling you what the above code did, you can understand it, because it reads like English. You can often pronounce the pipe as “and then” in your head, or out-loud, I’m not judging.\n\nNote:\nThe base-R and the tidyverse way are not mutually exclusive. Sometimes you can mix and match.\n\narrange\nA simple thing you might want from a table is to sort it based on some column. This is what arrange does:\n\n\ngapminder %>% \n  arrange(year)\n\n\n# A tibble: 1,704 x 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.      6.57e 9\n 2 Albania     Europe     1952    55.2  1282697     1601.      2.05e 9\n 3 Algeria     Africa     1952    43.1  9279525     2449.      2.27e10\n 4 Angola      Africa     1952    30.0  4232095     3521.      1.49e10\n 5 Argentina   Americas   1952    62.5 17876956     5911.      1.06e11\n 6 Australia   Oceania    1952    69.1  8691212    10040.      8.73e10\n 7 Austria     Europe     1952    66.8  6927772     6137.      4.25e10\n 8 Bahrain     Asia       1952    50.9   120447     9867.      1.19e 9\n 9 Bangladesh  Asia       1952    37.5 46886859      684.      3.21e10\n10 Belgium     Europe     1952    68    8730405     8343.      7.28e10\n# … with 1,694 more rows\n\nThe helper function desc marks a column to be arranged in descending order. We can arrange by multiple columns, where the first will be most important.\n\n\ngapminder %>% \n  arrange(desc(year), pop) %>% \n  select(country, year, pop) %>% \n  rename(population = pop)\n\n\n# A tibble: 1,704 x 3\n   country                year population\n   <chr>                 <dbl>      <dbl>\n 1 Sao Tome and Principe  2007     199579\n 2 Iceland                2007     301931\n 3 Djibouti               2007     496374\n 4 Equatorial Guinea      2007     551201\n 5 Montenegro             2007     684736\n 6 Bahrain                2007     708573\n 7 Comoros                2007     710960\n 8 Reunion                2007     798094\n 9 Trinidad and Tobago    2007    1056608\n10 Swaziland              2007    1133066\n# … with 1,694 more rows\n\nI also introduced the rename verb without warning. It does what it says it does, only the order of the names might be confusing. The new name comes first (like when you are creating a new column with mutate). You can also rename within select:\n\n\ngapminder %>% select(country, year, population = pop)\n\n\n# A tibble: 1,704 x 3\n   country      year population\n   <chr>       <dbl>      <dbl>\n 1 Afghanistan  1952    8425333\n 2 Afghanistan  1957    9240934\n 3 Afghanistan  1962   10267083\n 4 Afghanistan  1967   11537966\n 5 Afghanistan  1972   13079460\n 6 Afghanistan  1977   14880372\n 7 Afghanistan  1982   12881816\n 8 Afghanistan  1987   13867957\n 9 Afghanistan  1992   16317921\n10 Afghanistan  1997   22227415\n# … with 1,694 more rows\n\nsummarise\nTo condense one or multiple columns into summary values, we use summarise: Like with mutate, we can calculate multiple things in one step.\n\n\ngapminder %>% \n  summarise(\n    last_year = max(year),\n    average_pop = mean(pop),\n    minimal_gdp = min(gdp)\n  )\n\n\n# A tibble: 1 x 3\n  last_year average_pop minimal_gdp\n      <dbl>       <dbl>       <dbl>\n1      2007   29601212.   52784691.\n\nBut condensing whole columns into one value, flattening the tibble in the style of Super Mario jumping on mushrooms, is often not what we need. We would rather know the summaries within certain groups. For example the maximal gdp per country. This is what group_by is for.\ngroup_by\ngroup_by is considered an adverb, because it doesn’t change the data itself but it changes how subsequent functions handle the data. For example, if a tibble has groups, all summaries are calculated within these groups:\n\n\ngapminder %>% \n  group_by(country)\n\n\n# A tibble: 1,704 x 7\n# Groups:   country [142]\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# … with 1,694 more rows\n\nFor example, let’s look at the range of the life expectancy for each country:\n\n\ngapminder %>% \n  group_by(country) %>% \n  summarise(lower_life_exp = min(lifeExp),\n            upper_life_exp = max(lifeExp))\n\n\n# A tibble: 142 x 3\n   country     lower_life_exp upper_life_exp\n   <chr>                <dbl>          <dbl>\n 1 Afghanistan           28.8           43.8\n 2 Albania               55.2           76.4\n 3 Algeria               43.1           72.3\n 4 Angola                30.0           42.7\n 5 Argentina             62.5           75.3\n 6 Australia             69.1           81.2\n 7 Austria               66.8           79.8\n 8 Bahrain               50.9           75.6\n 9 Bangladesh            37.5           64.1\n10 Belgium               68             79.4\n# … with 132 more rows\n\nsummarize removes one level of grouping. If the data was grouped by multiple features, this means that some groups remain. We can make sure that the data is no longer grouped with ungroup.\n\n\ngapminder %>% \n  group_by(continent, year) %>% \n  summarise(mean_gdpPercap = mean(gdpPercap)) %>% \n  ungroup()\n\n\n# A tibble: 60 x 3\n   continent  year mean_gdpPercap\n   <chr>     <dbl>          <dbl>\n 1 Africa     1952          1253.\n 2 Africa     1957          1385.\n 3 Africa     1962          1598.\n 4 Africa     1967          2050.\n 5 Africa     1972          2340.\n 6 Africa     1977          2586.\n 7 Africa     1982          2482.\n 8 Africa     1987          2283.\n 9 Africa     1992          2282.\n10 Africa     1997          2379.\n# … with 50 more rows\n\nGroups also work within mutate and filter. For example, we can get all rows where the gdp per Person was highest per country:\n\n\ngapminder %>%\n  group_by(country) %>% \n  filter(gdpPercap == max(gdpPercap))\n\n\n# A tibble: 142 x 7\n# Groups:   country [142]\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1982    39.9   1.29e7      978.      1.26e10\n 2 Albania     Europe     2007    76.4   3.60e6     5937.      2.14e10\n 3 Algeria     Africa     2007    72.3   3.33e7     6223.      2.07e11\n 4 Angola      Africa     1967    36.0   5.25e6     5523.      2.90e10\n 5 Argentina   Americas   2007    75.3   4.03e7    12779.      5.15e11\n 6 Australia   Oceania    2007    81.2   2.04e7    34435.      7.04e11\n 7 Austria     Europe     2007    79.8   8.20e6    36126.      2.96e11\n 8 Bahrain     Asia       2007    75.6   7.09e5    29796.      2.11e10\n 9 Bangladesh  Asia       2007    64.1   1.50e8     1391.      2.09e11\n10 Belgium     Europe     2007    79.4   1.04e7    33693.      3.50e11\n# … with 132 more rows\n\nOr we can use groups in mutate to find out, what percentage of it’s continent a country’s population makes up per year:\n\n\ngapminder %>% \n  group_by(continent, year) %>% \n  mutate(pctPop = pop / sum(pop) * 100)\n\n\n# A tibble: 1,704 x 8\n# Groups:   continent, year [60]\n   country   continent  year lifeExp     pop gdpPercap      gdp pctPop\n   <chr>     <chr>     <dbl>   <dbl>   <dbl>     <dbl>    <dbl>  <dbl>\n 1 Afghanis… Asia       1952    28.8  8.43e6      779.  6.57e 9  0.604\n 2 Afghanis… Asia       1957    30.3  9.24e6      821.  7.59e 9  0.591\n 3 Afghanis… Asia       1962    32.0  1.03e7      853.  8.76e 9  0.605\n 4 Afghanis… Asia       1967    34.0  1.15e7      836.  9.65e 9  0.605\n 5 Afghanis… Asia       1972    36.1  1.31e7      740.  9.68e 9  0.608\n 6 Afghanis… Asia       1977    38.4  1.49e7      786.  1.17e10  0.624\n 7 Afghanis… Asia       1982    39.9  1.29e7      978.  1.26e10  0.494\n 8 Afghanis… Asia       1987    40.8  1.39e7      852.  1.18e10  0.483\n 9 Afghanis… Asia       1992    41.7  1.63e7      649.  1.06e10  0.521\n10 Afghanis… Asia       1997    41.8  2.22e7      635.  1.41e10  0.657\n# … with 1,694 more rows\n\nSometimes you want to refer to the size of the current group inside of mutate or summarise. The function to to just that is called n(). For example, I wonder how many rows of data we have per year.\n\n\ngapminder %>% \n  group_by(year) %>% \n  summarise(n = n())\n\n\n# A tibble: 12 x 2\n    year     n\n   <dbl> <int>\n 1  1952   142\n 2  1957   142\n 3  1962   142\n 4  1967   142\n 5  1972   142\n 6  1977   142\n 7  1982   142\n 8  1987   142\n 9  1992   142\n10  1997   142\n11  2002   142\n12  2007   142\n\nA shortcut for group_by and summarise with n() is the count function:\n\n\ngapminder %>% \n  count(year)\n\n\n# A tibble: 12 x 2\n    year     n\n   <dbl> <int>\n 1  1952   142\n 2  1957   142\n 3  1962   142\n 4  1967   142\n 5  1972   142\n 6  1977   142\n 7  1982   142\n 8  1987   142\n 9  1992   142\n10  1997   142\n11  2002   142\n12  2007   142\n\nIn general, you might find after solving a particular problem in a couple of steps that there is a more elegant solution. Do not be discouraged by that! It simply means that there is always more to learn, but the tools you already know by now will get you a very long way and set you on the right track.\nI think we learned enough dplyr verbs for now. We can treat ourselves to a little ggplot visualization.\nVisualization and our First Encounter with factors\n\n\ngapminder %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line(alpha = 0.3) +\n  facet_wrap(~ continent)\n\n\n\n\nThe facet_wrap function slices our plot into theses subplots, a style of plot sometimes referred to as small multiples. At this point you might wonder: “How do I control the order of these facets?” The answer is: With a factor! Any time we have a vector that can be thought of as representing discrete categories (ordered or unordered), we can express this by turning the vector into a factor with the factor function. This enables R’s functions to handle them appropriately. Let’s create a little example. We start out with a character vector.\n\n\nanimals <- c(\"cat\", \"dog\", \"parrot\", \"whale shark\", \"bear\")\nanimals\n\n\n[1] \"cat\"         \"dog\"         \"parrot\"      \"whale shark\"\n[5] \"bear\"       \n\n\n\nanimals <- factor(animals)\nanimals\n\n\n[1] cat         dog         parrot      whale shark bear       \nLevels: bear cat dog parrot whale shark\n\nNote the new information R gives us, the Levels, which is all possible values we can put into the factor. They are automatically ordered alphabetically on creation. We can also pass a vector of levels on creation.\n\n\nanimals <- c(\"cat\", \"dog\", \"parrot\", \"whale shark\", \"bear\")\nfactor(animals, levels = c(\"parrot\", \"cat\", \"dog\", \"bear\"))\n\n\n[1] cat    dog    parrot <NA>   bear  \nLevels: parrot cat dog bear\n\nA factor can only contain elements that are in the levels, so because I omitted the whale shark, it will be turned into NA. The tidyverse contains the forcats package to help with factors. Most functions from this package start with fct_.\n\n\n\n\n\nFor example, the fct_relevel function, which keeps all levels but let’s us change the order:\n\n\nanimals <- factor(animals)\nfct_relevel(animals, c(\"parrot\", \"dog\"))\n\n\n[1] cat         dog         parrot      whale shark bear       \nLevels: parrot dog bear cat whale shark\n\nUsing this in action, we get:\n\n\nplt <- gapminder %>% \n  mutate(continent = fct_relevel(continent, \"Europe\", \"Oceania\")) %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line(alpha = 0.3) +\n  facet_wrap(~ continent)\n\nplt\n\n\n\n\nI saved the plot to a variable called plt because we need it later. Let’s make this plot a bit prettier by adding color! The gapminder package that provided this dataset also included a nice color palette. I included it as a .csv file in the data/ folder so that we can practice importing data once more. But you could also take the shortcut of getting it straight from the package (gapminder::country_colors). Here, we are using the head function to look at the first couple of rows of the tibble and to look at the first couple of elements of the named vector from the package.\n\n\ncountry_colors <- read_csv(\"data/country_colors.csv\")\nhead(country_colors)\n\n\n# A tibble: 6 x 2\n  country          color  \n  <chr>            <chr>  \n1 Nigeria          #7F3B08\n2 Egypt            #833D07\n3 Ethiopia         #873F07\n4 Congo, Dem. Rep. #8B4107\n5 South Africa     #8F4407\n6 Sudan            #934607\n\n\n\nhead(gapminder::country_colors)\n\n\n         Nigeria            Egypt         Ethiopia Congo, Dem. Rep. \n       \"#7F3B08\"        \"#833D07\"        \"#873F07\"        \"#8B4107\" \n    South Africa            Sudan \n       \"#8F4407\"        \"#934607\" \n\nNotice, that the csv that we read in translates to a tibble with two columns, namely country and color. But what we need for ggplot to assign colors to the countries is what the gapminder package provides: a names vector. The names are the countries and the values so called hexadecimal (short Hex) color codes (https://www.w3schools.com/colors/colors_hexadecimal.asp). So what we want to do is translate the tibble into a named vector:\n\n\ncountry_colors <- country_colors %>% \n  mutate(color = set_names(color, country)) %>% \n  pull(color)\n\nhead(country_colors)\n\n\n         Nigeria            Egypt         Ethiopia Congo, Dem. Rep. \n       \"#7F3B08\"        \"#833D07\"        \"#873F07\"        \"#8B4107\" \n    South Africa            Sudan \n       \"#8F4407\"        \"#934607\" \n\nTwo things happened here that are sort of new. set_names is a handy way to take a vector and return a vector with names. It fits better into the tidyverse syntax than the “old” way of assigning to names(x) <- c(\"new\", \"names\", \"vector\"). And secondly pull can be though of as a pipeable dollar. It pulls out the column of a tibble or the element of a named list.\n\n\ngapminder$year %>% head()\n\n\n[1] 1952 1957 1962 1967 1972 1977\n\ngapminder %>% pull(year) %>% head()\n\n\n[1] 1952 1957 1962 1967 1972 1977\n\nNow, with our color vector ready to go, we can make the plot pretty. Remember the variable we saved our plot to? We can add more ggplot functions to it just like to a regular ggplot. A guide is the generalization of a legend, so we are setting it to none because adding a legend for 142 different colors (/countries) would fill the whole plot.\n\n\nplt +\n  aes(color = country) +\n  scale_color_manual(values = country_colors, guide = guide_none()) +\n  theme_minimal() + \n  labs(x = \"\",\n       y = \"Life Expectancy at Birth\",\n       title = \"Life Expectancy over Time\")\n\n\n\n\nWe also added a theme and modified the axis titles. You might have already notice a number of very pronounced dips in some of the lines. We will investigate this rather bleak reality when we talk about modeling and iteration next week.\nExercises\nDrink a cup of coffee or tea, relax, because you just worked through quite a long video.\nFamiliarize yourself with the folders on your computer. Make sure you understand, where your directories and files live.\nFrom RStudio, create a new RStudio project for this course.\nInside the project folder, create a folder for the data.\nCreate a new Rmarkdown document at the top level of your project folder for today’s exercises, again including questions that came up during the course.\nDownload the data for today in one of the ways taught. You can refer to the script anytime.\nMake sure you have all the important settings set and are feeling right at home in RStudio.\n\nThe file ./data/exercise1.txt is in an unfamiliar format.\nFind out how it is structured and read it as a tibble.\nCreate a scatterplot of the x and y column with ggplot2.\nLook at the help page for geom_point. What is the difference between geom_point(aes(color = <something>)) and geom_point(color = <something>)? A relevant hint is in the section about the ...-argument.\nMake the plot pretty by coloring the points, keeping in mind the above distinction.\n\nRead in the gapminder dataset with readr\nUsing a combination of dplyr verbs and / or visualizations with ggplot2, answer the following questions:\nWhich continent had the highest life expectancy on average in the most current year? There are two options here. First, calculate a simple mean for the countries in each continent. Then, remember that the countries have different population sizes, so we really need a weighted mean using R’s function weighted.mean().\nIs there a relationship between the GDP per capita and the life expectancy? A visualization might be helpful.\nHow did the population of the countries change over time? Make the plot more informative by adding color, facets and labels (with geom_text). Can you find out, how to add the country name label only to the last year? Hint: Have a look at the data argument that all geom_-functions have.\n\nResources\nPackage Documentation\nThe tidyverse website\nThe readr package website with cheatsheet\nThe dplyr package website with cheatsheet\nGetting Help\nHow to find help\nR4DS online learning community\n\n\n\n“Artwork by @allison_horst.” 2020. https://github.com/allisonhorst/stats-illustrations.\n\n\nBryan, Jennifer. 2017. Gapminder: Data from Gapminder. Manual.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\n\n\n",
    "preview": "lectures/lecture2/lecture2_files/figure-html5/prev-plt-1.png",
    "last_modified": "2020-12-09T13:46:55+01:00",
    "input_file": "lecture2.utf8.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "lectures/lecture1/",
    "title": "Lecture 1",
    "description": "... in which we get started with R and RStudio,\nexplore the basic structures and operations of R\nand build our first plot by discovering a Grammar\nof Graphics.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-02",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nWhat You will Learn\nFirst Things First: Installing R\nExecuting R Code\nBuilding Blocks of R\nAtomic Datatypes\nVariables\nFunctions\nVectors\nVectorization\n\nFunctions and Packages – Making our lives easier\nThe Tidyverse\n\nLiterate Programming: Rmarkdown\nOur First Dataset: The Palmer Penguins\nLists and dataframes\n\nTranslating Data into Visualizations\nThe Community: There to catch You.\n\nExercises\nSolutions\nResources\nTidyverse\nRmarkdown\nR in general\nStatistics\nTalks, Podcasts, Blogs, Videos\nMisc\n\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen mode. Press ? for a list of keyboard shortcuts. The arrow keys bring you to the next and previous slide.\n\n\n\n\nScript\nWhat You will Learn\nThroughout your scientific career — and potentially outside of it — you will encounter various forms of data. Maybe you do an experiment and measured the fluorescence of a molecular probe, or you simply count the penguins at your local zoo. Everything is data in some form or another. But raw numbers without context are meaningless and tables of numbers are not only boring to look at, but often hide the actual structure in the data.\nIn this course you will learn to handle different kinds of data. You will learn to create pretty and insightful visualizations, compute different statistics on your data and also what these statistical concepts mean. From penguins to p-values, I got you covered.\nThe course will be held in English, as the concepts covered will directly transfer to the research you do, where the working language is English. That being said, feel free to ask questions in any language that I understand, so German is also fine. My Latin is a little rusty, thought.\nIn this course, we will be using the programming language R. R is a language particularly well suited for data analysis, because it was initially designed by statisticians and because of the interactive nature of the language, which makes it easier to get started. So don’t fret if this is your first encounter with programming, we will take one step at a time.\nThe datasets chosen to illustrate the various concepts and tools are not particularly centered around Biology. Rather, I chose general datasets that require less introduction and enable us to focus on learning R and statistics. This is why we will be talking about penguins, racing games or life expectancy instead of intricate molecular measurements.\nFirst Things First: Installing R\n\n\n\n\n\nBut I was getting ahead of myself. First, we need to install R. You can download the installer for your operating system here: https://cran.r-project.org/. Feel free to post a question if you get stuck. This already gives you the ability to execute R code or use the interactive R console, but it is way more comfortable to use R inside of a so called IDE (Integrated Development Environment). IDEs give you neat things like autocompletion, a window for your plots and a help panel. The main IDE for R is called RStudio. We will be using it for this course and you can download it here: https://www.rstudio.com/products/rstudio/download/#download\n\n\n\nExecuting R Code\nYou can now execute commands in the R console in the bottom left. For example we can calculate a mathematical expression:\n\n\n1 + 1\n\n\n[1] 2\n\nOr generate the numbers from one to 10:\n\n\n1:10\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nBut I rarely type directly into the console. Because we want our results to be reproducible, we write our code in a script first, so that the next person1 can see what we did and replicate our analysis. You will see that reproducibility is quite near and dear to me, so it will pop up once or twice. And as scientists, I am sure you understand the importance.\nTo create a new script, click the little button in the top left corner. In a script you can type regular R code, but it won’t get executed straight away. To send a line of code to the console to be executed, hit Ctrl+Enter. Go ahead, try it with:\n\n\npaste(\"Hello\", \"World!\")\n\n\n[1] \"Hello World!\"\n\nThe paste function combines text, just like + combines numbers. Your code can have comments to tell your future self why you wrote a piece of code the way you did. Any line starting with the number symbol # will be ignored by R.\n\n\n# This line will be ignored\n43 - 1 # as will be the part after this #, but not before it\n\n\n[1] 42\n\nBuilding Blocks of R\nNow it is time to introduce you to the fundamental datatypes of R. We are going to cover the so called atomic datatypes first and introduce others as they appear.\nAtomic Datatypes\nFirst we have numbers (which internally are called numeric or double)\n\n\n12\n12.5\n\n\n\nThen, there are whole numbers (integer)\n\n\n1L # denoted by L\n\n\n\nas well as the rarely used complex numbers (complex)\n\n\n1 + 3i # denoted by the small i for the imaginary part\n\n\n\nText data however will be used more often (character, string). Everything enclosed in quotation marks will be treated as text. Double or single quotation marks are both fine.\n\n\n\"It was night again.\"\n'This is also text'\n\n\n\nLogical values can only contain yes or no, or rather TRUE and FALSE in programming terms (boolean, logical).\n\n\nTRUE\nFALSE\n\n\n\nThere are some special types that mix with any other type. Like NULL for no value and NA for Not Assigned.\n\n\nNULL\nNA\n\n\n\nNA is contagious. Any computation involving NA will return NA (because R has no way of knowing the answer):\n\n\nNA + 1\n\n\n[1] NA\n\nmax(NA, 12, 1)\n\n\n[1] NA\n\nBut some functions can remove NAs before giving us an answer:\n\n\nmax(NA, 12, 1, na.rm = TRUE)\n\n\n[1] 12\n\nYou can ask for the datatype of an object with the function typeof:\n\n\ntypeof(\"hello\")\n\n\n[1] \"character\"\n\nThere is also a concept called factors (factor) for categorical data, but we will talk about that later, when we get deeper into vectors.\nVariables\nOften, you will want to store the result of a computation for reuse, or to give it a sensible name and make your code more readable. This is what variables are for. We can assign a value to a variable using the assignment operator <- (In RStudio, there is a shortcut for it: Alt+Minus):\n\n\nmy_number <- 42\n\n\n\nExecuting the above code will not give you any output, but when you use the name of the variable, you can see its content.\n\n\nmy_number\n\n\n[1] 42\n\nAnd you can do operations with those variables:\n\n\nx <- 41\ny <- 1\nx + y\n\n\n[1] 42\n\n\nNOTE Be careful about the order of execution! R enables you to work interactively and to execute the code you write in your script in any order with Ctrl+Enter, but when you execute (=“source”) the whole script, it will be executed from top to bottom.\n\nFurthermore, code is not executed again automatically, if you change some dependency of the expression later on. So the second assignment to x doesn’t change y.\n\n\nx <- 1\ny <- x + 1\nx <- 1000\ny\n\n\n[1] 2\n\nVariable names can contain letters (capitalization matters), numbers (but not as the first character) and underscores _.2\n\n\n# snake_case\nmain_character_name <- \"Kvothe\"\n\n# or camelCase\nbookTitle <- \"The Name of the Wind\"\n\n# you can have numbers in the name\nx1 <- 12\n\n\n\nA depiction of various naming styles (“Artwork by @allison_horst” 2020).Functions\n\nIn R, everything that exists is an object, everything that does something is a function.\n\nFunctions are the main workhorse of our data analysis. For example, there are mathematical functions, like sin, cos etc.\n\n\nsin(x = 0)\n\n\n[1] 0\n\nFunctions take arguments (sometimes called parameters) and sometimes they also return things. The sin function takes just one argument x and returns its sine. What we do with the returned value is up to us. We can use it directly in another computation or store it in a variable. If we don’t do anything with the return value, R simply prints it to the console.\nNote, that the = inside the function parenthesis gives x = 0 to the function and is separate from any x defined outside of the function. For example:\n\n\nx <- 10\ncos(x = 0)\n\n\n[1] 1\n\n# x outside of the function is still 10\nx\n\n\n[1] 10\n\nTo learn more about a function in R, execute ? with the function name or press F1 with your mouse over the function. This is actually one of the most important things to learn today, because the help pages can be… well… incredibly helpful.\n\n\n?sin\n\n\n\nWe can pass arguments by name or by order of appearance. The following two expressions are equivalent.\n\n\nsin(x = 12)\nsin(12)\n\n\n\nVectors\nA vector is an ordered collection of things which have the same datatype, where a datatype is something like numbers (numeric), text (character also called string) or whole numbers (integer).\nThe basic datatypes in R are all vectors, which means they can contain more than one entry. You can create a vector by combining things of the same data type with the function c for combine.\n\n\nx <- c(1, 2, 3, 4, 5, 6)\nx\n\n\n[1] 1 2 3 4 5 6\n\nAny atomic datatype mentioned above can be in a vector, but atomic vectors can only store data of the same type. For example, you can have a character vector\n\n\nc(\"This\", \"is\", \"a\", \"character\", \"vector\")\n\n\n[1] \"This\"      \"is\"        \"a\"         \"character\" \"vector\"   \n\nor a vector of logical values\n\n\nc(TRUE, FALSE, TRUE, TRUE)\n\n\n[1]  TRUE FALSE  TRUE  TRUE\n\nBut not a vector with, say text and numbers. If we try to combine data of a different type, R will force all the data into the more permissive type. Because all Numbers can easily be converted into text, but not all text can be converted to numbers, this makes everything text in this example:\n\n\nc(\"Some text\", 42, 12)\n\n\n[1] \"Some text\" \"42\"        \"12\"       \n\nNote the quotation marks around the numbers, marking them as text. If we were to try and use them as numbers, we would get and error message:\n\n\n\"12\" + 1\n\n\nError in \"12\" + 1: non-numeric argument to binary operator\n\nThere are other cases where we will encounter error messages. Programming languages are not unlike human languages. The computer will not always understand, what you want it to do, unless you use exactly the right grammar and vocabulary. An error messages is R’s way of telling us, that it didn’t understand, or that we asked it to do something impossible. Even experienced programmers are very fond of this advice:\n\n\n\nFigure 1: Maybe the most important programming advice.\n\n\n\nTo solve above error message, we need to explicitly tell R to convert the text to a number:\n\n\nas.numeric(\"12\") + 1\n\n\n[1] 13\n\nSubsetting\nWe can look at, or change, subsets of vectors using square brackets [] like so:\n\n\nmy_elements <- c(\"first\", \"second\", \"third\")\nmy_elements[2]\n\n\n[1] \"second\"\n\n\n\nmy_elements[3] <- \"new element\"\nmy_elements\n\n\n[1] \"first\"       \"second\"      \"new element\"\n\nIf we assign names to the elements, we can also reference them by name.\n\n\nnames(my_elements) <- c(\"e1\", \"e2\", \"e3\")\nmy_elements\n\n\n           e1            e2            e3 \n      \"first\"      \"second\" \"new element\" \n\n\n\nmy_elements[\"e3\"]\n\n\n           e3 \n\"new element\" \n\nPass a vector of indices (or names) to the square brackets to get (or set) multiple elements:\n\n\nmy_elements[c(1, 3)]\n\n\n           e1            e3 \n      \"first\" \"new element\" \n\nUsing a logical vector yields all elements where the vector is TRUE:\n\n\nmy_elements[c(TRUE, TRUE, FALSE)]\n\n\n      e1       e2 \n \"first\" \"second\" \n\nVectorization\nThe basic mathematical operations in R and a lot of functions are vectorized. This means, they operate on every element of the vector. Here, every element is multiplied by 2 and the result is printed to the console.\n\n\nx * 2\n\n\n[1]  2  4  6  8 10 12\n\nThe original vector x was not changed in doing so.\n\n\nx\n\n\n[1] 1 2 3 4 5 6\n\nBut we could have, by assigning the result back to x, thus overwriting its previous content. The right hand side (RHS) is executed first:\n\n\nx <- x * 2\n\n\n\nNow x changed:\n\n\nx\n\n\n[1]  2  4  6  8 10 12\n\nA handy way of creating vectors of numbers is with the : operator to specify a range of values:\n\n\n1:5\n\n\n[1] 1 2 3 4 5\n\nOr using the seq function with some additional (optional) parameters:\n\n\nseq(from = 1, to = 10)\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nNow you: Look at the documentation/help page for seq and find out how to create a vector of all even numbers from 2 to 100.\n\nFunctions and Packages – Making our lives easier\nYou just learned about the functions sin, seq and max. But wait, there is more! Not only in the sense that there are more functions in R (what kind of language would that be with only two verbs?!), but also in a more powerful way:\n\nWe can define our own functions!\n\nThe syntax (\\(\\leftarrow\\) grammar for programming languages) is as follows.\n\n\nname_for_the_function <- function(parameter1, parameter2, ...) { # etc.\n  # body of the function\n  # things happen\n  result <- parameter1 + parameter2\n  # Something the function should return to the caller\n  return(result)\n}\n\n\n\nThe function ends when it reaches the return keyword. It also ends when it reaches the end of the function body and implicitly returns the last expression. So we could have written it a bit shorter and in fact you will often see people omitting the explicit return at the end:\n\n\nadd <- function(x, y) {\n  x + y\n}\n\n\n\nAnd we can call our freshly defined function:\n\n\nadd(23, 19)\n\n\n[1] 42\n\nGot an error like Error in add(23, 19) : could not find function \"add\"? Check that you did in fact execute the code that defines the function (i.e. put your cursor on the line with the function keyword and hit Ctrl+Enter.).\n\nNow you: Define a function that takes one argument, a vector of numbers, devides each element by the length of the vector (hint: length is the function to get the length) and returns the resulting scaled vector.\n\nYou are not the only one using R. There is a welcoming and helpful community out there. Some people also write a bunch of functions and put them together in a so called package. And some people even went a step further. The tidyverse is a collection of packages that play very well together and also iron out some of the quirkier ways in which R works (Wickham et al. 2019). They provide a consistent interface to enable us to do more while having to learn less special cases. The R function install.packages(\"<package_name_here>\") installs packages from CRAN a curated set of R packages.\nThe Tidyverse\nGo ahead and install the tidyverse packages with\n\n\ninstall.packages(\"tidyverse\")\n\n\n\nThis is one exception to our effort of having everything in our script and not just in the console. We don’t want R trying to install the package every time we run the script, as this needs to happen only once. So you can either turn it into a comment, delete it from the script, or only type it in the console. You can also use RStudio’s built-in panel for package installation.\n\n\n\nTo make the functions from a package available to your R session, run the library function with the name of the package.\n\n\nlibrary(tidyverse)\n\n\n\nThe convention is, to keep all library-calls at the top of your script, so that you ,and others, can see straight away, which packages are needed. Don’t worry about the messages that pop up. This is just the tidyverse telling us that two of it’s functions (lag and filter) have functions with the same names in another package (or in this case base-R) and because we loaded the tidyverse second, R will now use the tidyverse functions. This is what “masking” means.\nLiterate Programming: Rmarkdown\n\n\n\n(“Artwork by @allison_horst” 2020)There is another package I would like you to install. It is called Rmarkdown.\n\n\ninstall.packages(\"rmarkdown\")\n\n\n\nRmarkdown enables us, to combine text with code and then produce a range of output formats like pdf, html, word documents, presentations etc. In fact, this whole website, including the slides, was created with Rmarkdown. Sounds exciting? Let’s dive into it!\nOpen up a new Rmarkdown document with the file extension .Rmd from the New File menu in the top left corner of RStudio: File → New File → R Markdown and choose html as the output format. I particularly like html, because you don’t have to worry about page breaks and it easily works on screens of different sizes, like your phone.\nAn Rmarkdown document consists of three things:\nMetadata:\nInformation about your document such as the author or the date in a format called YAML. This YAML header starts and ends with three minus signs ---.\nText:\nRegular text is interpreted as markdown, meaning it supports things like creating headings by prefixing a line with #, or text that will be bold in the output by surrounding it with **.\nCode chunks:\nStarting with ```{r} and ending with ``` (backticks). They will be interpreted as R code. This is where you write the code like you did in the .R script file. You can insert new chunks with the button on the top right of the editor window or use the shortcut Ctrl+Alt+i.\nUse these to document your thoughts alongside your code when you are doing data analysis. Future you (and reviewer number 2) will be happy! To run code inside of chunks, use,the little play button on the chunk, the tried and true Ctrl+Enter to run one line, or Ctrl+Shift+Enter to run the whole chunk. Your chunks can be as large or small as you want, but try to maintain some sensible structure.\nOur First Dataset: The Palmer Penguins\n(“Artwork by @allison_horst” 2020)So let’s explore our first dataset together in a fresh Rmarkdown document. The setup chunk is special. It gets executed automatically before any other chunk in the document is run. This makes it a good place to load packages. The dataset we are working with today actually comes in its own package, so we need to install this as well (Yes, there is a lot of installing today, but you will have to do this only once):\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\nAnd then we populate our setup chunk with\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\n\nThis gives us the penguins dataset (Horst, Hill, and Gorman 2020):\n\n\npenguins\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\nLet’s talk about the shape of the penguins object. The str function reveals the structure of an object to us.\n\n\nstr(penguins)\n\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\nLists and dataframes\nPreviously, we only had atomic vectors, where all elements are of the same type, like a vector of numbers, and the individual elements could not contain other things themselves (hence the name atomic): c(1, 2, 3). The next more general thing is a list, which we can create with the function list(...). Lists can contain arbitrary elements, even other lists:\n\n\nmy_list <- list(1, \"hello\", c(1, 2, 3), list(42, \"text\"))\nmy_list\n\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"hello\"\n\n[[3]]\n[1] 1 2 3\n\n[[4]]\n[[4]][[1]]\n[1] 42\n\n[[4]][[2]]\n[1] \"text\"\n\nThe print output suggests something else: For vectors, we could subset them using [], but here we will need double square brackets [[]].\n\n\nmy_list[[3]]\n\n\n[1] 1 2 3\n\nUsing single brackets would just give us a subset of the list, not the actual element of the list (yes, this can be confusing):\n\n\nmy_list[3]\n\n\n[[1]]\n[1] 1 2 3\n\nThe penguins variable contains what is called a data.frame. The reason I talked about lists just now is that dataframes are built on top of lists, where the elements are the columns. Because dataframes form this rectangular data format like a spreadsheet you know from excel, the constraint is that the elements of the list need to have the same length. We can demonstrate this by creating our own dataframe from a list.\n\n\nnew_list <- list(x = 1:3, y = c(10, 42, 3), third = c(\"hello\", \"from\", \"R\"))\nnew_list\n\n\n$x\n[1] 1 2 3\n\n$y\n[1] 10 42  3\n\n$third\n[1] \"hello\" \"from\"  \"R\"    \n\nNotice that I did another thing: I gave names to the elements of the list. This is nice because of two reasons. Firstly, as the print output already suggests, we can now use the dollar syntax $ to refer to the individual elements by name instead of by position and RStudio’s autocomplete helps us out.\n\n\nnew_list$x\n\n\n[1] 1 2 3\n\nSecondly, the names will become column names when we turn it into a dataframe:\n\n\nmy_first_df <- as.data.frame(new_list)\nmy_first_df\n\n\n  x  y third\n1 1 10 hello\n2 2 42  from\n3 3  3     R\n\nThere is one last difference for the penguins. They are also a tibble, which is again built on top of dataframes and makes the object look nicer when we print it to the console. Compare the following when executing them in the console:\n\n\npenguins\nas.data.frame(penguins)\n\n\n\nThe dataset contains data for 344 penguins. of 3 different species, collected from 3 islands in the Palmer Archipelago, Antarctica3.\nTranslating Data into Visualizations\nYou probably took this course because you want to build some cool visualizations for you data. In order to do that, let us talk about how we can describe visualizations. Just like language has grammar, some smart people came up with a grammar of graphics (Wilkinson et al. 2005), which was then slightly modified and turned into an R package so that we can not only talk about but also create visualizations using this grammar (Wickham 2010).\n\n\n\n\n\nThe package is called ggplot2 and we already have it loaded because it is included in the tidyverse. Before looking at the code, we can describe what we need in order to create this graphic.\n\n\n\nggplot(penguins, aes(flipper_length_mm, bill_length_mm,\n                     color = species,\n                     shape = sex)) +\n  geom_point(size = 2.5) +\n  labs(x = \"Flipper length [mm]\",\n       y = \"Bill length [mm]\",\n       title = \"Penguins!\",\n       subtitle = \"The 3 penguin species can differentiated by their flipper and bill lengths\") +\n  theme_minimal() +\n  scale_color_brewer(type = \"qual\")\n\n\n\n\nWe can build this plot up step by step. The data is the foundation of our plot, but this just gives us an empty plotting canvas. I am assigning the individual steps we are going through to a variable, so that we can sequentially add elements, but you can do this in one step as shown above.\n\n\nplt <- ggplot(penguins)\nplt\n\n\n\n\nThen, we add and aesthetic mapping to the plot. It creates a relation from the features of our dataset (like the flipper length of each penguin) to a visual property, like position of the x-axis, color or shape.\n\n\nplt <- ggplot(penguins,\n              aes(x = flipper_length_mm,\n                  y = bill_length_mm,\n                  color = species,\n                  shape = sex))\nplt\n\n\n\n\nStill, the plot is empty, it only has a coordinate system with a certain scale. This is because we have no geometric objects to represent our aesthetics. Elements of the plot are added using the + operator and all geometric elements that ggplot knows start with geom_. Let’s add some points:\n\n\nplt <- plt +\n  geom_point()\nplt\n\n\n\n\nLook at the help page for geom_point to find out what aesthetics it understands. The exact way that features are mapped to aesthetics is regulated by scales starting with scale_ and the name of an aesthetic:\n\n\nplt <- plt +\n  scale_color_brewer(type = \"qual\")\nplt\n\n\n\n\nWe can add or change labels (like the x-axis-label) by adding the labs function.\n\n\nplt <- plt +\n    labs(x = \"Flipper length [mm]\",\n         y = \"Bill length [mm]\",\n         title = \"Penguins!\",\n         subtitle = \"The 3 penguin species can differentiated by their flipper and bill lengths\")\n\n\n\nThe overall look of the plot is regulated by themes like the premade theme_ functions or more finely regulated with the theme() function, which uses element functions to create the look of individual elements. Autocomplete helps us out a lot here (Ctrl+Space).\n\n\nplt <- plt + \n  theme_minimal() +\n  theme(legend.text = element_text(face = \"bold\"))\nplt\n\n\n\n\nThe Community: There to catch You.\n\nCoding can be incredibly rewarding, but also incredibly frustrating.\n\nLuckily, the R community is with you!\n(“Artwork by @allison_horst” 2020)In the video I give a brief overview of the resources linked below. Come back here anytime as a reference.\nExercises\nThis course is not graded, but I need some way of confirming that you did indeed take part in this course. In order to get the confirmation, you will send your solutions for a minimum of 5 out of the 8 exercises to me before the Friday following the lecture upload on Monday. For each week I would like you to create a fresh Rmarkdown document with your solutions as code as well as any questions that arose during the lecture. This will help me a lot in improving this course.\nWhen you are done solving the exercises, hit the knit button (at the top of the editor panel) and send me the resulting html document via discord or email (confirm that it looks the way you expected beforehand).\nHere are today’s tasks:\nWrite a section of text about your previous experience with data analysis and/or programming (optional, but I can use this information to customize the course).\nWrite the code that loads in the tidyverse and the palmer penguins data set.\nProduce a scatterplot (meaning a plot with points) of the bill length vs. the bill depth, colorcoded by species.\nImaginary bonus points if you manage to use the same colors as in the image above (hint: look at the help page for scale_color_manual() to find out how). Even more bonus points if you also look into the theme() function and it’s arguments, or the theme_<...>() functions to make the plot prettier.\n\nCreate a vector of all odd numbers from 1 to 99 and store it in a variable.\nCreate a second variable that contains the squares of the first.\nStore both variables in a named list and then turn this list into a tibble (the enhanced version of a data.frame\nDiscover a shortcut for the three steps above using the function tibble. Specifically, have a look at the third bullet point in the description of ?tibble::tibble (The two colons :: specify the package a function is coming from. You only need tibble(...) in the code because the tibble package is loaded automatically with the tidyverse. Here, I specify it directly to send you to the correct help page).\nCreate a scatterplot of the two variables stored in the tibble using ggplot.\nWhat geom_ function do you need to add to the plot to add a line that connects your points?\n\nCheck the metadata (YAML) of your Rmarkdown document and make sure it contains your name as the author: .\nHere are a couple more YAML options you can try if you feel adventurous.\n\nSolutions\nThe Office Hour for the solutions and questions is on Friday, Nov 6, 2020 at 10:00. Find the link in the discord.\nResources\nTidyverse\nR for Data Science (Wickham and Grolemund 2017)\nR4DS online Community\nRStudio Cheat Sheets!\nThe Modern Dive (Kim 2019)\nRStudio Education\nRmarkdown\nhttps://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf\nhttps://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf\nhttps://bookdown.org/yihui/rmarkdown-cookbook/\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://pandoc.org/MANUAL.html#pandocs-markdown\nhttps://reproducible-analysis-workshop.readthedocs.io/en/latest/6.RMarkdown-knitr.html\nhttps://rmarkdown.rstudio.com/index.html\nR in general\nAdvanced R (Wickham 2019)\nHands on Programming with R (Grolemund and Wickham 2014)\nR Packages (Wickham 2015)\nData Visualization: A Practical Introduction (Healy 2018)\nGraph Cookbook (Chang 2013)\nStatistics\nIntuitive Biostatistics (Motulsky 2017)\nStatistics Done Wrong (Reinhart 2015)\nTalks, Podcasts, Blogs, Videos\nDavid Robinson\nYouTube\nwebsite\n\nJulia Silge\nYouTube\nwebsite\n\nAlison Hill\nwebsite\n\nMisc\nCute and insightful illustrations (“Artwork by @allison_horst” 2020)\nHappy Git with R\nMade with the help of these amazing packages (plus documentation): (R Core Team 2020); (Xie 2020a); (Allaire et al. 2020); (Xie 2015); (Xie 2020b).\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2020. Rmarkdown: Dynamic Documents for r. Manual.\n\n\n“Artwork by @allison_horst.” 2020. https://github.com/allisonhorst/stats-illustrations.\n\n\nChang, Winston. 2013. R Graphics Cookbook: Practical Recipes for Visualizing Data. 1 edition. Beijing Cambridge Farnham Köln Sebastopol Tokyo: O’Reilly Media.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2014. Hands-On Programming with R: Write Your Own Functions and Simulations. Sebastopol, CA: O’Reilly Media.\n\n\nHealy, Kieran. 2018. Data Visualization: A Practical Introduction. 1 edition. Princeton, NJ: Princeton University Press.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2020. Palmerpenguins: Palmer Archipelago (antarctica) Penguin Data. Manual.\n\n\nKim, Chester Ismay and Albert Y. 2019. Statistical Inference via Data Science. CRC Press.\n\n\nMotulsky, Harvey. 2017. Intuitive Biostatistics: A Nonmathematical Guide to Statistical Thinking. 4 edition. New York: Oxford University Press.\n\n\nR Core Team. 2020. R: A Language and Environment for Statistical Computing. Manual. Vienna, Austria: R Foundation for Statistical Computing.\n\n\nReinhart, Alex. 2015. Statistics Done Wrong: The Woefully Complete Guide. 1 edition. San Francisco: No Starch Press.\n\n\nWickham, Hadley. 2010. “A Layered Grammar of Graphics.” Journal of Computational and Graphical Statistics 19 (1): 3–28. https://doi.org/10.1198/jcgs.2009.07098.\n\n\n———. 2015. R Packages: Organize, Test, Document, and Share Your Code. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\n———. 2019. Advanced R, Second Edition. 2 edition. Boca Raton: Chapman and Hall/CRC.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\nWilkinson, Leland, D. Wills, D. Rope, A. Norton, and R. Dubbs. 2005. The Grammar of Graphics. 2nd edition. New York: Springer.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and Knitr. Second. Boca Raton, Florida: Chapman and Hall/CRC.\n\n\n———. 2020a. Knitr: A General-Purpose Package for Dynamic Report Generation in r. Manual.\n\n\n———. 2020b. Xaringan: Presentation Ninja. Manual.\n\n\nThis will most likely be future You. And you will thank yourself later↩︎\nThey can also contain dots (.), but it is considered bad practice because it can lead to some confusing edge cases.↩︎\nhttps://allisonhorst.github.io/palmerpenguins/↩︎\n",
    "preview": "lectures/lecture1/lecture1_files/figure-html5/final-penguin-plot-1.png",
    "last_modified": "2020-11-01T23:17:45+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
