[
  {
    "path": "lectures/lecture1/",
    "title": "Lecture 1",
    "description": "... in which we get started with R and RStudio,\nexplore the basic structures and operations of R\nand build our first plot by discovering a Grammar\nof Graphics.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-02",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nWhat You will Learn\nFirst Things First: Installing R\nExecuting R Code\nBuilding Blocks of R\nAtomic Datatypes\nVariables\nFunctions\nVectors\nVectorization\n\nFunctions and Packages – Making our lives easier\nThe Tidyverse\n\nLiterate Programming: Rmarkdown\nOur First Dataset: The Palmer Penguins\nLists and dataframes\n\nTranslating Data into Visualizations\nThe Community: There to catch You.\n\nExercises\nSolutions\nResources\nTidyverse\nRmarkdown\nR in general\nStatistics\nTalks, Podcasts, Blogs, Videos\nMisc\n\n\nVideo\nWatch today’s video here:\n\n\nSlides\nHover over the slides and press f for full screen mode. Press ? for a list of keyboard shortcuts. The arrow keys bring you to the next and previous slide.\n\n\n\n\nScript\nWhat You will Learn\nThroughout your scientific career — and potentially outside of it — you will encounter various forms of data. Maybe you do an experiment and measured the fluorescence of a molecular probe, or you simply count the penguins at your local zoo. Everything is data in some form or another. But raw numbers without context are meaningless and tables of numbers are not only boring to look at, but often hide the actual structure in the data.\nIn this course you will learn to handle different kinds of data. You will learn to create pretty and insightful visualizations, compute different statistics on your data and also what these statistical concepts mean. From penguins to p-values, I got you covered.\nThe course will be held in English, as the concepts covered will directly transfer to the research you do, where the working language is English. That being said, feel free to ask questions in any language that I understand, so German is also fine. My Latin is a little rusty, thought.\nIn this course, we will be using the programming language R. R is a language particularly well suited for data analysis, because it was initially designed by statisticians and because of the interactive nature of the language, which makes it easier to get started. So don’t fret if this is your first encounter with programming, we will take one step at a time.\nThe datasets chosen to illustrate the various concepts and tools are not particularly centered around Biology. Rather, I chose general datasets that require less introduction and enable us to focus on learning R and statistics. This is why we will be talking about penguins, racing games or life expectancy instead of intricate molecular measurements.\nFirst Things First: Installing R\n\n\n\n\n\nBut I was getting ahead of myself. First, we need to install R. You can download the installer for your operating system here: https://cran.r-project.org/. Feel free to post a question if you get stuck. This already gives you the ability to execute R code or use the interactive R console, but it is way more comfortable to use R inside of a so called IDE (Integrated Development Environment). IDEs give you neat things like autocompletion, a window for your plots and a help panel. The main IDE for R is called RStudio. We will be using it for this course and you can download it here: https://www.rstudio.com/products/rstudio/download/#download\n\n\n\nExecuting R Code\nYou can now execute commands in the R console in the bottom left. For example we can calculate a mathematical expression:\n\n\n1 + 1\n\n\n[1] 2\n\nOr generate the numbers from one to 10:\n\n\n1:10\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nBut I rarely type directly into the console. Because we want our results to be reproducible, we write our code in a script first, so that the next person1 can see what we did and replicate our analysis. You will see that reproducibility is quite near and dear to me, so it will pop up once or twice. And as scientists, I am sure you understand the importance.\nTo create a new script, click the little button in the top left corner. In a script you can type regular R code, but it won’t get executed straight away. To send a line of code to the console to be executed, hit Ctrl+Enter. Go ahead, try it with:\n\n\npaste(\"Hello\", \"World!\")\n\n\n[1] \"Hello World!\"\n\nThe paste function combines text, just like + combines numbers. Your code can have comments to tell your future self why you wrote a piece of code the way you did. Any line starting with the number symbol # will be ignored by R.\n\n\n# This line will be ignored\n43 - 1 # as will be the part after this #, but not before it\n\n\n[1] 42\n\nBuilding Blocks of R\nNow it is time to introduce you to the fundamental datatypes of R. We are going to cover the so called atomic datatypes first and introduce others as they appear.\nAtomic Datatypes\nFirst we have numbers (which internally are called numeric or double)\n\n\n12\n12.5\n\n\n\nThen, there are whole numbers (integer)\n\n\n1L # denoted by L\n\n\n\nas well as the rarely used complex numbers (complex)\n\n\n1 + 3i # denoted by the small i for the imaginary part\n\n\n\nText data however will be used more often (character, string). Everything enclosed in quotation marks will be treated as text. Double or single quotation marks are both fine.\n\n\n\"It was night again.\"\n'This is also text'\n\n\n\nLogical values can only contain yes or no, or rather TRUE and FALSE in programming terms (boolean, logical).\n\n\nTRUE\nFALSE\n\n\n\nThere are some special types that mix with any other type. Like NULL for no value and NA for Not Assigned.\n\n\nNULL\nNA\n\n\n\nNA is contagious. Any computation involving NA will return NA (because R has no way of knowing the answer):\n\n\nNA + 1\n\n\n[1] NA\n\nmax(NA, 12, 1)\n\n\n[1] NA\n\nBut some functions can remove NAs before giving us an answer:\n\n\nmax(NA, 12, 1, na.rm = TRUE)\n\n\n[1] 12\n\nYou can ask for the datatype of an object with the function typeof:\n\n\ntypeof(\"hello\")\n\n\n[1] \"character\"\n\nThere is also a concept called factors (factor) for categorical data, but we will talk about that later, when we get deeper into vectors.\nVariables\nOften, you will want to store the result of a computation for reuse, or to give it a sensible name and make your code more readable. This is what variables are for. We can assign a value to a variable using the assignment operator <- (In RStudio, there is a shortcut for it: Alt+Minus):\n\n\nmy_number <- 42\n\n\n\nExecuting the above code will not give you any output, but when you use the name of the variable, you can see its content.\n\n\nmy_number\n\n\n[1] 42\n\nAnd you can do operations with those variables:\n\n\nx <- 41\ny <- 1\nx + y\n\n\n[1] 42\n\n\nNOTE Be careful about the order of execution! R enables you to work interactively and to execute the code you write in your script in any order with Ctrl+Enter, but when you execute (=“source”) the whole script, it will be executed from top to bottom.\n\nFurthermore, code is not executed again automatically, if you change some dependency of the expression later on. So the second assignment to x doesn’t change y.\n\n\nx <- 1\ny <- x + 1\nx <- 1000\ny\n\n\n[1] 2\n\nVariable names can contain letters (capitalization matters), numbers (but not as the first character) and underscores _.2\n\n\n# snake_case\nmain_character_name <- \"Kvothe\"\n\n# or camelCase\nbookTitle <- \"The Name of the Wind\"\n\n# you can have numbers in the name\nx1 <- 12\n\n\n\nA depiction of various naming styles (“Artwork by @allison_horst” 2020).Functions\n\nIn R, everything that exists is an object, everything that does something is a function.\n\nFunctions are the main workhorse of our data analysis. For example, there are mathematical functions, like sin, cos etc.\n\n\nsin(x = 0)\n\n\n[1] 0\n\nFunctions take arguments (sometimes called parameters) and sometimes they also return things. The sin function takes just one argument x and returns its sine. What we do with the returned value is up to us. We can use it directly in another computation or store it in a variable. If we don’t do anything with the return value, R simply prints it to the console.\nNote, that the = inside the function parenthesis gives x = 0 to the function and is separate from any x defined outside of the function. For example:\n\n\nx <- 10\ncos(x = 0)\n\n\n[1] 1\n\n# x outside of the function is still 10\nx\n\n\n[1] 10\n\nTo learn more about a function in R, execute ? with the function name or press F1 with your mouse over the function. This is actually one of the most important things to learn today, because the help pages can be… well… incredibly helpful.\n\n\n?sin\n\n\n\nWe can pass arguments by name or by order of appearance. The following two expressions are equivalent.\n\n\nsin(x = 12)\nsin(12)\n\n\n\nVectors\nA vector is an ordered collection of things which have the same datatype, where a datatype is something like numbers (numeric), text (character also called string) or whole numbers (integer).\nThe basic datatypes in R are all vectors, which means they can contain more than one entry. You can create a vector by combining things of the same data type with the function c for combine.\n\n\nx <- c(1, 2, 3, 4, 5, 6)\nx\n\n\n[1] 1 2 3 4 5 6\n\nAny atomic datatype mentioned above can be in a vector, but atomic vectors can only store data of the same type. For example, you can have a character vector\n\n\nc(\"This\", \"is\", \"a\", \"character\", \"vector\")\n\n\n[1] \"This\"      \"is\"        \"a\"         \"character\" \"vector\"   \n\nor a vector of logical values\n\n\nc(TRUE, FALSE, TRUE, TRUE)\n\n\n[1]  TRUE FALSE  TRUE  TRUE\n\nBut not a vector with, say text and numbers. If we try to combine data of a different type, R will force all the data into the more permissive type. Because all Numbers can easily be converted into text, but not all text can be converted to numbers, this makes everything text in this example:\n\n\nc(\"Some text\", 42, 12)\n\n\n[1] \"Some text\" \"42\"        \"12\"       \n\nNote the quotation marks around the numbers, marking them as text. If we were to try and use them as numbers, we would get and error message:\n\n\n\"12\" + 1\n\n\nError in \"12\" + 1: non-numeric argument to binary operator\n\nThere are other cases where we will encounter error messages. Programming languages are not unlike human languages. The computer will not always understand, what you want it to do, unless you use exactly the right grammar and vocabulary. An error messages is R’s way of telling us, that it didn’t understand, or that we asked it to do something impossible. Even experienced programmers are very fond of this advice:\n\n\n\nFigure 1: Maybe the most important programming advice.\n\n\n\nTo solve above error message, we need to explicitly tell R to convert the text to a number:\n\n\nas.numeric(\"12\") + 1\n\n\n[1] 13\n\nSubsetting\nWe can look at, or change, subsets of vectors using square brackets [] like so:\n\n\nmy_elements <- c(\"first\", \"second\", \"third\")\nmy_elements[2]\n\n\n[1] \"second\"\n\n\n\nmy_elements[3] <- \"new element\"\nmy_elements\n\n\n[1] \"first\"       \"second\"      \"new element\"\n\nIf we assign names to the elements, we can also reference them by name.\n\n\nnames(my_elements) <- c(\"e1\", \"e2\", \"e3\")\nmy_elements\n\n\n           e1            e2            e3 \n      \"first\"      \"second\" \"new element\" \n\n\n\nmy_elements[\"e3\"]\n\n\n           e3 \n\"new element\" \n\nPass a vector of indices (or names) to the square brackets to get (or set) multiple elements:\n\n\nmy_elements[c(1, 3)]\n\n\n           e1            e3 \n      \"first\" \"new element\" \n\nUsing a logical vector yields all elements where the vector is TRUE:\n\n\nmy_elements[c(TRUE, TRUE, FALSE)]\n\n\n      e1       e2 \n \"first\" \"second\" \n\nVectorization\nThe basic mathematical operations in R and a lot of functions are vectorized. This means, they operate on every element of the vector. Here, every element is multiplied by 2 and the result is printed to the console.\n\n\nx * 2\n\n\n[1]  2  4  6  8 10 12\n\nThe original vector x was not changed in doing so.\n\n\nx\n\n\n[1] 1 2 3 4 5 6\n\nBut we could have, by assigning the result back to x, thus overwriting its previous content. The right hand side (RHS) is executed first:\n\n\nx <- x * 2\n\n\n\nNow x changed:\n\n\nx\n\n\n[1]  2  4  6  8 10 12\n\nA handy way of creating vectors of numbers is with the : operator to specify a range of values:\n\n\n1:5\n\n\n[1] 1 2 3 4 5\n\nOr using the seq function with some additional (optional) parameters:\n\n\nseq(from = 1, to = 10)\n\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nNow you: Look at the documentation/help page for seq and find out how to create a vector of all even numbers from 2 to 100.\n\nFunctions and Packages – Making our lives easier\nYou just learned about the functions sin, seq and max. But wait, there is more! Not only in the sense that there are more functions in R (what kind of language would that be with only two verbs?!), but also in a more powerful way:\n\nWe can define our own functions!\n\nThe syntax (\\(\\leftarrow\\) grammar for programming languages) is as follows.\n\n\nname_for_the_function <- function(parameter1, parameter2, ...) { # etc.\n  # body of the function\n  # things happen\n  result <- parameter1 + parameter2\n  # Something the function should return to the caller\n  return(result)\n}\n\n\n\nThe function ends when it reaches the return keyword. It also ends when it reaches the end of the function body and implicitly returns the last expression. So we could have written it a bit shorter and in fact you will often see people omitting the explicit return at the end:\n\n\nadd <- function(x, y) {\n  x + y\n}\n\n\n\nAnd we can call our freshly defined function:\n\n\nadd(23, 19)\n\n\n[1] 42\n\nGot an error like Error in add(23, 19) : could not find function \"add\"? Check that you did in fact execute the code that defines the function (i.e. put your cursor on the line with the function keyword and hit Ctrl+Enter.).\n\nNow you: Define a function that takes one argument, a vector of numbers, devides each element by the length of the vector (hint: length is the function to get the length) and returns the resulting scaled vector.\n\nYou are not the only one using R. There is a welcoming and helpful community out there. Some people also write a bunch of functions and put them together in a so called package. And some people even went a step further. The tidyverse is a collection of packages that play very well together and also iron out some of the quirkier ways in which R works (Wickham et al. 2019). They provide a consistent interface to enable us to do more while having to learn less special cases. The R function install.packages(\"<package_name_here>\") installs packages from CRAN a curated set of R packages.\nThe Tidyverse\nGo ahead and install the tidyverse packages with\n\n\ninstall.packages(\"tidyverse\")\n\n\n\nThis is one exception to our effort of having everything in our script and not just in the console. We don’t want R trying to install the package every time we run the script, as this needs to happen only once. So you can either turn it into a comment, delete it from the script, or only type it in the console. You can also use RStudio’s built-in panel for package installation.\n\n\n\nTo make the functions from a package available to your R session, run the library function with the name of the package.\n\n\nlibrary(tidyverse)\n\n\n\nThe convention is, to keep all library-calls at the top of your script, so that you ,and others, can see straight away, which packages are needed. Don’t worry about the messages that pop up. This is just the tidyverse telling us that two of it’s functions (lag and filter) have functions with the same names in another package (or in this case base-R) and because we loaded the tidyverse second, R will now use the tidyverse functions. This is what “masking” means.\nLiterate Programming: Rmarkdown\n\n\n\n(“Artwork by @allison_horst” 2020)There is another package I would like you to install. It is called Rmarkdown.\n\n\ninstall.packages(\"rmarkdown\")\n\n\n\nRmarkdown enables us, to combine text with code and then produce a range of output formats like pdf, html, word documents, presentations etc. In fact, this whole website, including the slides, was created with Rmarkdown. Sounds exciting? Let’s dive into it!\nOpen up a new Rmarkdown document with the file extension .Rmd from the New File menu in the top left corner of RStudio: File → New File → R Markdown and choose html as the output format. I particularly like html, because you don’t have to worry about page breaks and it easily works on screens of different sizes, like your phone.\nAn Rmarkdown document consists of three things:\nMetadata:\nInformation about your document such as the author or the date in a format called YAML. This YAML header starts and ends with three minus signs ---.\nText:\nRegular text is interpreted as markdown, meaning it supports things like creating headings by prefixing a line with #, or text that will be bold in the output by surrounding it with **.\nCode chunks:\nStarting with ```{r} and ending with ``` (backticks). They will be interpreted as R code. This is where you write the code like you did in the .R script file. You can insert new chunks with the button on the top right of the editor window or use the shortcut Ctrl+Alt+i.\nUse these to document your thoughts alongside your code when you are doing data analysis. Future you (and reviewer number 2) will be happy! To run code inside of chunks, use,the little play button on the chunk, the tried and true Ctrl+Enter to run one line, or Ctrl+Shift+Enter to run the whole chunk. Your chunks can be as large or small as you want, but try to maintain some sensible structure.\nOur First Dataset: The Palmer Penguins\n(“Artwork by @allison_horst” 2020)So let’s explore our first dataset together in a fresh Rmarkdown document. The setup chunk is special. It gets executed automatically before any other chunk in the document is run. This makes it a good place to load packages. The dataset we are working with today actually comes in its own package, so we need to install this as well (Yes, there is a lot of installing today, but you will have to do this only once):\n\n\ninstall.packages(\"palmerpenguins\")\n\n\n\nAnd then we populate our setup chunk with\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\n\n\nThis gives us the penguins dataset (Horst, Hill, and Gorman 2020):\n\n\npenguins\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\nLet’s talk about the shape of the penguins object. The str function reveals the structure of an object to us.\n\n\nstr(penguins)\n\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\nLists and dataframes\nPreviously, we only had atomic vectors, where all elements are of the same type, like a vector of numbers, and the individual elements could not contain other things themselves (hence the name atomic): c(1, 2, 3). The next more general thing is a list, which we can create with the function list(...). Lists can contain arbitrary elements, even other lists:\n\n\nmy_list <- list(1, \"hello\", c(1, 2, 3), list(42, \"text\"))\nmy_list\n\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"hello\"\n\n[[3]]\n[1] 1 2 3\n\n[[4]]\n[[4]][[1]]\n[1] 42\n\n[[4]][[2]]\n[1] \"text\"\n\nThe print output suggests something else: For vectors, we could subset them using [], but here we will need double square brackets [[]].\n\n\nmy_list[[3]]\n\n\n[1] 1 2 3\n\nUsing single brackets would just give us a subset of the list, not the actual element of the list (yes, this can be confusing):\n\n\nmy_list[3]\n\n\n[[1]]\n[1] 1 2 3\n\nThe penguins variable contains what is called a data.frame. The reason I talked about lists just now is that dataframes are built on top of lists, where the elements are the columns. Because dataframes form this rectangular data format like a spreadsheet you know from excel, the constraint is that the elements of the list need to have the same length. We can demonstrate this by creating our own dataframe from a list.\n\n\nnew_list <- list(x = 1:3, y = c(10, 42, 3), third = c(\"hello\", \"from\", \"R\"))\nnew_list\n\n\n$x\n[1] 1 2 3\n\n$y\n[1] 10 42  3\n\n$third\n[1] \"hello\" \"from\"  \"R\"    \n\nNotice that I did another thing: I gave names to the elements of the list. This is nice because of two reasons. Firstly, as the print output already suggests, we can now use the dollar syntax $ to refer to the individual elements by name instead of by position and RStudio’s autocomplete helps us out.\n\n\nnew_list$x\n\n\n[1] 1 2 3\n\nSecondly, the names will become column names when we turn it into a dataframe:\n\n\nmy_first_df <- as.data.frame(new_list)\nmy_first_df\n\n\n  x  y third\n1 1 10 hello\n2 2 42  from\n3 3  3     R\n\nThere is one last difference for the penguins. They are also a tibble, which is again built on top of dataframes and makes the object look nicer when we print it to the console. Compare the following when executing them in the console:\n\n\npenguins\nas.data.frame(penguins)\n\n\n\nThe dataset contains data for 344 penguins. of 3 different species, collected from 3 islands in the Palmer Archipelago, Antarctica3.\nTranslating Data into Visualizations\nYou probably took this course because you want to build some cool visualizations for you data. In order to do that, let us talk about how we can describe visualizations. Just like language has grammar, some smart people came up with a grammar of graphics (Wilkinson et al. 2005), which was then slightly modified and turned into an R package so that we can not only talk about but also create visualizations using this grammar (Wickham 2010).\n\n\n\n\n\nThe package is called ggplot2 and we already have it loaded because it is included in the tidyverse. Before looking at the code, we can describe what we need in order to create this graphic.\n\n\n\nggplot(penguins, aes(flipper_length_mm, bill_length_mm,\n                     color = species,\n                     shape = sex)) +\n  geom_point(size = 2.5) +\n  labs(x = \"Flipper length [mm]\",\n       y = \"Bill length [mm]\",\n       title = \"Penguins!\",\n       subtitle = \"The 3 penguin species can differentiated by their flipper and bill lengths\") +\n  theme_minimal() +\n  scale_color_brewer(type = \"qual\")\n\n\n\n\nWe can build this plot up step by step. The data is the foundation of our plot, but this just gives us an empty plotting canvas. I am assigning the individual steps we are going through to a variable, so that we can sequentially add elements, but you can do this in one step as shown above.\n\n\nplt <- ggplot(penguins)\nplt\n\n\n\n\nThen, we add and aesthetic mapping to the plot. It creates a relation from the features of our dataset (like the flipper length of each penguin) to a visual property, like position of the x-axis, color or shape.\n\n\nplt <- ggplot(penguins,\n              aes(x = flipper_length_mm,\n                  y = bill_length_mm,\n                  color = species,\n                  shape = sex))\nplt\n\n\n\n\nStill, the plot is empty, it only has a coordinate system with a certain scale. This is because we have no geometric objects to represent our aesthetics. Elements of the plot are added using the + operator and all geometric elements that ggplot knows start with geom_. Let’s add some points:\n\n\nplt <- plt +\n  geom_point()\nplt\n\n\n\n\nLook at the help page for geom_point to find out what aesthetics it understands. The exact way that features are mapped to aesthetics is regulated by scales starting with scale_ and the name of an aesthetic:\n\n\nplt <- plt +\n  scale_color_brewer(type = \"qual\")\nplt\n\n\n\n\nWe can add or change labels (like the x-axis-label) by adding the labs function.\n\n\nplt <- plt +\n    labs(x = \"Flipper length [mm]\",\n         y = \"Bill length [mm]\",\n         title = \"Penguins!\",\n         subtitle = \"The 3 penguin species can differentiated by their flipper and bill lengths\")\n\n\n\nThe overall look of the plot is regulated by themes like the premade theme_ functions or more finely regulated with the theme() function, which uses element functions to create the look of individual elements. Autocomplete helps us out a lot here (Ctrl+Space).\n\n\nplt <- plt + \n  theme_minimal() +\n  theme(legend.text = element_text(face = \"bold\"))\nplt\n\n\n\n\nThe Community: There to catch You.\n\nCoding can be incredibly rewarding, but also incredibly frustrating.\n\nLuckily, the R community is with you!\n(“Artwork by @allison_horst” 2020)In the video I give a brief overview of the resources linked below. Come back here anytime as a reference.\nExercises\nThis course is not graded, but I need some way of confirming that you did indeed take part in this course. In order to get the confirmation, you will send your solutions for a minimum of 5 out of the 8 exercises to me before the Friday following the lecture upload on Monday. For each week I would like you to create a fresh Rmarkdown document with your solutions as code as well as any questions that arose during the lecture. This will help me a lot in improving this course.\nWhen you are done solving the exercises, hit the knit button (at the top of the editor panel) and send me the resulting html document via discord or email (confirm that it looks the way you expected beforehand).\nHere are today’s tasks:\nWrite a section of text about your previous experience with data analysis and/or programming (optional, but I can use this information to customize the course).\nWrite the code that loads in the tidyverse and the palmer penguins data set.\nProduce a scatterplot (meaning a plot with points) of the bill length vs. the bill depth, colorcoded by species.\nImaginary bonus points if you manage to use the same colors as in the image above (hint: look at the help page for scale_color_manual() to find out how). Even more bonus points if you also look into the theme() function and it’s arguments, or the theme_<...>() functions to make the plot prettier.\n\nCreate a vector of all odd numbers from 1 to 99 and store it in a variable.\nCreate a second variable that contains the squares of the first.\nStore both variables in a named list and then turn this list into a tibble (the enhanced version of a data.frame\nDiscover a shortcut for the three steps above using the function tibble. Specifically, have a look at the third bullet point in the description of ?tibble::tibble (The two colons :: specify the package a function is coming from. You only need tibble(...) in the code because the tibble package is loaded automatically with the tidyverse. Here, I specify it directly to send you to the correct help page).\nCreate a scatterplot of the two variables stored in the tibble using ggplot.\nWhat geom_ function do you need to add to the plot to add a line that connects your points?\n\nCheck the metadata (YAML) of your Rmarkdown document and make sure it contains your name as the author: .\nHere are a couple more YAML options you can try if you feel adventurous.\n\nSolutions\nThe Office Hour for the solutions and questions is on Friday, Nov 6, 2020 at 10:00. Find the link in the discord.\nResources\nTidyverse\nR for Data Science (Wickham and Grolemund 2017)\nR4DS online Community\nRStudio Cheat Sheets!\nThe Modern Dive (Kim 2019)\nRStudio Education\nRmarkdown\nhttps://rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf\nhttps://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf\nhttps://bookdown.org/yihui/rmarkdown-cookbook/\nhttps://bookdown.org/yihui/rmarkdown/\nhttps://pandoc.org/MANUAL.html#pandocs-markdown\nhttps://reproducible-analysis-workshop.readthedocs.io/en/latest/6.RMarkdown-knitr.html\nhttps://rmarkdown.rstudio.com/index.html\nR in general\nAdvanced R (Wickham 2019)\nHands on Programming with R (Grolemund and Wickham 2014)\nR Packages (Wickham 2015)\nData Visualization: A Practical Introduction (Healy 2018)\nGraph Cookbook (Chang 2013)\nStatistics\nIntuitive Biostatistics (Motulsky 2017)\nStatistics Done Wrong (Reinhart 2015)\nTalks, Podcasts, Blogs, Videos\nDavid Robinson\nYouTube\nwebsite\n\nJulia Silge\nYouTube\nwebsite\n\nAlison Hill\nwebsite\n\nMisc\nCute and insightful illustrations (“Artwork by @allison_horst” 2020)\nHappy Git with R\nMade with the help of these amazing packages (plus documentation): (R Core Team 2020); (Xie 2020a); (Allaire et al. 2020); (Xie 2015); (Xie 2020b).\n\n\n\nAllaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, and Richard Iannone. 2020. Rmarkdown: Dynamic Documents for r. Manual.\n\n\n“Artwork by @allison_horst.” 2020. https://github.com/allisonhorst/stats-illustrations.\n\n\nChang, Winston. 2013. R Graphics Cookbook: Practical Recipes for Visualizing Data. 1 edition. Beijing Cambridge Farnham Köln Sebastopol Tokyo: O’Reilly Media.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2014. Hands-On Programming with R: Write Your Own Functions and Simulations. Sebastopol, CA: O’Reilly Media.\n\n\nHealy, Kieran. 2018. Data Visualization: A Practical Introduction. 1 edition. Princeton, NJ: Princeton University Press.\n\n\nHorst, Allison, Alison Hill, and Kristen Gorman. 2020. Palmerpenguins: Palmer Archipelago (antarctica) Penguin Data. Manual.\n\n\nKim, Chester Ismay and Albert Y. 2019. Statistical Inference via Data Science. CRC Press.\n\n\nMotulsky, Harvey. 2017. Intuitive Biostatistics: A Nonmathematical Guide to Statistical Thinking. 4 edition. New York: Oxford University Press.\n\n\nR Core Team. 2020. R: A Language and Environment for Statistical Computing. Manual. Vienna, Austria: R Foundation for Statistical Computing.\n\n\nReinhart, Alex. 2015. Statistics Done Wrong: The Woefully Complete Guide. 1 edition. San Francisco: No Starch Press.\n\n\nWickham, Hadley. 2010. “A Layered Grammar of Graphics.” Journal of Computational and Graphical Statistics 19 (1): 3–28. https://doi.org/10.1198/jcgs.2009.07098.\n\n\n———. 2015. R Packages: Organize, Test, Document, and Share Your Code. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\n———. 2019. Advanced R, Second Edition. 2 edition. Boca Raton: Chapman and Hall/CRC.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\nWilkinson, Leland, D. Wills, D. Rope, A. Norton, and R. Dubbs. 2005. The Grammar of Graphics. 2nd edition. New York: Springer.\n\n\nXie, Yihui. 2015. Dynamic Documents with R and Knitr. Second. Boca Raton, Florida: Chapman and Hall/CRC.\n\n\n———. 2020a. Knitr: A General-Purpose Package for Dynamic Report Generation in r. Manual.\n\n\n———. 2020b. Xaringan: Presentation Ninja. Manual.\n\n\nThis will most likely be future You. And you will thank yourself later↩︎\nThey can also contain dots (.), but it is considered bad practice because it can lead to some confusing edge cases.↩︎\nhttps://allisonhorst.github.io/palmerpenguins/↩︎\n",
    "preview": "lectures/lecture1/lecture1_files/figure-html5/final-penguin-plot-1.png",
    "last_modified": "2020-11-01T23:17:45+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "lectures/lecture2/",
    "title": "Lecture 2",
    "description": "... in which we explore the typical data analysis workflow\nwith the `tidyverse`, wrangle different kinds of data and\nlearn about `factors`.",
    "author": [
      {
        "name": "Jannik Buhr",
        "url": "https://jmbuhr.de"
      }
    ],
    "date": "2020-11-02",
    "categories": [
      "lecture"
    ],
    "contents": "\n\nContents\nVideo\nSlides\nScript\nMaking Ourselves at Home in RStudio\nImportant Settings\nA Project-based Workflow\nWorking in Style\n\nA Data Analysis Workflow\nReading Data with readr\nCommon Hurdles when Importing Data\n\nWrangling Data with dplyr\nselect\nfilter\nmutate\nInterlude: Begind the magic, handling data with base-R\nThe pipe %>%\narrange\nsummarise\ngroup_by\n\nVisualization and our First Encounter with factors\n\nExercises\nResources\nPackage Documentation\nGetting Help\n\n\nVideo\n\n\nSlides\n\n\n\n\nScript\n\nNote:\nI try to be vocal about what the code does in plain English while I type it and learning the “translations” of symbols and keywords can help you, too. After a while, programming can feel a lot more like having a conversation with your digital assistant or a helpful friend. The boundary between human languages and computer languages is more blurry than you might think.\n\nBefore we get deepter into R, let’s talk a little bit about our Home when working with R: RStudio.\nMaking Ourselves at Home in RStudio\nImportant Settings\nI highlighted 3 settings that I consider important to change from their default values. The first two might seem odd at first glance.\n\n\n\nThe workspace that RStudio would save as .RData contains all objects created in a session, which is, what we can see in the Environment pane (by default in the top right panel, bottom right in my setup). Why would we not want to load the objects we created in the last session into our current session automatically? The reason is reproducibility. We want to make sure that everything our analysis needs is in the script. It creates our variables and plots from the raw data and should be the sole source of truth. Given the raw data and the script, everyone should be able to reproduce our results. The third setting (text encoding) is also concerned with collaboration. It makes sure that our text files and special characters in them (like German umlauts) look the same on different operating systems like Windows, iOS and Linux.\nA Project-based Workflow\nLast week we simply went ahead and created a script file and an Rmarkdown file in some folder on our computer. But how does R known, where the script is? How does it know, where to look, when we tell it to read in a file or save a plot? The main folder where R starts is called the working directory. To find out, what our current working directory is, we execute the function getwd() for get working directory:\n\n\ngetwd()\n\n\n[1] \"/home/jannik/Documents/projects/teaching/dataIntro20/_lectures/lecture2\"\n\nThis will look slightly different depending on you operating system. The next function I want you to know, but never use:\n\n\nsetwd(\"some/file/path\")\n\n\n\n“Why should I not use it?” you might ask. Let’s assume I use the function to set the working directory as seen above:\n\n\nsetwd(\"/home/jannik/Documents/projects/teaching/dataIntro20/_lectures/lecture2\")\n\n\n\nNow, when I give the file to you to test my analysis, chances are very low that it would work. Because you are likely not called Jannik and even more likely don’t have the same folder structure that I had.\nSo what we want instead of these absolute file paths, is a relative file paths that start in the folder that our scripts are in. This is what RStudio Projects are for. It is basically just a folder with a special file that ends in .Rproj, but as soon as R finds this file in the folder, the working directory will automatically be this folder. So when you share this folder, it will still just work.\nGo ahead and use the blue R button in the top right corner to create a New Project. I recommend you do this either as one project for the whole course or with one project per week. Projects are also convenient because they save what files you had open and so forth.\nThere is one thing I didn’t tell you about Rmarkdown documents, yet. Their working directory is always the folder they are in, even if they are in some subdirectory of a project. In a way this also means that you don’t necessarily need a project to work with Rmarkdown, but having one anyway makes it easier to keep track of your files and have a consistent structure.\nWorking in Style\nNow that we have a cosy project for today, let’s also make sure we are working in style and are feeling right at home in RStudio. This blogpost provides excellent gifs for the different settings in RStudio and even for Rmarkdown troubleshooting. I am also fond of the rsthemes package for additional appearances.\nA Data Analysis Workflow\nWe are getting close to importing our very first dataset from a file into R. Generally, this is the first thing that needs to happen with any data analysis and we will cover it today. The data I provided is already pretty tidy so we will start with that and build some visualizations. The communicate-part is also covered, because we are working in Rmarkdown after all, which is designed to communicate our findings. Later, we will also have a look at some less tidy data, but not before having defined what “tidy data” is.\n\n\n\n\nFigure 1: Figure from Wickham and Grolemund (2017).\n\n\n\nReading Data with readr\n\n\n\n\n\nThe package responsible for loading data in the tidyverse is called readr, so we start by loading the whole tidyverse.\nNote, that in general, we could also load just the readr package with library(readr), but we need the rest of the tidyverse later on anyways. There is also the option to not load a package at all but rather only use one function from a package by prefixing the function with the package name and two colons (::) Like so: readr::read_csv(\"...\").\n\n\nlibrary(tidyverse)\n\n\n\nWithout further ado, let’s download the data for today. In fact, there are multiple ways to go about this. We could download the whole course folder from GitHub by following the link in the top right corner of this website and then using the download button:\n\n\n\nYou will then find the data in the folder ./_lectures/lecture2/data/.\nOr we can navigate to the file on GitHub. Follow this link: files, click on one of the files and then click on raw:\n\n\n\nFrom there you can copy the link displayed in your browser address field and download the file straight from R:\n\n\ndownload.file(\"https://raw.githubusercontent.com/jmbuhr/dataIntro20/master/_lectures/lecture2/data/gapminder.csv\",\n              \"data/gapminder.csv\")\n\n\n\nThe folder to download your data to (./data) must be created in advance. This is an example for a relative path (an absolute path would start with / or a drive letter like C:).\nNow we can finally load in the data and store it in a variable. When working with file paths, RStudio’s autocompletion is especially helpful. We can trigger it with Tab or Ctrl+Space.\n\n\ngapminder <- read_csv(\"data/gapminder.csv\")\n\n\n\nreadr will also tell you the datatypes it guessed for the columns. Let’s inspect our dataset:\n\n\ngapminder\n\n\n# A tibble: 1,704 x 6\n   country     continent  year lifeExp      pop gdpPercap\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# … with 1,694 more rows\n\nThe gapminder dataset (Bryan 2017) is an excerpt from the gapminder project and contains the life expectancy at birth for 142 countries at 5 year intervals between 1952 and 2007. It also contains the population and the Gross Domestic Product (GDP) per Inhabitant. We will built a visualization later on.\nread_csv can even read data from a url straight away, without the need for us to download the file ourselves, but we usually want a copy of the data locally. For the curious run this:\n\n\nread_csv(\"https://raw.githubusercontent.com/jmbuhr/dataIntro20/master/_lectures/lecture2/data/gapminder.csv\")\n\n\n\nSo, this all went smoothly. But this will not always be the case. We will now look at common hurdles when importing data\nCommon Hurdles when Importing Data\nThe function we just used was called read_csv, because it reads a file format that consists of comma separated values. Look at the raw file in a text editor (not word) like notepad or RStudio to see why. But the file extension .csv can sometimes be lying…\nBecause in German, the comma is used to separate decimal numbers (vs. the dot in English), a lot of Software will output a different type of csv-file when configured in German. It will still call it csv, but actually it is separated by semicolons! We have a special function for this:\n\n\nread_csv2(\"data/gapminder_csv2.csv\")\n\n\n\nWhen looking through the autocompletion options that pop up when you are typing the function name, you might have noticed a similar function read.csv and read.csv2. These are the functions that come with R, without any packages like the tidyverse. You can of course use those as well, but the tidyverse functions provide a more consistent experience and have less surprising quirks. I am teaching the tidyverse first, because it allows you to do more while having to learn less edge cases.\nIf we look at yet another file data/gapminder_tsv.txt, we notice that the file extension doesn’t tell us much about the format, only that it is text (as opposed to a binary format only computers can read). If we look into the file:\n\n\nread_lines(\"data/gapminder_tsv.txt\", n_max = 3)\n\n\n[1] \"country\\tcontinent\\tyear\\tlifeExp\\tpop\\tgdpPercap\"    \n[2] \"Afghanistan\\tAsia\\t1952\\t28.801\\t8425333\\t779.4453145\"\n[3] \"Afghanistan\\tAsia\\t1957\\t30.332\\t9240934\\t820.8530296\"\n\nWe notice that the values are separated by \", a special sequence that stands for the tab character. The read_tsv function will do the job.\nIf the separator (also called delimiter) is even more obscure, we can use the general function read_delim. Say a co-worker misunderstood us and thought tsv stands for “Tilde separated values,” we can still read his file.\n\n\nread_lines(\"data/obscure_file.tsv\", n_max = 3)\n\n\n[1] \"country~continent~year~lifeExp~pop~gdpPercap\"    \n[2] \"Afghanistan~Asia~1952~28.801~8425333~779.4453145\"\n[3] \"Afghanistan~Asia~1957~30.332~9240934~820.8530296\"\n\n\n\nread_delim(\"data/obscure_file.tsv\", delim = \"~\")\n\n\n\nThere are more ways in which raw data can be messy or hard to read depending on the machine but I can’t show all of them. One common thing you will encounter though is measurement machines writing some additional information in the first couple of lines before the actual data (like the time of the measurement). In this example:\n\n\nread_lines(\"data/gapminder_messier.csv\", n_max = 4)\n\n\n[1] \"# Some comment about the data\"                   \n[2] \"And maybe a personal note\"                       \n[3] \"country,continent,year,lifeExp,pop,gdpPercap\"    \n[4] \"Afghanistan,Asia,1952,28.801,8425333,779.4453145\"\n\nThe first 2 lines are not part of the data. Reading the file normally as a csv would produce something weird: Because the first line does not contain any commata, it will assume that the file contains only one column and also report a bunch of parsing failures. Parsing is the act of turning data represented as raw text into a useful format, like a table of numbers.\n\n\nread_csv(\"data/gapminder_messier.csv\", n_max = 3)\n\n\n# A tibble: 3 x 1\n  `# Some comment about the data`\n  <chr>                          \n1 And maybe a personal note      \n2 country                        \n3 Afghanistan                    \n\nWe can fix this by telling R to skip the first 2 lines entirely:\n\n\nread_csv(\"data/gapminder_messier.csv\", skip = 2, n_max = 3)\n\n\n# A tibble: 3 x 6\n  country     continent  year lifeExp      pop gdpPercap\n  <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n\nI was using the n_max argument of the functions above to save space in this lecture script.\nIn the video I forgot to mention that I also included an excel file to practice. We can read it using a function from the readxl package. This package is automatically installed with the tidyverse, but it is not loaded along with the other packages via library(tidyverse). We can either load it with library(readxl) or refer to a single function from the package without loading the whole thing using double colons (::):\n\n\nreadxl::read_xlsx(\"./data/gapminder.xlsx\")\n\n\n\nNow, that we learned about some of the ways in which raw data can be structured, let us go back to the original data that we read in and saved in the variable gapminder.\n\ncountry\ncontinent\nyear\nlifeExp\npop\ngdpPercap\nAfghanistan\nAsia\n1952\n28.801\n8425333\n779.4453\nAfghanistan\nAsia\n1957\n30.332\n9240934\n820.8530\nAfghanistan\nAsia\n1962\n31.997\n10267083\n853.1007\nAfghanistan\nAsia\n1967\n34.020\n11537966\n836.1971\nAfghanistan\nAsia\n1972\n36.088\n13079460\n739.9811\nAfghanistan\nAsia\n1977\n38.438\n14880372\n786.1134\n\nWrangling Data with dplyr\n\n\n\n\n\nThere a are a number of ways in which we can manipulate data. Of course I mean manipulate in it’s original sense, not the malicious one. This is sometimes referred to as data wrangling and within the tidyverse, this is a job for the dplyr package (short for data plyer, the tool you see in the logo).\ndplyr provides functions for various operations on our data. Theses functions are sometimes also called dplyr verbs. All of them take a tibble or data.frame as input (plus additional parameters) and always return a tibble.\n\n\n\nFigure 2: (“Artwork by @allison_horst” 2020)\n\n\n\nselect\nThe first verb we introduce is used to select columns. And hence, it is called select. The first argument is always the data, followed by an arbitrary number of column names. We can recognize functions the take an arbitrary number of additional arguments by the ... in the autocompletion and help page.\n\n\nselect(gapminder, country, year, pop)\n\n\n# A tibble: 1,704 x 3\n   country      year      pop\n   <chr>       <dbl>    <dbl>\n 1 Afghanistan  1952  8425333\n 2 Afghanistan  1957  9240934\n 3 Afghanistan  1962 10267083\n 4 Afghanistan  1967 11537966\n 5 Afghanistan  1972 13079460\n 6 Afghanistan  1977 14880372\n 7 Afghanistan  1982 12881816\n 8 Afghanistan  1987 13867957\n 9 Afghanistan  1992 16317921\n10 Afghanistan  1997 22227415\n# … with 1,694 more rows\n\nIt might be confusing why we don’t need quotation marks around the column names like we do when we select and element from a vector by name as in:\n\n\nc(first = 1, second = 2)[\"first\"]\n\n\nfirst \n    1 \n\nThis concept is known as quasiquotation or data masking. It is quite unique to R, but it allows functions to known about the content of the data that is passed to them and use this as the environment in which they do their computations and search for variable names. So while the variable country doesn’t exist in the global environment, it does exist as a column of the gapminder tibble. dplyr functions always look in the data first when they search for names.\nThe help page for select tells us more about the different ways in which we can select columns. Here are a couple of examples without the output, rum them in your R session to confirm that they do what you think they do. (but do have a look at the help pages yourselves, they are quite well written).\n\n\nselect(gapminder, where(is.numeric))\nselect(gapminder, country:lifeExp)\nselect(gapminder, starts_with(\"c\"))\nselect(gapminder, c(1, 3, 4))\n\n\n\nfilter\n\n\n\nFigure 3: (“Artwork by @allison_horst” 2020)\n\n\n\nAfter selecting columns it is only natural to ask how to select rows. This is achieved with the function filter. For example, we can filter for all years smaller than 2000:\n\n\nfilter(gapminder, year < 2000)\n\n\n# A tibble: 1,420 x 6\n   country     continent  year lifeExp      pop gdpPercap\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# … with 1,410 more rows\n\nOr all the rows where the country is “New Zealand”:\n\n\nfilter(gapminder, country == \"New Zealand\")\n\n\n# A tibble: 12 x 6\n   country     continent  year lifeExp     pop gdpPercap\n   <chr>       <chr>     <dbl>   <dbl>   <dbl>     <dbl>\n 1 New Zealand Oceania    1952    69.4 1994794    10557.\n 2 New Zealand Oceania    1957    70.3 2229407    12247.\n 3 New Zealand Oceania    1962    71.2 2488550    13176.\n 4 New Zealand Oceania    1967    71.5 2728150    14464.\n 5 New Zealand Oceania    1972    71.9 2929100    16046.\n 6 New Zealand Oceania    1977    72.2 3164900    16234.\n 7 New Zealand Oceania    1982    73.8 3210650    17632.\n 8 New Zealand Oceania    1987    74.3 3317166    19007.\n 9 New Zealand Oceania    1992    76.3 3437674    18363.\n10 New Zealand Oceania    1997    77.6 3676187    21050.\n11 New Zealand Oceania    2002    79.1 3908037    23190.\n12 New Zealand Oceania    2007    80.2 4115771    25185.\n\nmutate\nWe are back at manipulating columns, this time by creating new ones or changing old ones. The dplyr verb that does that is called muate. For example, we might want to calculate the total GDP from the GDP per Capita and the population:\n\n\nmutate(gapminder, gdp = pop * gdpPercap)\n\n\n# A tibble: 1,704 x 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# … with 1,694 more rows\n\nNotice, that none of the functions changed the original variable gapminder. They only take an input and return and output, which makes it easier to reason about our code and later chain pieces of code together. How do you change it then? Use the Force! … ahem, I mean, the assignment operator (<-).\n\n\ngapminder <- mutate(gapminder, gdp = pop * gdpPercap)\n\n\n\nHere, the power of dplyr shines. It knows that pop and gdpPercap are columns of the tibble and that gdp refers to the new name of the freshly created column.\nInterlude: Begind the magic, handling data with base-R\nThis section is meant to show you what happens behind the scenes. It is not strictly necessary to understand all the details of it in order to work effectively with the tidyverse, but it helps especially when things don’t go as planned.\nSo let’s look into handling data with base-R. Last week we briefly covered subsetting of vectors by their indices, their names, or a logical vector:\n\n\nx <- c(42, 1, 13, 29)\nnames(x) <- c(\"first\", \"second\", \"third\", \"fourth\")\nx\n\n\n first second  third fourth \n    42      1     13     29 \n\n\n\nx[c(1,3)]\n\n\nfirst third \n   42    13 \n\n\n\nx[c(\"first\", \"second\")]\n\n\n first second \n    42      1 \n\n\n\nx[c(TRUE, FALSE, FALSE, TRUE)]\n\n\n first fourth \n    42     29 \n\nThis subsetting with a logical vector can be used to filter the vector:\n\n\nselect_this <- x < 20\nselect_this\n\n\n first second  third fourth \n FALSE   TRUE   TRUE  FALSE \n\n\n\nx[select_this]\n\n\nsecond  third \n     1     13 \n\nWith data in 2 dimensions, rows and columns, subsetting works similarly. Let’s use the function tibble to create a tibble from vectors:\n\n\nmy_data <- tibble(\n  x = c(42, 1, 13, 29),\n  y = c(1, 2, 3, 4),\n  z = c(\"z1\", \"z2\", \"z3\", \"z4\")\n)\nmy_data\n\n\n# A tibble: 4 x 3\n      x     y z    \n  <dbl> <dbl> <chr>\n1    42     1 z1   \n2     1     2 z2   \n3    13     3 z3   \n4    29     4 z4   \n\n\nNote:\nR is not whitespace sensitive (like python). That means indentation doesn’t change the meaning of the code. We can use this to format our code to look pretty, which is why I started a new line after the opening bracket of tibble(.\n\nSubsetting a tibble like a vector selects columns:\n\n\nmy_data[c(1, 3)]\n\n\n# A tibble: 4 x 2\n      x z    \n  <dbl> <chr>\n1    42 z1   \n2     1 z2   \n3    13 z3   \n4    29 z4   \n\nBut if you pass two arguments to the square brackets, separated by commata, we can filter rows and select columns Here, we get the first row in the second and third columns:\n\n\nmy_data[1, c(2, 3)]\n\n\n# A tibble: 1 x 2\n      y z    \n  <dbl> <chr>\n1     1 z1   \n\nIf we follow the logic above, we can also filter the data. The comma without any argument afterwards selects all columns.\n\n\nmy_data[my_data$x < 20, ]\n\n\n# A tibble: 2 x 3\n      x     y z    \n  <dbl> <dbl> <chr>\n1     1     2 z2   \n2    13     3 z3   \n\nAt first glance, the tidyverse way of doing the same is only a little bit shorter. But apart from the fact that we don’t have to repeat the name of the data object my_data (because filter knows where to look for x, whereas [] doesn’t), there is another advantage.\n\n\nfilter(my_data, x < 20)\n\n\n# A tibble: 2 x 3\n      x     y z    \n  <dbl> <dbl> <chr>\n1     1     2 z2   \n2    13     3 z3   \n\nThe pipe %>%\nThe tidyverse functions are easier to compose (i.e. chain together). To facilitate this, we introduce another operator, a bit like + for numbers or the + to add ggplot components, but specially for functions. The pipe, which you can either type or insert in RStudio with Ctrl+Shift+M, takes it’s left side and passes it as the first argument to the function on the right side:\n\n\nmy_data %>% select(x, z)\n\n\n# A tibble: 4 x 2\n      x z    \n  <dbl> <chr>\n1    42 z1   \n2     1 z2   \n3    13 z3   \n4    29 z4   \n\nAnd because all main tidyverse functions take data as their first argument, we can chain them together fluently. Additionally, it enables autocompletion of column names inside of the function that gets the data. So back to the gapminder example:\n\n\ngapminder %>% \n  filter(year > 2000) %>% \n  mutate(gdp = pop * gdpPercap) %>% \n  select(country, year, gdp)\n\n\n# A tibble: 284 x 3\n   country      year           gdp\n   <chr>       <dbl>         <dbl>\n 1 Afghanistan  2002  18363410424.\n 2 Afghanistan  2007  31079291949.\n 3 Albania      2002  16153932130.\n 4 Albania      2007  21376411360.\n 5 Algeria      2002 165447670333.\n 6 Algeria      2007 207444851958.\n 7 Angola       2002  30134833901.\n 8 Angola       2007  59583895818.\n 9 Argentina    2002 337223430800.\n10 Argentina    2007 515033625357.\n# … with 274 more rows\n\nIt also reads much nicer in your head, which makes reasoning about the code easier. Without telling you what the above code did, you can understand it, because it reads like English. You can often pronounce the pipe as “and then” in your head, or out-loud, I’m not judging.\n\nNote:\nThe base-R and the tidyverse way are not mutually exclusive. Sometimes you can mix and match.\n\narrange\nA simple thing you might want from a table is to sort it based on some column. This is what arrange does:\n\n\ngapminder %>% \n  arrange(year)\n\n\n# A tibble: 1,704 x 7\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.      6.57e 9\n 2 Albania     Europe     1952    55.2  1282697     1601.      2.05e 9\n 3 Algeria     Africa     1952    43.1  9279525     2449.      2.27e10\n 4 Angola      Africa     1952    30.0  4232095     3521.      1.49e10\n 5 Argentina   Americas   1952    62.5 17876956     5911.      1.06e11\n 6 Australia   Oceania    1952    69.1  8691212    10040.      8.73e10\n 7 Austria     Europe     1952    66.8  6927772     6137.      4.25e10\n 8 Bahrain     Asia       1952    50.9   120447     9867.      1.19e 9\n 9 Bangladesh  Asia       1952    37.5 46886859      684.      3.21e10\n10 Belgium     Europe     1952    68    8730405     8343.      7.28e10\n# … with 1,694 more rows\n\nThe helper function desc marks a column to be arranged in descending order. We can arrange by multiple columns, where the first will be most important.\n\n\ngapminder %>% \n  arrange(desc(year), pop) %>% \n  select(country, year, pop) %>% \n  rename(population = pop)\n\n\n# A tibble: 1,704 x 3\n   country                year population\n   <chr>                 <dbl>      <dbl>\n 1 Sao Tome and Principe  2007     199579\n 2 Iceland                2007     301931\n 3 Djibouti               2007     496374\n 4 Equatorial Guinea      2007     551201\n 5 Montenegro             2007     684736\n 6 Bahrain                2007     708573\n 7 Comoros                2007     710960\n 8 Reunion                2007     798094\n 9 Trinidad and Tobago    2007    1056608\n10 Swaziland              2007    1133066\n# … with 1,694 more rows\n\nI also introduced the rename verb without warning. It does what it says it does, only the order of the names might be confusing. The new name comes first (like when you are creating a new column with mutate). You can also rename within select:\n\n\ngapminder %>% select(country, year, population = pop)\n\n\n# A tibble: 1,704 x 3\n   country      year population\n   <chr>       <dbl>      <dbl>\n 1 Afghanistan  1952    8425333\n 2 Afghanistan  1957    9240934\n 3 Afghanistan  1962   10267083\n 4 Afghanistan  1967   11537966\n 5 Afghanistan  1972   13079460\n 6 Afghanistan  1977   14880372\n 7 Afghanistan  1982   12881816\n 8 Afghanistan  1987   13867957\n 9 Afghanistan  1992   16317921\n10 Afghanistan  1997   22227415\n# … with 1,694 more rows\n\nsummarise\nTo condense one or multiple columns into summary values, we use summarise: Like with mutate, we can calculate multiple things in one step.\n\n\ngapminder %>% \n  summarise(\n    last_year = max(year),\n    average_pop = mean(pop),\n    minimal_gdp = min(gdp)\n  )\n\n\n# A tibble: 1 x 3\n  last_year average_pop minimal_gdp\n      <dbl>       <dbl>       <dbl>\n1      2007   29601212.   52784691.\n\nBut condensing whole columns into one value, flattening the tibble in the style of Super Mario jumping on mushrooms, is often not what we need. We would rather know the summaries within certain groups. For example the maximal gdp per country. This is what group_by is for.\ngroup_by\ngroup_by is considered an adverb, because it doesn’t change the data itself but it changes how subsequent functions handle the data. For example, if a tibble has groups, all summaries are calculated within these groups:\n\n\ngapminder %>% \n  group_by(country)\n\n\n# A tibble: 1,704 x 7\n# Groups:   country [142]\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1952    28.8  8425333      779.  6567086330.\n 2 Afghanistan Asia       1957    30.3  9240934      821.  7585448670.\n 3 Afghanistan Asia       1962    32.0 10267083      853.  8758855797.\n 4 Afghanistan Asia       1967    34.0 11537966      836.  9648014150.\n 5 Afghanistan Asia       1972    36.1 13079460      740.  9678553274.\n 6 Afghanistan Asia       1977    38.4 14880372      786. 11697659231.\n 7 Afghanistan Asia       1982    39.9 12881816      978. 12598563401.\n 8 Afghanistan Asia       1987    40.8 13867957      852. 11820990309.\n 9 Afghanistan Asia       1992    41.7 16317921      649. 10595901589.\n10 Afghanistan Asia       1997    41.8 22227415      635. 14121995875.\n# … with 1,694 more rows\n\nFor example, let’s look at the range of the life expectancy for each country:\n\n\ngapminder %>% \n  group_by(country) %>% \n  summarise(lower_life_exp = min(lifeExp),\n            upper_life_exp = max(lifeExp))\n\n\n# A tibble: 142 x 3\n   country     lower_life_exp upper_life_exp\n   <chr>                <dbl>          <dbl>\n 1 Afghanistan           28.8           43.8\n 2 Albania               55.2           76.4\n 3 Algeria               43.1           72.3\n 4 Angola                30.0           42.7\n 5 Argentina             62.5           75.3\n 6 Australia             69.1           81.2\n 7 Austria               66.8           79.8\n 8 Bahrain               50.9           75.6\n 9 Bangladesh            37.5           64.1\n10 Belgium               68             79.4\n# … with 132 more rows\n\nsummarize removes one level of grouping. If the data was grouped by multiple features, this means that some groups remain. We can make sure that the data is no longer grouped with ungroup.\n\n\ngapminder %>% \n  group_by(continent, year) %>% \n  summarise(mean_gdpPercap = mean(gdpPercap)) %>% \n  ungroup()\n\n\n# A tibble: 60 x 3\n   continent  year mean_gdpPercap\n   <chr>     <dbl>          <dbl>\n 1 Africa     1952          1253.\n 2 Africa     1957          1385.\n 3 Africa     1962          1598.\n 4 Africa     1967          2050.\n 5 Africa     1972          2340.\n 6 Africa     1977          2586.\n 7 Africa     1982          2482.\n 8 Africa     1987          2283.\n 9 Africa     1992          2282.\n10 Africa     1997          2379.\n# … with 50 more rows\n\nGroups also work within mutate and filter. For example, we can get all rows where the gdp per Person was highest per country:\n\n\ngapminder %>%\n  group_by(country) %>% \n  filter(gdpPercap == max(gdpPercap))\n\n\n# A tibble: 142 x 7\n# Groups:   country [142]\n   country     continent  year lifeExp      pop gdpPercap          gdp\n   <chr>       <chr>     <dbl>   <dbl>    <dbl>     <dbl>        <dbl>\n 1 Afghanistan Asia       1982    39.9   1.29e7      978.      1.26e10\n 2 Albania     Europe     2007    76.4   3.60e6     5937.      2.14e10\n 3 Algeria     Africa     2007    72.3   3.33e7     6223.      2.07e11\n 4 Angola      Africa     1967    36.0   5.25e6     5523.      2.90e10\n 5 Argentina   Americas   2007    75.3   4.03e7    12779.      5.15e11\n 6 Australia   Oceania    2007    81.2   2.04e7    34435.      7.04e11\n 7 Austria     Europe     2007    79.8   8.20e6    36126.      2.96e11\n 8 Bahrain     Asia       2007    75.6   7.09e5    29796.      2.11e10\n 9 Bangladesh  Asia       2007    64.1   1.50e8     1391.      2.09e11\n10 Belgium     Europe     2007    79.4   1.04e7    33693.      3.50e11\n# … with 132 more rows\n\nOr we can use groups in mutate to find out, what percentage of it’s continent a country’s population makes up per year:\n\n\ngapminder %>% \n  group_by(continent, year) %>% \n  mutate(pctPop = pop / sum(pop) * 100)\n\n\n# A tibble: 1,704 x 8\n# Groups:   continent, year [60]\n   country   continent  year lifeExp     pop gdpPercap      gdp pctPop\n   <chr>     <chr>     <dbl>   <dbl>   <dbl>     <dbl>    <dbl>  <dbl>\n 1 Afghanis… Asia       1952    28.8  8.43e6      779.  6.57e 9  0.604\n 2 Afghanis… Asia       1957    30.3  9.24e6      821.  7.59e 9  0.591\n 3 Afghanis… Asia       1962    32.0  1.03e7      853.  8.76e 9  0.605\n 4 Afghanis… Asia       1967    34.0  1.15e7      836.  9.65e 9  0.605\n 5 Afghanis… Asia       1972    36.1  1.31e7      740.  9.68e 9  0.608\n 6 Afghanis… Asia       1977    38.4  1.49e7      786.  1.17e10  0.624\n 7 Afghanis… Asia       1982    39.9  1.29e7      978.  1.26e10  0.494\n 8 Afghanis… Asia       1987    40.8  1.39e7      852.  1.18e10  0.483\n 9 Afghanis… Asia       1992    41.7  1.63e7      649.  1.06e10  0.521\n10 Afghanis… Asia       1997    41.8  2.22e7      635.  1.41e10  0.657\n# … with 1,694 more rows\n\nSometimes you want to refer to the size of the current group inside of mutate or summarise. The function to to just that is called n(). For example, I wonder how many rows of data we have per year.\n\n\ngapminder %>% \n  group_by(year) %>% \n  summarise(n = n())\n\n\n# A tibble: 12 x 2\n    year     n\n   <dbl> <int>\n 1  1952   142\n 2  1957   142\n 3  1962   142\n 4  1967   142\n 5  1972   142\n 6  1977   142\n 7  1982   142\n 8  1987   142\n 9  1992   142\n10  1997   142\n11  2002   142\n12  2007   142\n\nA shortcut for group_by and summarise with n() is the count function:\n\n\ngapminder %>% \n  count(year)\n\n\n# A tibble: 12 x 2\n    year     n\n   <dbl> <int>\n 1  1952   142\n 2  1957   142\n 3  1962   142\n 4  1967   142\n 5  1972   142\n 6  1977   142\n 7  1982   142\n 8  1987   142\n 9  1992   142\n10  1997   142\n11  2002   142\n12  2007   142\n\nIn general, you might find after solving a particular problem in a couple of steps that there is a more elegant solution. Do not be discouraged by that! It simply means that there is always more to learn, but the tools you already know by now will get you a very long way and set you on the right track.\nI think we learned enough dplyr verbs for now. We can treat ourselves to a little ggplot visualization.\nVisualization and our First Encounter with factors\n\n\ngapminder %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line(alpha = 0.3) +\n  facet_wrap(~ continent)\n\n\n\n\nThe facet_wrap function slices our plot into theses subplots, a style of plot sometimes referred to as small multiples. At this point you might wonder: “How do I control the order of these facets?” The answer is: With a factor! Any time we have a vector that can be thought of as representing discrete categories (ordered or unordered), we can express this by turning the vector into a factor with the factor function. This enables R’s functions to handle them appropriately. Let’s create a little example. We start out with a character vector.\n\n\nanimals <- c(\"cat\", \"dog\", \"parrot\", \"whale shark\", \"bear\")\nanimals\n\n\n[1] \"cat\"         \"dog\"         \"parrot\"      \"whale shark\"\n[5] \"bear\"       \n\n\n\nanimals <- factor(animals)\nanimals\n\n\n[1] cat         dog         parrot      whale shark bear       \nLevels: bear cat dog parrot whale shark\n\nNote the new information R gives us, the Levels, which is all possible values we can put into the factor. They are automatically ordered alphabetically on creation. We can also pass a vector of levels on creation.\n\n\nanimals <- c(\"cat\", \"dog\", \"parrot\", \"whale shark\", \"bear\")\nfactor(animals, levels = c(\"parrot\", \"cat\", \"dog\", \"bear\"))\n\n\n[1] cat    dog    parrot <NA>   bear  \nLevels: parrot cat dog bear\n\nA factor can only contain elements that are in the levels, so because I omitted the whale shark, it will be turned into NA. The tidyverse contains the forcats package to help with factors. Most functions from this package start with fct_.\n\n\n\n\n\nFor example, the fct_relevel function, which keeps all levels but let’s us change the order:\n\n\nanimals <- factor(animals)\nfct_relevel(animals, c(\"parrot\", \"dog\"))\n\n\n[1] cat         dog         parrot      whale shark bear       \nLevels: parrot dog bear cat whale shark\n\nUsing this in action, we get:\n\n\nplt <- gapminder %>% \n  mutate(continent = fct_relevel(continent, \"Europe\", \"Oceania\")) %>% \n  ggplot(aes(year, lifeExp, group = country)) +\n  geom_line(alpha = 0.3) +\n  facet_wrap(~ continent)\n\nplt\n\n\n\n\nI saved the plot to a variable called plt because we need it later. Let’s make this plot a bit prettier by adding color! The gapminder package that provided this dataset also included a nice color palette. I included it as a .csv file in the data/ folder so that we can practice importing data once more. But you could also take the shortcut of getting it straight from the package (gapminder::country_colors). Here, we are using the head function to look at the first couple of rows of the tibble and to look at the first couple of elements of the named vector from the package.\n\n\ncountry_colors <- read_csv(\"data/country_colors.csv\")\nhead(country_colors)\n\n\n# A tibble: 6 x 2\n  country          color  \n  <chr>            <chr>  \n1 Nigeria          #7F3B08\n2 Egypt            #833D07\n3 Ethiopia         #873F07\n4 Congo, Dem. Rep. #8B4107\n5 South Africa     #8F4407\n6 Sudan            #934607\n\n\n\nhead(gapminder::country_colors)\n\n\n         Nigeria            Egypt         Ethiopia Congo, Dem. Rep. \n       \"#7F3B08\"        \"#833D07\"        \"#873F07\"        \"#8B4107\" \n    South Africa            Sudan \n       \"#8F4407\"        \"#934607\" \n\nNotice, that the csv that we read in translates to a tibble with two columns, namely country and color. But what we need for ggplot to assign colors to the countries is what the gapminder package provides: a names vector. The names are the countries and the values so called hexadecimal (short Hex) color codes (https://www.w3schools.com/colors/colors_hexadecimal.asp). So what we want to do is translate the tibble into a named vector:\n\n\ncountry_colors <- country_colors %>% \n  mutate(color = set_names(color, country)) %>% \n  pull(color)\n\nhead(country_colors)\n\n\n         Nigeria            Egypt         Ethiopia Congo, Dem. Rep. \n       \"#7F3B08\"        \"#833D07\"        \"#873F07\"        \"#8B4107\" \n    South Africa            Sudan \n       \"#8F4407\"        \"#934607\" \n\nTwo things happened here that are sort of new. set_names is a handy way to take a vector and return a vector with names. It fits better into the tidyverse syntax than the “old” way of assigning to names(x) <- c(\"new\", \"names\", \"vector\"). And secondly pull can be though of as a pipeable dollar. It pulls out the column of a tibble or the element of a named list.\n\n\ngapminder$year %>% head()\n\n\n[1] 1952 1957 1962 1967 1972 1977\n\ngapminder %>% pull(year) %>% head()\n\n\n[1] 1952 1957 1962 1967 1972 1977\n\nNow, with our color vector ready to go, we can make the plot pretty. Remember the variable we saved our plot to? We can add more ggplot functions to it just like to a regular ggplot. A guide is the generalization of a legend, so we are setting it to none because adding a legend for 142 different colors (/countries) would fill the whole plot.\n\n\nplt +\n  aes(color = country) +\n  scale_color_manual(values = country_colors, guide = guide_none()) +\n  theme_minimal() + \n  labs(x = \"\",\n       y = \"Life Expectancy at Birth\",\n       title = \"Life Expectancy over Time\")\n\n\n\n\nWe also added a theme and modified the axis titles. You might have already notice a number of very pronounced dips in some of the lines. We will investigate this rather bleak reality when we talk about modeling and iteration next week.\nExercises\nDrink a cup of coffee or tea, relax, because you just worked through quite a long video.\nFamiliarize yourself with the folders on your computer. Make sure you understand, where your directories and files live.\nFrom RStudio, create a new RStudio project for this course.\nInside the project folder, create a folder for the data.\nCreate a new Rmarkdown document at the top level of your project folder for today’s exercises, again including questions that came up during the course.\nDownload the data for today in one of the ways taught. You can refer to the script anytime.\nMake sure you have all the important settings set and are feeling right at home in RStudio.\n\nThe file ./data/exercise1.txt is in an unfamiliar format.\nFind out how it is structured and read it as a tibble.\nCreate a scatterplot of the x and y column with ggplot2.\nLook at the help page for geom_point. What is the difference between geom_point(aes(color = <something>)) and geom_point(color = <something>)? A relevant hint is in the section about the ...-argument.\nMake the plot pretty by coloring the points, keeping in mind the above distinction.\n\nRead in the gapminder dataset with readr\nUsing a combination of dplyr verbs and / or visualizations with ggplot2, answer the following questions:\nWhich continent had the highest life expectancy on average in the most current year? There are two options here. First, calculate a simple mean for the countries in each continent. Then, remember that the countries have different population sizes, so we really need a weighted mean using R’s function weighted.mean().\nIs there a relationship between the GDP per capita and the life expectancy? A visualization might be helpful.\nHow did the population of the countries change over time? Make the plot more informative by adding color, facets and labels (with geom_text). Can you find out, how to add the country name label only to the last year? Hint: Have a look at the data argument that all geom_-functions have.\n\nResources\nPackage Documentation\nThe tidyverse website\nThe readr package website with cheatsheet\nThe dplyr package website with cheatsheet\nGetting Help\nHow to find help\nR4DS online learning community\n\n\n\n“Artwork by @allison_horst.” 2020. https://github.com/allisonhorst/stats-illustrations.\n\n\nBryan, Jennifer. 2017. Gapminder: Data from Gapminder. Manual.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1 edition. Sebastopol, CA: O’Reilly Media.\n\n\n\n\n",
    "preview": "lectures/lecture2/img/RS_settings.png",
    "last_modified": "2020-11-06T13:34:55+01:00",
    "input_file": "lecture2.utf8.md",
    "preview_width": 589,
    "preview_height": 581
  }
]
