---
title: "Introduction to Data Analysis with R"
subtitle: "Lecture 5: The Nature of Randomness"
institute: "Heidelberg University, WS20/21"
author: 
  - "Jannik Buhr"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    css: ["xaringan-themer.css", "extra.css"]
    nature:
      ratio: '16:9'
      navigation:
        scroll: false
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, warning=FALSE}
source(here::here("assets/slide-setup.R"))

xaringanExtra::use_xaringan_extra(c(
  "tile_view", "editable", "animate_css",
  "clipboard", "tachyons"
))
```

layout: true

.absolute.top-0.right-1.tr.w-10[
```{r}
include_graphics("https://raw.githubusercontent.com/jmbuhr/dataIntro20/master/images/hex.png")
```
]


---
name: title
class: left bottom hide-count
background-color: #FBFCFF;

```{r title-slides, echo=FALSE, message = FALSE, warning = FALSE}
htmltools::withTags(
  div(
    class = "talk-meta",
    div(
      class = "talk-title",
      h1(rmarkdown::metadata$title),
      p(rmarkdown::metadata$subtitle)
    ),
    div(
      class = "talk-author",
      paste(rmarkdown::metadata$author, collapse = " <br> "),
      br(),
      span(paste(rmarkdown::metadata$institute, collapse = ", "))
    ),
    div(
      class = "talk-date",
      knitr::knit(text = rmarkdown::metadata$date, quiet = TRUE)
    )
  )
)
```

.absolute.bottom-0.right-1.mid-gray[
With Artwork by @allison_horst
]

---

class: inverse center middle

> To understand statistics means understanding the nature of randomness first.

---

class: inverse center middle

```{r, out.width="50%"}
include_graphics("img/statistically-significant.jpg")
```

---

class: center middle

```{r chess-board, echo=FALSE, fig.asp=1, fig.width=7}
n = 8
crossing(x = 1:n,
         y = 1:n) %>%
  mutate(f = xor((x %% 2 == 0), (y %% 2 == 0))) %>% 
  ggplot(aes(x, y, fill = f)) +
  geom_tile() +
  coord_equal() +
  scale_fill_brewer() +
  theme_void() +
  guides(fill = "none")
```

---

class: center middle animated fadeInUp

```{r significant, echo=FALSE, fig.cap="Artwork by @allison_horst", out.extra="class=.external"}
include_graphics("img/paste-5E31A2FF.png")
```

---

## Definitions

- **alternative hypothesis** ( $H_1$ ) ("I am the better player.")
- **null hypothesis** ( $H_0$ ) ("This is just luck")


## $\rightarrow$ to R!

---

## Making Decisions

- How likely is certain event is under the assumption of the null hypothesis (only chance)?
- Decide on some threshold $\alpha$, at which we reject the null hypothesis.
- This is called the **significance threshold**.
- For $P[X \ge x]< \alpha$: **statistically significant**
- This probability is called the **p-value**.

---

class: middle

> »A p value is not a measure of how right you are,
  or how significant the difference is;
  it’s a measure of how surprised you should be if there is no actual difference
  between the groups, but you got data suggesting there is.
  A bigger difference, or one backed up by more data,
  suggests more surprise and a smaller p value.«
> — Alex Reinhart [@reinhartStatisticsDoneWrong2015]

---

class: middle

[I Fooled Millions Into Thinking Chocolate Helps Weight Loss. Here's How.](https://io9.gizmodo.com/i-fooled-millions-into-thinking-chocolate-helps-weight-1707251800)
by John Bohannon

---

## Example: Medical Testing

- Sensitivity = Power = true positive rate = $1-\beta$
- Specificity = true negative rate = $1-\alpha$

Let us assume a test with a
sensitivity of 90% and a specificity
of 92%.

--

- 1000 people
- 10 positive
- 9 tested true positive
- 1 false negative
- 79 false positives



--

```{r, echo = FALSE, fig.asp=0.1, fig.width=12, out.width="90%"}
total <- 1000
positives <- 10
negatives <- total - positives
sensitivity <- 0.9
specificity <- 1 - 0.08
true_positives  <- sensitivity * positives
false_positives <- (1 - specificity) * negatives
p_positive <- true_positives / (true_positives + false_positives)

colors = c("detected positives" = "darkred",
            "not detected positives (false negatives)" = "palevioletred1",
            "false positives" = "red",
            "true negatives" = "white")

transform_and_plot <- function(df) {
  long <- df %>% 
  rowwise() %>%
  mutate(res = list(rep(parts, times = vals))) %>% 
  unnest()

  long %>% 
    ggplot(aes(x = 0, fill = res)) +
    geom_bar(color = "black") +
    theme_void() + 
    scale_fill_manual(values = colors) +
    coord_flip() +
    theme(legend.position = "bottom") +
    guides(fill = guide_legend(title = "", reverse = TRUE))
}
tibble(
  parts = c("detected positives",
            "not detected positives (false negatives)",
            "false positives",
            "true negatives"),
  vals = c(true_positives,
           positives - true_positives,
           round(false_positives),
           negatives)
) %>% 
  transform_and_plot()
```

Probability of being positive after positive test:

$$\frac{true~positives}{true~positives + false~positives}=10\%$$

Formally, this is described by Bayes's Formula

$$P(A|B)=\frac{P(B|A)*P(A)}{P(B)}$$


